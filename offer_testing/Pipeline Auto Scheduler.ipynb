{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a81877ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import infrastructure\n",
    "import filepath \n",
    "import pygsheets\n",
    "import datetime as dt\n",
    "import openpyxl \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# use creds to create a client to interact with the Google Drive API\n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "mamba = gc.open_by_url('https://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1238872091') \n",
    "pipeline_test = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/16vrHMWs0ambcBJ1sC0SqpYVG8SOSWlbg1N22-bF49v8/edit#gid=1963352944\")\n",
    "pipeline_test_wks = pipeline_test.worksheet('title','Testing Scheduler')\n",
    "pl_df = pipeline_test_wks.get_as_df()\n",
    "# open worksheet - mamba\n",
    "schedule_wks  =  mamba.worksheet('title','New Mamba')\n",
    "schedule_df = schedule_wks.get_as_df()\n",
    "#la nina\n",
    "lanina = infrastructure.get_lanina()\n",
    "lanina1 =  lanina[~(lanina['Content Approval Status'].str.contains('Paused|Not Approved|Failed Testing', na = False)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aceebd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the row index in the schedule sheet\n",
    "def find_schedule_row(schedule_df, shortcode):\n",
    "    matching_rows = schedule_df[schedule_df['Dataset'] == shortcode].index\n",
    "    return matching_rows[0] if not matching_rows.empty else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b355e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the column index for the date\n",
    "def find_date_column(schedule_wks, test_date):\n",
    "    for idx, col in enumerate(schedule_wks.get_row(2, include_tailing_empty=False)[3:], start=4):\n",
    "        if pd.to_datetime(col).date() == test_date.date():\n",
    "            return idx\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df728e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_to_letters(column):\n",
    "    \"\"\"Convert a column number to a column letter.\"\"\"\n",
    "    string = \"\"\n",
    "    while column > 0:\n",
    "        column, remainder = divmod(column - 1, 26)\n",
    "        string = chr(65 + remainder) + string\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3553a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over pl_df and update the schedule sheet\n",
    "for index, row in pl_df.iterrows():\n",
    "    shortcode = row['Shortcode_DP.SV']\n",
    "    test_date = pd.to_datetime(row['Testing Date'])\n",
    "    drop_number = row['Drop Number']\n",
    "    time = row['Time']\n",
    "    segment = row['Segment']\n",
    "    send_strategy = row['Send Strategy']\n",
    "    \n",
    "    #add creative id to pl_df\n",
    "    sc = row['Offer'].split()[4]\n",
    "    hitpath = row['Offer'].split()[0]\n",
    "    df_content= lanina1[(lanina1['OfferIDs'] == int(hitpath)) & (lanina1['Type'] == sc) & (lanina1['Channel'] =='SC')][['Reporting Content ID','Content Approval Status', 'Content']]  \n",
    "    ccid  = df_content['Reporting Content ID'].values[0]\n",
    "    col_idx = 10\n",
    "    col_letter = column_to_letters(col_idx)\n",
    "    cell_address = f\"{col_letter}{index+2}\"\n",
    "    pipeline_test_wks.update_value(cell_address, ccid)\n",
    "    \n",
    "    offer = row['Offer']\n",
    "    limit = row['Limit']\n",
    "    offset = row['Offset']\n",
    "    creative = row['Creative']\n",
    "    job_name = row['Job Name']\n",
    "    p_limit = \"Total - \"+(str(limit+1))\n",
    "    p_offset = str(limit+1)\n",
    "    \n",
    "    schedule_row_idx = find_schedule_row(schedule_df, shortcode)\n",
    "    date_col_idx = find_date_column(schedule_wks, test_date)\n",
    "\n",
    "    if schedule_row_idx is not None and date_col_idx is not None:\n",
    "        values_to_update = [time, segment, send_strategy, offer, limit, offset, creative, job_name]\n",
    "\n",
    "        # update cells with new data\n",
    "        for i, value in enumerate(values_to_update):\n",
    "            col_letter = column_to_letters(date_col_idx)\n",
    "            cell_address = f\"{col_letter}{schedule_row_idx + 12 + i}\"\n",
    "            schedule_wks.update_value(cell_address, value)\n",
    "        \n",
    "        cell_address = f\"{col_letter}{schedule_row_idx + 7}\"\n",
    "        schedule_wks.update_value(cell_address, p_limit)\n",
    "        cell_address = f\"{col_letter}{schedule_row_idx + 8}\"\n",
    "        schedule_wks.update_value(cell_address, p_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8dd105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
