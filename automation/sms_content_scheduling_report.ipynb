{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Future development plan: \n",
    "    -   schedule direct into cobra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import filepath\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pygsheets\n",
    "import infrastructure\n",
    "import datetime\n",
    "import math\n",
    "import datetime\n",
    "from datetime import timedelta  \n",
    "import re\n",
    "import warnings\n",
    "import statistics\n",
    "from datetime import date\n",
    "from calendar import monthrange\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import xlsxwriter\n",
    "import send_email\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import filepath \n",
    "import datetime as dt\n",
    "from scipy.stats import percentileofscore\n",
    "from datetime import datetime\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanina = infrastructure.get_lanina()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=time.time()\n",
    "sms = pd.read_csv(filepath.output_folder+'SS_LC_merged_data.csv')\n",
    "df = infrastructure.transform_sms_df(sms)\n",
    "\n",
    "# df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "\n",
    "df = df[~df['Send Strategy'].isin(['PT','RT','IT','OT','W','MI','Mi'])]\n",
    "#testMaster = scheduleMaster[scheduleMaster['Send Strategy'].isin(['PT','RT','IT','OT','CT'])]\n",
    "#miningMaster = scheduleMaster[scheduleMaster['Send Strategy']=='MI']\n",
    "#scheduleMaster = scheduleMaster[~(scheduleMaster.index.isin(testMaster.index) | scheduleMaster.index.isin(miningMaster.index))] #create index s time series sorted index\n",
    "df['Datestring']=df['Date'].dt.strftime('%m.%d.%y') #create datestring variable \n",
    "df['CTR']=(df['Clicks']/df['Delivered'])\n",
    "df['eCPM']=(df['Revenue']*1000/df['Delivered'])\n",
    "df['JPCTR']=(df['Jump Page Clicks']/df['Delivered'])\n",
    "df['optout rate']=(df['Optout']/df['Delivered'])\n",
    "df['CTR Normalized']=(df['CTR']-df['CTR'].min())/(df['CTR'].max()-df['CTR'].min())\n",
    "df['eCPM Normalized']=(df['eCPM']-df['eCPM'].min())/(df['eCPM'].max()-df['eCPM'].min())\n",
    "df['CTR50'] = df['CTR Normalized'] + df['eCPM Normalized']\n",
    "df['Creative Type'] = df['Creative Type'].str.split(' ',expand = True)[0]\n",
    "# Import Lanina\n",
    "lanina = infrastructure.get_lanina()\n",
    "lanina['OfferIDs'] = lanina['OfferIDs'].astype(str).str.split('.',expand = True)[0]\n",
    "# mamba \n",
    "mamba = infrastructure.get_mamba()\n",
    "    # oppo ctr\n",
    "temp1= df.groupby(['Segments','Opportunity Cost Send Strategy','Date']).agg({'Revenue':'sum','Clicks':'sum','Delivered':'sum'}).reset_index()\n",
    "temp1[['rolling Revenue','rolling Clicks','rolling Delivered']] = temp1.groupby('Segments').shift(1).rolling(30, min_periods=5)[['Revenue','Clicks','Delivered']].sum().reset_index(drop=True)\n",
    "temp1['Dataset_Agg_30day_ctr'] = temp1['rolling Clicks'] / temp1['rolling Delivered']\n",
    "temp1['Dataset_Agg_30day_ecpm'] = temp1['rolling Revenue'] * 1000/ temp1['rolling Delivered']\n",
    "dataset_agg_ctr =  temp1[['Segments','Date','Opportunity Cost Send Strategy','Dataset_Agg_30day_ctr','Dataset_Agg_30day_ecpm']]\n",
    "df = df.merge(dataset_agg_ctr, how = 'left')\n",
    "df['Opportunity Clicks'] = df['Clicks'] - df['Dataset_Agg_30day_ctr'] * df['Delivered']\n",
    "df['Opportunity Cost'] = df['Revenue'] - df['Dataset_Agg_30day_ecpm'] * df['Delivered'] /1000  # revenue  - last 30 days average revenue in that drop \n",
    "df['opportunity CTR'] = df['Opportunity Clicks'] / df['Delivered']\n",
    "df['opportunity eCPM'] = df['Opportunity Cost'] * 1000 / df['Delivered']\n",
    "\n",
    "# change the following code to the function calculate_oppo_ctr\n",
    "# I need to calculate \n",
    "def calculate_oppo_ctr(df):\n",
    "    df['opportunity CTR'] = df['Opportunity Clicks'] / df['Delivered']\n",
    "    \n",
    "    opportunity_ctr_series = df[(df['opportunity CTR']!=np.inf)&(df['opportunity CTR'].isna() == False)]['opportunity CTR']\n",
    "    #df['opportunity CTR Normalized']=(df['opportunity CTR']-df['opportunity CTR'].min())/(df['opportunity CTR'].max()-df['opportunity CTR'].min())\n",
    "    df['opportunity CTR Normalized']= percentileofscore(opportunity_ctr_series, df['opportunity CTR'], kind='weak') / 100\n",
    "    df['opportunity eCPM'] = df['Opportunity Cost'] * 1000 / df['Delivered']\n",
    "    opportunity_eCPM_series =  df[(df['opportunity eCPM']!=np.inf)&(df['opportunity eCPM'].isna() == False)]['opportunity eCPM']\n",
    "    #df['opportunity eCPM Normalized']=(df['opportunity eCPM']-df['opportunity eCPM'].min())/(df['opportunity eCPM'].max()-df['opportunity eCPM'].min())\n",
    "    df['opportunity eCPM Normalized']=percentileofscore(opportunity_eCPM_series, df['opportunity eCPM'], kind='weak') / 100 \n",
    "    df['opportunity CTR50'] = df['opportunity CTR Normalized']*0.6 + df['opportunity eCPM Normalized']*0.4\n",
    "    return df\n",
    "\n",
    "df = calculate_oppo_ctr(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select by Opportunity Cost CTR50 (60% Oppr CTR Normalized + 40% Oppr eCPM Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################### Content Selection with HTML Selection #######################\n",
    "\n",
    "# ignore all warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def content_select(df,sc,pubid,hitpath,past_content_explode,direct):\n",
    "    ccid=''\n",
    "    mamba = infrastructure.get_mamba()\n",
    "    # according to pubid and sc to find out sc_dppub from df\n",
    "    publisher = infrastructure.get_publisher()\n",
    "    dppub = publisher[publisher['PUBID']==int(pubid)]['DP.DS or DP.sV'].values[0]\n",
    "    dv = publisher[publisher['PUBID']==int(pubid)]['Sub Vertical'].values[0]\n",
    "    sc_dppub = sc + \"_\" + dppub\n",
    "    \n",
    "    df['Opp Cost eCPM'] = df['Opportunity Cost'] / df['Delivered'] * 1000\n",
    "    df = df.merge(lanina[['Reporting Content ID','Old Content ID']], how = 'left', left_on = 'Creative Type', right_on = 'Old Content ID')\n",
    "    df.loc[df['Reporting Content ID'].isna() == False,'Creative Type'] = df['Reporting Content ID']\n",
    "    df.drop(columns=['Reporting Content ID','Old Content ID'], inplace=True)\n",
    "    # Create dataframe of all drops of given hitpath in past 90 days\n",
    "    df_content = df[(df['Date'] > pd.Timestamp.today() - pd.to_timedelta(90, unit='d')) & (df['Hitpath Offer ID']==hitpath) & (df['Shortcode Name']==sc)]\n",
    "    df_content = df_content[(df_content['Creative Type'].isin(lanina['Reporting Content ID'].unique().tolist())) ]\n",
    "\n",
    "    \n",
    "    df_content['shortcode_DP.SV'] = df_content['shortcode_DP.SV'] == sc_dppub \n",
    "    df_content['data_vertical'] = df_content['Data Vertical'] == dv\n",
    "    df_content_by_drop = df_content.copy()\n",
    "    ## get the opportunity CTR50 for each content piece in the same data vertical \n",
    "    df_content_other_affliate = df_content[(df_content['shortcode_DP.SV']==False) & (df_content['data_vertical'] == True)]\n",
    "    df_content_other_affliate = df_content_other_affliate.groupby(['data_vertical','Creative Type','Hitpath Offer ID'], as_index=False).agg({'Delivered': 'sum', 'Opportunity Cost': 'sum','Opportunity Clicks': 'sum','Clicks': 'sum','Revenue':'sum'})\n",
    "    df_content_other_affliate = calculate_oppo_ctr(df_content_other_affliate)\n",
    "    df_content_other_affliate = df_content_other_affliate[['Creative Type','opportunity CTR50']]\n",
    "    df_content_other_affliate = df_content_other_affliate.rename(columns = {'opportunity CTR50':'opportunity CTR50_data_vertical_level'})\n",
    "\n",
    "\n",
    "    #offer_median_eCPM = df_content['Opp Cost eCPM'].median()\n",
    "    offer_median_eCPM = df_content['opportunity CTR50'].median()\n",
    "    df_content_drops = df_content.groupby(['shortcode_DP.SV','Creative Type'], as_index=False).count()\n",
    "    df_content_drops = df_content_drops[['shortcode_DP.SV','Creative Type', 'Hitpath Offer ID']]\n",
    "    df_content_drops.columns = ['shortcode_DP.SV','Creative Type','Drops']\n",
    "    df_content = df_content.groupby(['shortcode_DP.SV','Creative Type','Hitpath Offer ID'], as_index=False).agg({'Delivered': 'sum', 'Opportunity Cost': 'sum','Opportunity Clicks': 'sum','Clicks': 'sum','Revenue':'sum'})\n",
    "    df_content = calculate_oppo_ctr(df_content)\n",
    "    df_content['Calculated Opp Cost eCPM'] = df_content['Opportunity Cost'] / df_content['Delivered'] * 1000\n",
    "    df_content['Calculated CTR'] = df_content['Clicks'] / df_content['Delivered']\n",
    "    df_content['Calculated opp CTR'] = df_content['Opportunity Clicks'] / df_content['Delivered']\n",
    "    #df_content['Calculated Opp Cost eCPM'] = df_content['Opportunity Cost'] / df_content['Delivered'] * 1000\n",
    "    df_content = df_content.merge(df_content_drops, on=['shortcode_DP.SV','Creative Type'])\n",
    "\n",
    "    # Get the drops for the affiliate account\n",
    "    df_content_affliate = df_content[df_content['shortcode_DP.SV']==True]\n",
    "    df_content_affliate_eCPM = df_content_by_drop[df_content_by_drop['shortcode_DP.SV']==True]['opportunity CTR50'].median()\n",
    "    df_content_drops = df_content_drops[df_content_drops['shortcode_DP.SV']==True]\n",
    "    df_content_affliate_drops = df_content_affliate.groupby('Creative Type', as_index=False).count()\n",
    "    #df_content_affliate_eCPM = df_content_affliate['Opportunity Cost'].sum() / df_content_affliate['Delivered'].sum() * 1000\n",
    "    df_content_affliate = calculate_oppo_ctr(df_content_affliate)\n",
    "    #df_content_affliate['Calculated Opp Cost eCPM'] = df_content_affliate['Opportunity Cost'] / df_content_affliate['Delivered'] * 1000\n",
    "    df_content_affliate = df_content_affliate[['shortcode_DP.SV','Creative Type','opportunity CTR50','Calculated Opp Cost eCPM','Calculated CTR','Calculated opp CTR','Drops']]\n",
    "    df_content_affliate['Meets Threshold'] =  df_content_affliate['opportunity CTR50'] >= df_content_affliate_eCPM\n",
    "\n",
    "    # Get date last dropped in affiliate account and whether it is in the past 30 days or not\n",
    "    df_content_dates = df[(df['Date'] > pd.Timestamp.today() - pd.to_timedelta(90, unit='d')) & \\\n",
    "                        (df['Hitpath Offer ID']==hitpath) & \\\n",
    "                        (df['shortcode_DP.SV'] == sc_dppub)]\n",
    "    df_content_dates = df_content_dates[['Creative Type','Date']]\n",
    "    df_content_dates = df_content_dates.groupby(['Creative Type'],as_index=False).max()\n",
    "    cobra_dates = mamba[(mamba['Hitpath Offer ID']==hitpath) & (mamba['shortcode_DP.SV']==sc_dppub) & (mamba['Creative']!='') & (mamba['Date']> df['Date'].max() ) ][['Date','Creative']]\n",
    "    cobra_dates['Creative'] = cobra_dates['Creative'].str.replace('NEW','')\n",
    "    cobra_dates['Creative'] = cobra_dates['Creative'].str.replace('*','')\n",
    "    cobra_dates['Creative'] = cobra_dates['Creative'].str.split('\\n')\n",
    "    cobra_dates = cobra_dates.explode('Creative')\n",
    "    cobra_dates = cobra_dates.reset_index(drop=True)\n",
    "    cobra_dates['Creative'] = cobra_dates['Creative'].str.strip()\n",
    "    cobra_dates = cobra_dates[cobra_dates['Creative']!='']\n",
    "    #cobra_dates = mamba[(mamba['Hitpath Offer ID']==hitpath) & (mamba['shortcode_DP.SV']==sc_dppub)][['Date','Creative']]\n",
    "    cobra_dates.columns = ['Date','Creative Type']\n",
    "    df_content_dates = pd.concat([df_content_dates,cobra_dates],ignore_index=True).drop_duplicates()\n",
    "    df_content_dates = df_content_dates.groupby(['Creative Type'],as_index=False).max()\n",
    "    df_content_dates['Recently Dropped'] = df_content_dates['Date'] > pd.Timestamp.today() - pd.to_timedelta(30, unit='d')\n",
    "\n",
    "    # Get the drops for all other accounts\n",
    "    df_content_other = df_content[df_content['shortcode_DP.SV']==False]\n",
    "    df_content_other_eCPM = df_content_by_drop[df_content_by_drop['shortcode_DP.SV']==False]['opportunity CTR50'].median()\n",
    "    df_content_drops = df_content_drops[df_content_drops['shortcode_DP.SV']==False]\n",
    "    #df_content_other_eCPM = df_content_other['Opportunity Cost'].sum() / df_content_other['Delivered'].sum() * 1000\n",
    "    df_content_other = calculate_oppo_ctr(df_content_other)\n",
    "    df_content_other = df_content_other.merge(df_content_other_affliate, on = 'Creative Type', how = 'left') \n",
    "    df_content_other.loc[df_content_other['opportunity CTR50_data_vertical_level'].isna() == False, 'opportunity CTR50'] = df_content_other['opportunity CTR50_data_vertical_level'] * 0.7 +   df_content_other['opportunity CTR50'] * 0.3\n",
    "    \n",
    "    #df_content_other_median_eCPM = df_content_other['Revenue CPM (eCPM)'].median()\n",
    "    df_content_other = df_content_other[['shortcode_DP.SV','Creative Type','opportunity CTR50','Calculated Opp Cost eCPM','Calculated CTR','Calculated opp CTR','Drops']]\n",
    "    df_content_other['Meets Threshold'] =  df_content_other['opportunity CTR50'] >= df_content_other_eCPM\n",
    "  \n",
    " \n",
    "\n",
    "\n",
    "    # Merge the above dataframes together \n",
    "    df_content = df_content_other.merge(df_content_affliate, how='outer', on='Creative Type').merge(df_content_dates, how='outer', on='Creative Type')\n",
    "    df_content['Meets Threshold'] = (df_content['Meets Threshold_y'] == True) | ((df_content['Meets Threshold_y'].isnull()) & (df_content['Meets Threshold_x'] == True))\n",
    "    print('Offer eCPM for Other Accounts: ', round(df_content_other_eCPM,2))\n",
    "    print('Offer eCPM for Affiliate Account: ', round(df_content_affliate_eCPM,2))\n",
    "    print('Offer median eCPM: ',round(offer_median_eCPM,2))\n",
    "\n",
    "    df_content = df_content[['Creative Type', 'opportunity CTR50_x', 'Drops_x',\n",
    "                                'opportunity CTR50_y', 'Drops_y', 'Date', 'Recently Dropped', 'Meets Threshold']]\n",
    "    df_content.columns = ['Creative Type','eCPM in Other Accounts','Drops in Other Accounts',\n",
    "                            'eCPM in Affiliate Account', 'Drops in Affiliate Accounts','Date','Recently Dropped',\n",
    "                            'Meets Mean Threshold']\n",
    "    # check if the content has a median eCPM higher than the offer median eCPM\n",
    "    df_content_by_drop = df_content_by_drop.groupby(['Creative Type'], as_index=False)['opportunity CTR50'].median()\n",
    "    df_content = df_content.merge(df_content_by_drop, how='left', on='Creative Type')\n",
    "    df_content = df_content.rename(columns = {'opportunity CTR50':'median eCPM'})\n",
    "    df_content['Meets Median Threshold'] = df_content['median eCPM'] >= offer_median_eCPM\n",
    "\n",
    "    # check if the content has an aggregate eCPM in the affiliate account higher than the offer aggregate eCPM in the affiliate account \n",
    "    df_content.loc[df_content['eCPM in Affiliate Account'] >= df_content_affliate_eCPM,'Meets Median Threshold'] = True\n",
    "\n",
    "    # rank is calculated as the average of the aggregate eCPM of the content piece and two times the median eCPM of the content piece \n",
    "    df_content['rank'] = (df_content['eCPM in Other Accounts'] + 2 * df_content['median eCPM']) / 3\n",
    "    # if the content piece has been dropped in the affiliate account in the past 90 days, that aggregate eCPM will be used in the ranking instead of the aggregate for all accounts\n",
    "    df_content.loc[~df_content['eCPM in Affiliate Account'].isna(),['rank']] = (df_content['eCPM in Affiliate Account'] + 2*df_content['median eCPM'])/3\n",
    "    df_content = df_content.sort_values('rank', ascending=False)\n",
    "    df_content = df_content.merge(lanina[['Reporting Content ID','OfferIDs','Content Approval Status','Content']], how='left', left_on='Creative Type',right_on = 'Reporting Content ID', copy = False )\n",
    "    # drop reporting content id column\n",
    "    df_content = df_content.drop(columns=['Reporting Content ID'])\n",
    "    # filter out content that is not approved and failed testing \n",
    "    df_content = df_content[~(df_content['Content Approval Status'].str.contains('Paused|Not Approved|Failed Testing', na = False)) ]\n",
    "    if direct == True:\n",
    "        df_content = df_content[df_content['OfferIDs'].astype(int)==int(hitpath)]\n",
    "    df_content_all = df_content.copy()\n",
    "    past_content_body = lanina[lanina['Reporting Content ID'].isin(past_content_explode)]['Content'].tolist()\n",
    "    if df_content.empty:\n",
    "        \n",
    "                    # find Reporting Content ID from la nina based on offer IDs and Type \n",
    "        lanina1 =  lanina[~(lanina['Content Approval Status'].str.contains('Paused|Not Approved|Failed Testing', na = False)) ]\n",
    "        df_content= lanina1[(lanina1['OfferIDs'] == hitpath) & (lanina1['Type'] == sc[:3]) & (lanina1['Channel'] !='LC') & (lanina1['Content'].isin(past_content_body)==False)][['Reporting Content ID','Content Approval Status', 'Content']]\n",
    "        tf_content = len(lanina1[(lanina1['Type'] == sc[:3])]['Content'].unique().tolist())\n",
    "        z = 2 \n",
    "        if tf_content >= 14:\n",
    "            z = 2\n",
    "        else:\n",
    "            z = 1\n",
    "        if len(df_content) > 1: \n",
    "            print('No content available from content selection script, we choose 2 random content from Lanina')\n",
    "            ccid  = df_content.sample(n=z)\n",
    "            content = ccid['Content'].tolist()\n",
    "            ccid = ccid['Reporting Content ID'].tolist()\n",
    "            ccid = \"\\n\".join(ccid)\n",
    "            df_content_all = df_content.copy()\n",
    "            print(ccid)\n",
    "            print(content)\n",
    "        elif len(df_content) == 1:\n",
    "            print('No content available from content selection script, we choose 1 random content from Lanina')\n",
    "            ccid  = df_content['Reporting Content ID'].values[0]\n",
    "            content = df_content['Content'].values[0]\n",
    "            df_content_all = df_content.copy()\n",
    "            print(ccid)\n",
    "            print(content)\n",
    "        else:\n",
    "            \n",
    "            print('No content available from lanina')\n",
    "    else:\n",
    "        # select only content that has been dropped more than 2 times in any account, or has been dropped at least once in the affiliate account it\n",
    "        df_content['Meets Drop Threshold'] = (df_content['Drops in Other Accounts']>=2) \n",
    "        df_content = df_content[((df_content['Meets Drop Threshold']==True) & (df_content['eCPM in Affiliate Account'].isna())) | (~df_content['eCPM in Affiliate Account'].isna())]\n",
    "        df_content = df_content[(df_content['Meets Mean Threshold']==True) & (df_content['Meets Median Threshold']==True)].sort_values('rank', ascending=False)\n",
    "\n",
    "    # if no content meets threshold, remove drop number requirement\n",
    "        if df_content.empty:\n",
    "            df_content = df_content_all.copy()\n",
    "            df_content = df_content[(df_content['Meets Mean Threshold']==True) & (df_content['Meets Median Threshold']==True)].sort_values('rank', ascending=False)\n",
    "\n",
    "        # if after remove number of drop restriction no content meets threshold, reduce mean and median threshold until content is found\n",
    "        k=0\n",
    "        while df_content.empty:\n",
    "            k = k + 1\n",
    "            print('No offers, decreasing thresholds.')\n",
    "            df_content = df_content_all.copy()\n",
    "            df_content_other['Meets Threshold'] =  df_content_other['opportunity CTR50'] >= df_content_other_eCPM - k * 0.1\n",
    "            df_content_affliate['Meets Threshold'] =  df_content_affliate['opportunity CTR50'] >= df_content_affliate_eCPM - k * 0.1\n",
    "            df_content['Meets Median Threshold'] = df_content['median eCPM'] >= offer_median_eCPM - k * 0.1\n",
    "            df_content = df_content[(df_content['Meets Mean Threshold']==True) & (df_content['Meets Median Threshold']==True)].sort_values('rank', ascending=False)\n",
    "\n",
    "            if k > 20:\n",
    "                df_content = df_content_all.copy()\n",
    "                df_content['Meets Drop Threshold'] = (df_content['Drops in Other Accounts'] > 2) \n",
    "                df_content = df_content.sort_values('rank', ascending=False)\n",
    "                break\n",
    "\n",
    "        df_content = df_content.reset_index(drop=True)\n",
    "        # If not specifying HTML, remove dates from HTML so gapping is not considered\n",
    "        \n",
    "        # Select content, either a random content piece that has not dropped in the past 30 days weighted by the rank or 4 times the rank if opp cost is positive\n",
    "        # or the one least recently dropped if all have been dropped in the past 30 days\n",
    "        content = df_content[df_content['Recently Dropped']!=True] # didn't drop in the past 30 days \n",
    "        #content.loc[content['rank']>0,'rank'] = content['rank'] * 4 \n",
    " \n",
    "        if content.empty:\n",
    "            print(\"All content has been dropped in the past 30 days, selecting the least recently dropped content piece.\")\n",
    "            content = df_content[(df_content['Meets Mean Threshold']==True) & (df_content['Meets Median Threshold']==True)]\n",
    "            print(len(content))\n",
    "            selected_creative = content[content['Date'] == content['Date'].min()][['Creative Type']]\n",
    "\n",
    "            \n",
    "        else:\n",
    "            selected_creative = content[['Creative Type']].sample(n=1,weights=pd.to_numeric(content['rank']) + abs(2*min(pd.to_numeric(content['rank']))))\n",
    "            #selected_creative = content[['Creative Type']]\n",
    "        try: \n",
    "            ccid = selected_creative['Creative Type'].iloc[0]\n",
    "        except: \n",
    "            ccid = df_content_all['Creative Type'].iloc[0]\n",
    "        print('')\n",
    "        \n",
    "        print(ccid)\n",
    "        print('Ranked', df_content.index[df_content['Creative Type'] == ccid][0] + 1, 'out of', len(df_content), 'pieces that meet thresholds')        \n",
    "\n",
    "        if len(df_content) == 1:\n",
    "            print(\"There's only one content piece that meets thresholds, we try to add a test content\")\n",
    "            lanina1 =  lanina[~(lanina['Content Approval Status'].str.contains('Paused|Not Approved|Failed Testing', na = False)) ]\n",
    "            lanina_backup_content= lanina1[(lanina1['OfferIDs'] == hitpath) & (lanina1['Type'] == sc[:3]) & (lanina1['Channel'] !='LC') & (lanina1['Content'].isin(past_content_body)==False)&(lanina1['Content Status in Platform']=='Uncreated')][['Reporting Content ID']]\n",
    "            if len(lanina_backup_content) > 0:\n",
    "                ccid = ccid + \"\\n\"+lanina_backup_content['Reporting Content ID'].sample(n=1).values[0] \n",
    "                print(ccid)\n",
    "        \n",
    "\n",
    "\n",
    "    return df_content, df_content_all, ccid \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\npassed_content = lanina[lanina[\\'Content Approval Status\\'].str.contains(\"Approved - Passed\")]\\ndf1 = df[(df[\\'Creative Type\\'].isin(passed_content[\\'Reporting Content ID\\'].unique().tolist())) | (df[\\'Hitpath Offer ID\\']==6272)]\\ndf2 = df1.groupby([\\'Creative Type\\'])[\\'Date\\'].count().reset_index(name = \"count\")\\ntemp = df2[df2[\\'count\\'] == 1].merge(lanina[[\\'Reporting Content ID\\',\\'OfferIDs\\',\\'Content Approval Status\\',\\'Offer Status\\']], left_on = \\'Creative Type\\',right_on = \\'Reporting Content ID\\', how = \\'left\\', copy = False).drop_duplicates().sort_values(\\'OfferIDs\\', ascending = False).drop(columns = [\\'Reporting Content ID\\']).reset_index(drop = True)\\ntemp = temp[temp[\\'Offer Status\\'] == \\'Passed Test - In Production\\']\\ntemp.to_csv(\\'/Users/liliguo/Desktop/passed_content.csv\\', index = False) \\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "passed_content = lanina[lanina['Content Approval Status'].str.contains(\"Approved - Passed\")]\n",
    "df1 = df[(df['Creative Type'].isin(passed_content['Reporting Content ID'].unique().tolist())) | (df['Hitpath Offer ID']==6272)]\n",
    "df2 = df1.groupby(['Creative Type'])['Date'].count().reset_index(name = \"count\")\n",
    "temp = df2[df2['count'] == 1].merge(lanina[['Reporting Content ID','OfferIDs','Content Approval Status','Offer Status']], left_on = 'Creative Type',right_on = 'Reporting Content ID', how = 'left', copy = False).drop_duplicates().sort_values('OfferIDs', ascending = False).drop(columns = ['Reporting Content ID']).reset_index(drop = True)\n",
    "temp = temp[temp['Offer Status'] == 'Passed Test - In Production']\n",
    "temp.to_csv('/Users/liliguo/Desktop/passed_content.csv', index = False) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def content_schedule(sc_dppub_affiliate, days_ahead, update_bool = False): \n",
    "    lyst = [] \n",
    "    \n",
    "    for i in range(1,math.ceil(days_ahead/7)+1):\n",
    "        lyst.append(i*7)\n",
    "    for days_ahead in lyst:  \n",
    "        begin_day = days_ahead-7\n",
    "        gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "        cobra_google_sheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1186670009')\n",
    "        cobra_sheet =  cobra_google_sheet.worksheet('title','New Mamba')\n",
    "        cobra = infrastructure.get_mamba_full_slot()\n",
    "        cobra_sheet_df = cobra_sheet.get_as_df()\n",
    "        cobra_sheet_df.columns=cobra_sheet_df.iloc[0]\n",
    "        \n",
    "        sc = sc_dppub_affiliate.split('_')[0]\n",
    "        dppub = sc_dppub_affiliate.split('_')[1]\n",
    "        pubid = sc_dppub_affiliate.split('_')[2]\n",
    "        sc_dppub = sc + \"_\" + dppub\n",
    "        past_content = cobra[(cobra['Dataset']==sc_dppub_affiliate)& (cobra['Date'].dt.date>=date.today()-timedelta(days=4)) & (cobra['Creative']!='') ][['Date','Creative']]\n",
    "        past_content['Creative'] = past_content['Creative'].str.split('\\n')\n",
    "        past_content_explode = past_content.explode('Creative')\n",
    "        content_df=cobra[(cobra['Dataset']==sc_dppub_affiliate)& (cobra['Date'].dt.date>=date.today()+timedelta(days=begin_day)) &\n",
    "                                    (cobra['Date'].dt.date<=date.today()+timedelta(days=days_ahead))]\n",
    "                # set row 1 as column \n",
    "                #\n",
    "        \n",
    "        days=pd.to_datetime(content_df['Date'].unique())\n",
    "\n",
    "        drops=['Drop 1','Drop 2','Drop 3','Drop 4','Drop 5','Drop 6']\n",
    "        cols=['Time','Segment ','Send Strategy','Offer','Limit',\n",
    "                    'Offset','Creative','Job Name','Blank']\n",
    "\n",
    "        write_dict={}\n",
    "        \n",
    "        for index,day in enumerate(pd.to_datetime(content_df['Date'].unique()).strftime('%D')):\n",
    "            for drop in drops:\n",
    "                for col in cols:\n",
    "                    if len(content_df[(content_df[\"Drop\"]==drop) & (content_df['Date']==day)])>0:\n",
    "                        if col == 'Blank':\n",
    "                            write_dict[(drop,col)] = ''\n",
    "                        else: \n",
    "                            write_dict[(drop,col)] = content_df[(content_df[\"Drop\"]==drop) & (content_df['Date']==day)][col].values[0]\n",
    "                        if col == 'Offer' and write_dict[(drop,col)] != '':\n",
    "                            offer = write_dict[(drop,col)]\n",
    "                            direct = \"DIR\" in offer\n",
    "                            hitpath = write_dict[(drop,col)].split(' ')[0]\n",
    "                        if col == 'Creative' and write_dict[(drop,col)] == '' and write_dict[(drop,'Offer' )] != '':\n",
    "                            past_content_list = past_content_explode[(past_content_explode['Date']<pd.to_datetime(day)) & (past_content_explode['Date']>=pd.to_datetime(day)-timedelta(days=4))]['Creative'].tolist()\n",
    "                            content = content_select(df,sc,pubid,hitpath,past_content_list,direct)[2]\n",
    "                            write_dict[(drop,col)] = content\n",
    "                            for i in content.split('\\n'):\n",
    "                                # Convert the new data to a DataFrame\n",
    "                                new_row = pd.DataFrame([{'Date': pd.to_datetime(day), 'Creative': i}])\n",
    "                                # Use pd.concat to append the new data\n",
    "                                past_content_explode = pd.concat([past_content_explode, new_row], ignore_index=True)\n",
    "                        if col == 'Job Name' and write_dict[(drop,col)] == '' and write_dict[(drop,'Offer' )] != '':\n",
    "                                date1 = datetime.strptime(day, \"%m/%d/%y\").strftime(\"%d%b%y\")  \n",
    "                                #Format: SS_HZB_TLG-PL-30DC-VZN_12386_P_21Oct23    \n",
    "                                write_dict[(drop,col)] =   \"SS_\"+write_dict[(drop,'Segment ')][:3] + \"_\"+write_dict[(drop,'Segment ')][4:].replace(\".\",'-').replace(\"_\",'-')+\"_\"+ write_dict[(drop,'Offer')].split(' ')[0] +\"_\"+ write_dict[(drop,'Send Strategy')] + \"_\" +   date1       \n",
    "\n",
    "                    else:\n",
    "                        write_dict[(drop,col)] = ''\n",
    "\n",
    "            if index==0:\n",
    "                write_df = pd.DataFrame(write_dict,index=[day]).T\n",
    "                write_df1 = pd.DataFrame(write_dict,index=[day]).T\n",
    "\n",
    "            else:\n",
    "                write_df_new = pd.DataFrame(write_dict,index=[day]).T\n",
    "                write_df = pd.concat([write_df,write_df_new],axis=1)\n",
    "\n",
    "            #write_df=write_df.replace(np.nan,'')\n",
    "        if update_bool == True:\n",
    "                    \n",
    "            cobra_row = int(cobra_sheet_df[cobra_sheet_df['Dataset'].str.contains(sc_dppub_affiliate)].index.values[0]+3)\n",
    "            if len(content_df) >0:\n",
    "                date_string = content_df['Date'].dt.date.values[0].strftime('%-m/%-d/%Y')\n",
    "                #3.11.5 python version accept this: date_string = content_df['Date'].dt.date.values[0].strftime('%#m/%#d/%Y')\n",
    "                cobra_column = cobra_sheet_df.columns.get_loc(date_string)+1\n",
    "                cobra_sheet.set_dataframe(start=(cobra_row,cobra_column),df=write_df,copy_head=False,nan='')\n",
    "                \n",
    "        else: \n",
    "            return write_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offer eCPM for Other Accounts:  nan\n",
      "Offer eCPM for Affiliate Account:  nan\n",
      "Offer median eCPM:  nan\n",
      "No content available from content selection script, we choose 2 random content from Lanina\n",
      "13238.TF.MFA.454341\n",
      "13238.TF.MFA.454343\n",
      "['MyFam: Want to pay less for household repairs, {{coalesce|first_name|starting now}}?\\n\\nCheck out these offers: {{offer_target_url}}\\n\\nSTOP to end', 'MyFam: {{coalesce|first_name|Congrats}}, we found home warranty plans in {{coalesce|City|your area}}.\\n\\nView here: {{offer_target_url}}\\n\\nSTOP to end']\n"
     ]
    }
   ],
   "source": [
    "#sc_dppub_affiliates = ['HZB_CM.OSR_461452','MBC_CM.OSR_461452','SVT_AMD.PL_461810','HZB_AMD.PL_461810','SVT_AL.PL.3_461838','HZB_AL.PL.3_461838','DSS_TLG.PL_461768','HZB_TLG.PL_461768','MBC_WWM.YFA.2_461680','FLC_WWM.YFA.2_461680','DSS_SM.SRV_461896','HZB_SM.SRV_461896'] #the sc_dppub_affiliate for which to schedule (list of strings)\n",
    "sc_dppub_affiliates =  [\n",
    "    \"FLC_I.CC_460918\", \"MBC_I.CC_460918\", \"FLC_SPK.CR_460921\",\n",
    "    \"MBC_SPK.CR_460921\", \"FLC_AI.CC_460939\", \"MBC_AI.CC_460939\", \"HZB_RHD.CC_461263\",\n",
    "    \"DSS_RHD.CC_461263\",\"UAA_SPK.CR2_461842\",\"UAATF_SPK.CR2_461842\",\"MBC_PN.FC_461653\",\"FLC_PN.FC_461653\",\n",
    "    \"SVT_AL.PL_461794\",\"HZB_AL.PL_461794\",\"SVT_AL.PL.2_461795\",\"HZB_AL.PL.2_461795\",\n",
    "    \"DSS_JET.ZTA_461835\",\"FLC_JET.ZTA_461835\", \"FLC_SPK.CR2_461842\",\"MBC_PN.SWP_461500\", \"FLC_PN.SWP_461500\", 'FLC_EDM.247L_461227','MBC_EDM.247L_461227']\n",
    "# sc_dppub_affiliates = ['SVT_AL.PL.2_461795']\n",
    "#sc_dppub_affiliates = ['MFA_I.MFA_461871']\n",
    "days_ahead = 20\n",
    "update_bool = True \n",
    "\n",
    "for sc_dppub_affiliate in sc_dppub_affiliates: \n",
    "    try:\n",
    "        content_schedule(sc_dppub_affiliate, days_ahead, update_bool)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with {sc_dppub_affiliate}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check recent content body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Creative</th>\n",
       "      <th>Reporting Content ID</th>\n",
       "      <th>Content Approval Status</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>102.TF.MFA.453992</td>\n",
       "      <td>102.TF.MFA.453992</td>\n",
       "      <td>Paused - Others</td>\n",
       "      <td>MyFam: {{coalesce|first_name|Congrats}}, a credit card offer is available as of {{today_mm_dd_yy}}.\\n\\nView here: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>103.TF.MFA.454012</td>\n",
       "      <td>103.TF.MFA.454012</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: You’re eligible on {{today_mm_dd_yy}} to request financial relief.\\n\\nRequest an e-deposit now: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>TF.MFA.453582</td>\n",
       "      <td>TF.MFA.453582</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: Here is the guide you requested! Access now: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>104.SC.MFA.454212</td>\n",
       "      <td>104.SC.MFA.454212</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: Review your {{today_month}} home coverage offer on {{today_mm_dd_yy}} before it expires: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>103.TF.MFA.454012</td>\n",
       "      <td>103.TF.MFA.454012</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: You’re eligible on {{today_mm_dd_yy}} to request financial relief.\\n\\nRequest an e-deposit now: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-05-27</td>\n",
       "      <td>13194.TF.MFA.454343</td>\n",
       "      <td>13194.TF.MFA.454343</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: {{max_length|14||first_name|Hey}}, we processed your e-deposit request on {{today_mm_dd_yy}}.\\n\\nGet instant relief today: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-05-27</td>\n",
       "      <td>13194.TF.MFA.454345</td>\n",
       "      <td>13194.TF.MFA.454345</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: Check your family’s newest relief opportunities as of {{today_mm_dd_yy}}: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>12972.TF.MFA.454271</td>\n",
       "      <td>12972.TF.MFA.454271</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: You received a grant request for free federal relief on {{today_mm_dd_yy}}.\\n\\nApply now: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>13253.TF.MFA.454252</td>\n",
       "      <td>13253.TF.MFA.454252</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: Access granted - open your credit card options, {{coalesce|first_name|instantly}}.\\n\\nIt takes just 30 seconds: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>13253.TF.MFA.454251</td>\n",
       "      <td>13253.TF.MFA.454251</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: You’re invited on {{today_mm_dd_yy}} to access card offers of up to 5,000.\\n\\nGet Started: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>104.SC.MFA.454212</td>\n",
       "      <td>104.SC.MFA.454212</td>\n",
       "      <td>Live</td>\n",
       "      <td>MyFam: Review your {{today_month}} home coverage offer on {{today_mm_dd_yy}} before it expires: {{offer_target_url}}\\n\\nSTOP to end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date             Creative Reporting Content ID  \\\n",
       "0  2024-05-20    102.TF.MFA.453992    102.TF.MFA.453992   \n",
       "1  2024-05-21    103.TF.MFA.454012    103.TF.MFA.454012   \n",
       "2  2024-05-22        TF.MFA.453582        TF.MFA.453582   \n",
       "3  2024-05-23    104.SC.MFA.454212    104.SC.MFA.454212   \n",
       "4  2024-05-24    103.TF.MFA.454012    103.TF.MFA.454012   \n",
       "5  2024-05-27  13194.TF.MFA.454343  13194.TF.MFA.454343   \n",
       "6  2024-05-27  13194.TF.MFA.454345  13194.TF.MFA.454345   \n",
       "7  2024-05-29  12972.TF.MFA.454271  12972.TF.MFA.454271   \n",
       "8  2024-05-30  13253.TF.MFA.454252  13253.TF.MFA.454252   \n",
       "9  2024-05-30  13253.TF.MFA.454251  13253.TF.MFA.454251   \n",
       "10 2024-05-31    104.SC.MFA.454212    104.SC.MFA.454212   \n",
       "\n",
       "   Content Approval Status  \\\n",
       "0          Paused - Others   \n",
       "1                     Live   \n",
       "2                     Live   \n",
       "3                     Live   \n",
       "4                     Live   \n",
       "5                     Live   \n",
       "6                     Live   \n",
       "7                     Live   \n",
       "8                     Live   \n",
       "9                     Live   \n",
       "10                    Live   \n",
       "\n",
       "                                                                                                                                                                  Content  \n",
       "0                   MyFam: {{coalesce|first_name|Congrats}}, a credit card offer is available as of {{today_mm_dd_yy}}.\\n\\nView here: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "1                              MyFam: You’re eligible on {{today_mm_dd_yy}} to request financial relief.\\n\\nRequest an e-deposit now: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "2                                                                                 MyFam: Here is the guide you requested! Access now: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "3                                     MyFam: Review your {{today_month}} home coverage offer on {{today_mm_dd_yy}} before it expires: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "4                              MyFam: You’re eligible on {{today_mm_dd_yy}} to request financial relief.\\n\\nRequest an e-deposit now: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "5   MyFam: {{max_length|14||first_name|Hey}}, we processed your e-deposit request on {{today_mm_dd_yy}}.\\n\\nGet instant relief today: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "6                                                    MyFam: Check your family’s newest relief opportunities as of {{today_mm_dd_yy}}: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "7                                    MyFam: You received a grant request for free federal relief on {{today_mm_dd_yy}}.\\n\\nApply now: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "8              MyFam: Access granted - open your credit card options, {{coalesce|first_name|instantly}}.\\n\\nIt takes just 30 seconds: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "9                                   MyFam: You’re invited on {{today_mm_dd_yy}} to access card offers of up to 5,000.\\n\\nGet Started: {{offer_target_url}}\\n\\nSTOP to end  \n",
       "10                                    MyFam: Review your {{today_month}} home coverage offer on {{today_mm_dd_yy}} before it expires: {{offer_target_url}}\\n\\nSTOP to end  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all content from the column \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "sc_dppub_affiliate = 'MFA_I.MFA_461871'\n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "cobra_google_sheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1186670009')\n",
    "cobra_sheet =  cobra_google_sheet.worksheet('title','New Mamba')\n",
    "cobra = infrastructure.get_mamba_full_slot()\n",
    "past_content = cobra[(cobra['Dataset']==sc_dppub_affiliate)& (cobra['Date'].dt.date>=date.today()-timedelta(days=4)) & (cobra['Creative']!='') ][['Date','Creative']]\n",
    "past_content['Creative'] = past_content['Creative'].str.split('\\n')\n",
    "past_content_explode = past_content.explode('Creative')\n",
    "past_content_explode.merge(lanina[['Reporting Content ID','Content Approval Status','Content']], how = 'left', left_on = 'Creative', right_on = 'Reporting Content ID', copy = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
