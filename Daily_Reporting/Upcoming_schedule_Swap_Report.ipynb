{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cf0744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liliguo/Desktop/SMS-NewData/\n"
     ]
    }
   ],
   "source": [
    "# Check your current folder:\n",
    "import filepath \n",
    "local_folder = filepath.output_folder \n",
    "print(local_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2ec3a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:53:37.126372Z",
     "start_time": "2023-08-10T15:53:24.959772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import infrastructure \n",
    "import pygsheets\n",
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime as dt \n",
    "import send_email \n",
    "\n",
    "\n",
    "# import publisher information \n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "rxmgref = gc.open_by_url('https://docs.google.com/spreadsheets/d/1Tzda6Djr3zQmOhWu7Ief3GVR9Cjaml8238CeX7chj_U/edit#gid=1620368362') \n",
    "publisher  = rxmgref.worksheet('title','Publisher Configurations').get_as_df()\n",
    "\n",
    "# import offer sheet \n",
    "offer_sms = infrastructure.get_smartsheet('offers_sms')\n",
    "offer_sms = offer_sms[offer_sms['Hitpath ID'].isna() == False]\n",
    "# import offer sheet from email \n",
    "offer_email_raw_data=infrastructure.get_smartsheet('offers_email')\n",
    "offer_email=offer_email_raw_data[['Hitpath Offer ID','Scheduling Name','Operational Status','Payout']]\n",
    "offer_email_raw_data = offer_email_raw_data.add_suffix(' from email')\n",
    "\n",
    "# import mamba \n",
    "mamba = gc.open_by_url('https://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=534096291') \n",
    "new_mamba  = mamba.worksheet('title','New Mamba')\n",
    "schedule = new_mamba.get_as_df()\n",
    "\n",
    "# define today \n",
    "today = pd.to_datetime(dt.datetime.today())\n",
    "\n",
    "# get holiday restriction list \n",
    "holiday_dict = {}\n",
    "def holiday_restriction(url): \n",
    "    holiday_restriction = gc.open_by_url(url)\n",
    "    holiday_restriction_sheet  = holiday_restriction.worksheet('title','SMS Drop Restrictions')\n",
    "    holiday_restriction_df = holiday_restriction_sheet.get_as_df()\n",
    "    holiday_restriction_df.columns = holiday_restriction_df.iloc[3]\n",
    "    holiday_restriction_df1= holiday_restriction_df.iloc[4:]\n",
    "    temp = holiday_restriction_df1.set_index('HitPath ID').iloc[:,4:]\n",
    "    for i in temp.columns:\n",
    "        df_for_date = temp[i]\n",
    "        df_for_date1 = df_for_date[df_for_date.str.upper()=='NO DROPS']\n",
    "        i = pd.to_datetime(i)\n",
    "        holiday_dict[i] = df_for_date1.index.tolist()\n",
    "    return holiday_dict\n",
    "holiday_dict = holiday_restriction('https://docs.google.com/spreadsheets/d/1RuZloAnwCDWQjn5GuRAyEtLoBtQtmiF1nsdJF-ArXYw/edit#gid=0')\n",
    "holiday_dict = holiday_restriction('https://docs.google.com/spreadsheets/d/1USZQ_CIpfEV-NDH8K9oVy-hy3cTh4uaD0SuksRCtEq8/edit#gid=1068286208')\n",
    "\n",
    "\n",
    "\n",
    "# La nina \n",
    "lanina = gc.open_by_url('https://docs.google.com/spreadsheets/d/1obszkCQoE0ELOR1O0CrLVETUEmEIWlGuyAmK3FgWSJg/edit#gid=1060654066')\n",
    "lanina_sheet =  lanina.worksheet('title','La Nina (Current)')\n",
    "lanina_df = lanina_sheet.get_as_df()\n",
    "\n",
    "# DA payout \n",
    "dapayout = gc.open_by_url('https://docs.google.com/spreadsheets/d/1iUxuhBWag0Pamg-GVLpfiJo-ENc2AQzdw3uYhAXVEcQ/edit#gid=1010710644')\n",
    "offer9287 =  dapayout.worksheet('title','Endurance').get_as_df()\n",
    "offer9287.columns = offer9287.iloc[0].reset_index()[0].tolist()\n",
    "offer9287 = offer9287[1:]\n",
    "offer7878 =  dapayout.worksheet('title','ADT').get_as_df()\n",
    "offer7878.columns = offer7878.iloc[0].reset_index()[0].tolist()\n",
    "offer7878 = offer7878[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943b5e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether there's any duplicated  CCID in La Nina \n",
    "lanina_df[lanina_df['Reporting Content ID'].duplicated()]['Reporting Content ID'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee50a53",
   "metadata": {},
   "source": [
    "# Update in La Nina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e277760f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:53:38.783102Z",
     "start_time": "2023-08-10T15:53:37.134467Z"
    }
   },
   "outputs": [],
   "source": [
    "offer_sms_merge = offer_sms[['Hitpath ID','Status','Vertical']].drop_duplicates()\n",
    "lanina1  = lanina_df.merge(offer_sms_merge[['Hitpath ID','Status','Vertical']], how = 'left',  left_on = 'OfferIDs',right_on ='Hitpath ID',copy = False )\n",
    "lanina1\n",
    "lanina1['Status'] = lanina1['Status'].fillna('')\n",
    "offer_status_list = ['Offer Status'] +  lanina1['Status'].tolist()\n",
    "lanina_sheet.update_col(21, offer_status_list)\n",
    "lanina1['Vertical'] = lanina1['Vertical'].fillna('')\n",
    "offer_vertical_list = ['Offer Vertical'] +  lanina1['Vertical'].tolist()\n",
    "lanina_sheet.update_col(22, offer_vertical_list)\n",
    "# Define the condition and new value\n",
    "condition_column_index = 4 # Index of the column containing the condition\n",
    "condition_value = 'Approved - Pipeline Testing'  # Condition to match in the column\n",
    "condition_column_index_2 = 21\n",
    "condition_value_2 = 'Passed Test - In Production'\n",
    "target_column_index = 4 # Index of the column to update\n",
    "new_value = 'Approved - Passed'  # New value to update\n",
    "\n",
    "\n",
    "# Iterate over dataframe\n",
    "for index, row in lanina1.iterrows():\n",
    "    # Check your condition\n",
    "    if (row['Content Approval Status'].strip() == 'Pending') & ((row['Status'] == condition_value_2) |(row['Status'] == 'Passed Test - Dupe Bucket')  ):\n",
    "        # access Data using \n",
    "        cell = lanina_sheet.cell((index+2, 4))\n",
    "        cell.value = 'Approved - Passed' \n",
    "        cell.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fbde2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11891']\n"
     ]
    }
   ],
   "source": [
    "rxpcontent_sheet = lanina.worksheet('title','La Nina for RXP ETL')\n",
    "rxpcontent = lanina_sheet.get_as_df()\n",
    "\n",
    "#\n",
    "flc_url = \"https://cf.freedomlender.co/\"\n",
    "mbc_url = \"https://cf.mybenefitsclub.com/\"\n",
    "dss_url = \"https://members.dollar-sensei.com/\"\n",
    "hzb_url = \"https://cf.horizonbenefits.org/\"\n",
    "uaa_url = \"https://members.unitedamericanalliance.com/\"\n",
    "svt_url = \"https://members.solvent.tools/\"\n",
    "prc_url = \"https://members.parentsresourceconnection.co/\"\n",
    "rxp_network_offer_id = pd.read_csv(\"/Users/liliguo/Desktop/SMS offer id & network offer id.csv\")\n",
    "rxp_network_offer_id['Hitpath ID'] = rxp_network_offer_id['meta_data'].str.extract( '(\\d+)')\n",
    "rxp_network_offer_id['network_offer_id'] = rxp_network_offer_id['network_offer_id'].str.extract( '(\\d+)')\n",
    "\n",
    "\n",
    "# change int to str \n",
    "rxpcontent['OfferIDs']  = rxpcontent['OfferIDs'].astype(str).str.replace('.0','')\n",
    "rxp_network_offer_id['network_offer_id']  = rxp_network_offer_id['network_offer_id'].astype(str).str.replace('.0','')\n",
    "rxp_network_offer_id['Hitpath ID'] = rxp_network_offer_id['Hitpath ID'].astype(str).str.replace('.0','')\n",
    "\n",
    "# merge table \n",
    "rxpcontent = rxpcontent.merge(rxp_network_offer_id[['Hitpath ID','network_offer_id']] , how = 'left', left_on = 'OfferIDs', right_on = 'Hitpath ID',copy = False)\n",
    "# production offer wasn't shown in the rxp \n",
    "#rxpcontent['network_offer_id'] = rxpcontent['network_offer_id'].fillna('')\n",
    "rxpcontent.loc[rxpcontent['Hitpath ID'].isna() == False, 'network_offer_id' ] = rxpcontent['network_offer_id'].astype(str).str.replace('nan','')\n",
    "rxpcontent['Hitpath ID'] = rxpcontent['Hitpath ID'].fillna('')\n",
    "# offer we couldn't find in rxp\n",
    "off_hit = offer_sms['Hitpath ID'].astype(str).str.split(\".\",expand=True)[0].tolist()\n",
    "print(rxpcontent[(rxpcontent['network_offer_id'].isna())&(rxpcontent['Offer Status'].isin(['Passed Test - In Production','Passed Test - Dupe Bucket'])) & (rxpcontent['OfferIDs'].isin(off_hit)) ]['OfferIDs'].unique())\n",
    "rest_url =  \"o/?cfid=\"+rxpcontent['OfferIDs'] + \"&oid=\"+rxpcontent['network_offer_id'] +\"&emailaddress={{emailaddress}}&firstname={{firstname}}&lastname={{lastname}}&phonenumbermobile={{phonenumbermobile}}&cityname={{cityname}}&postalzipcode={{postalzipcode}}\"\n",
    "\n",
    "\n",
    "\n",
    "rxpcontent['Offer Target URL']  = ''\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'FLC')& (rxpcontent['Channel'] == 'SC') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = flc_url + rest_url\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'MBC')& (rxpcontent['Channel'] == 'SC') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = mbc_url + rest_url\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'DSS')& (rxpcontent['Channel'] == 'SC') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = dss_url + rest_url\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'HZB')& (rxpcontent['Channel'] == 'SC') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = hzb_url + rest_url\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'UAA')& (rxpcontent['Channel'] == 'SC') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = uaa_url + rest_url\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'SVT')& (rxpcontent['Channel'] == 'SC') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = svt_url + rest_url\n",
    "rxpcontent.loc[(rxpcontent['Type'] == 'PRC')& (rxpcontent['Channel'] == 'TF') & (rxpcontent['network_offer_id'].isna() == False), 'Offer Target URL'] = prc_url + rest_url\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578c13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rxpcontent['Offer Target URL'].unique()\n",
    "pattern = r'({{.*?}})'\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content']\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace(r'{{.*?\\|First_name\\|.*?}}','{{First_name}}',regex = True)\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace(r'{{.*?\\|first_name\\|.*?}}','{{first_name}}',regex = True)\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace(r'{{.*?\\|city\\|.*?}}','{{city}}',regex = True)\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace(r'{{.*?\\|region\\|.*?}}','{{region}}',regex = True)\n",
    "#rxpcontent['Content'].str.extractall(pattern)[0].unique()\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace(r'{{region}}|{{Region}}','%%provincestatename%%',regex = True)\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace(r'{{first_name}}|{{First_name}}','%%first_name%%',regex = True)\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{today_month}}','%%date:F|today%%')\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{today_dd_mm_yy}}','%%date:d-m-y|today%%')\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{city}}','%%cityname%%')\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{today_mm_dd_yy}}','%%date:m-d-y|today%%')\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{tomorrow_month}}','%%date:F|tomorrow%%')\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{tomorrow_mon_dd_yy}}','%%date:M, d Y|tomorrow%%')\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('{{random|Erica|Ally|Tom|Grant|Mark|Julie}}','Tom')\n",
    "\n",
    "# replace the stop to end with \"\"\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].str.replace('STOP to end','')\n",
    "rxpcontent['Content_rxp'].str.extractall(pattern)[0].unique()\n",
    "\n",
    "rxpcontent['Content_rxp'] = rxpcontent['Content_rxp'].astype('str')\n",
    "rxpcontent['Offer Target URL'] = rxpcontent['Offer Target URL'].fillna('')\n",
    "rxpcontent['Offer Target URL'] = rxpcontent['Offer Target URL'].astype('str')\n",
    "# Function to replace the text\n",
    "def replace_target_url(row):\n",
    "    if (row['Offer Target URL'] != '') & (row['Offer Target URL'] != np.nan):\n",
    "        return row['Content_rxp'].replace('{{offer_target_url}}', row['Offer Target URL'])\n",
    "    return ''\n",
    "\n",
    "    \n",
    "rxpcontent['Content_rxp_with_url'] = rxpcontent.apply(replace_target_url, axis=1)\n",
    "rxpcontent = rxpcontent.drop(columns = ['Drop Count','Content_rxp'])\n",
    "rxpcontent = rxpcontent[['index', 'Reporting Content ID', 'Long Code Content ID',\n",
    "       'Content Approval Status', 'Content Status in Platform', 'Type (Pitch)',\n",
    "       'OfferIDs', 'Advertiser', 'OfferAbbrv', 'Channel', 'Platform', 'Type',\n",
    "       'Allocation Period (Date Added)', 'Piece Number', 'Copywriter',\n",
    "       'Date Restrictions', 'Character Count', 'Content','Content_rxp_with_url', 'Review by SMS Team',\n",
    "       'Link & \"STOP to end\"', 'Offer Status', 'Offer Vertical', 'Hitpath ID',\n",
    "       'network_offer_id', 'Offer Target URL']]\n",
    "rxpcontent_sheet.set_dataframe(rxpcontent, start='A1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5981402a",
   "metadata": {},
   "source": [
    "# Update Offer Status in SMS Jump Page Content Review Google Sheet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e86357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsmsjumppage = gc.open_by_url('https://docs.google.com/spreadsheets/d/1e8p1LMr4-StJWTF0BK0cwQzSwNLsVSFeRUD1h5pMwfA/edit#gid=1132279237')\\nsmsjumppage_sheet = smsjumppage.worksheet('title','offers-cf')\\nsmsjumppage_df = smsjumppage_sheet.get_as_df()\\nsmsjumppage_df['sid'] = smsjumppage_df['sid'].astype('str').str.split('.',expand = True)[0]\\nsmsjumppage_df1 = smsjumppage_df.merge(offer_sms[['Hitpath ID','Status']], how = 'left',  left_on = 'sid',right_on ='Hitpath ID',copy = False )\\n\\nsmsjumppage_df1['Status'] = smsjumppage_df1['Status'].fillna('')\\noffer_status_list_jumppage  = ['Offer Status'] +  smsjumppage_df1['Status'].tolist()\\nsmsjumppage_sheet.update_col(2, offer_status_list_jumppage)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "smsjumppage = gc.open_by_url('https://docs.google.com/spreadsheets/d/1e8p1LMr4-StJWTF0BK0cwQzSwNLsVSFeRUD1h5pMwfA/edit#gid=1132279237')\n",
    "smsjumppage_sheet = smsjumppage.worksheet('title','offers-cf')\n",
    "smsjumppage_df = smsjumppage_sheet.get_as_df()\n",
    "smsjumppage_df['sid'] = smsjumppage_df['sid'].astype('str').str.split('.',expand = True)[0]\n",
    "smsjumppage_df1 = smsjumppage_df.merge(offer_sms[['Hitpath ID','Status']], how = 'left',  left_on = 'sid',right_on ='Hitpath ID',copy = False )\n",
    "\n",
    "smsjumppage_df1['Status'] = smsjumppage_df1['Status'].fillna('')\n",
    "offer_status_list_jumppage  = ['Offer Status'] +  smsjumppage_df1['Status'].tolist()\n",
    "smsjumppage_sheet.update_col(2, offer_status_list_jumppage)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d656a79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:53:43.099133Z",
     "start_time": "2023-08-10T15:53:39.279225Z"
    }
   },
   "source": [
    "# Upcoming Schedule "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4002cacc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:53:43.130363Z",
     "start_time": "2023-08-10T15:53:43.115898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/infrastructure.py:60: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  schedule2['Date']=pd.to_datetime(schedule2[0],errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "snakes = infrastructure.get_mamba()\n",
    "snakes['PUBID'] = snakes['Dataset'].str.split('_',expand = True)[2].astype(int)\n",
    "All_merge = snakes.merge(publisher[['PUBID','Sub Vertical','DMA']], how = 'left', copy = False)\n",
    "All_merge = All_merge[(All_merge['Date'] > today) ]\n",
    "All_merge = All_merge.sort_values(['Date','DMA','Sub Vertical','PUBID','Shortcode','Drop'])\n",
    "upcoming_schedule_mamba = All_merge[['Date','DMA','Sub Vertical','PUBID','Dataset','Drop', 'Time', 'Segment ', 'Send Strategy', 'Offer',\n",
    "       'Creative', 'Job Name']]\n",
    "\n",
    "upcoming_schedule_mamba.to_csv('upcoming_schdule.csv',index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a14dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:54:25.621558Z",
     "start_time": "2023-08-10T15:53:43.130615Z"
    }
   },
   "outputs": [],
   "source": [
    "upcomingschedule = mamba.worksheet('title','Upcoming Schedule')\n",
    "upcomingschedule.clear()\n",
    "upcomingschedule.set_dataframe(upcoming_schedule_mamba,(1,1))\n",
    "upcomingschedule.cell('A1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('B1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('C1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('D1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('E1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('F1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('G1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('H1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('I1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('J1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('K1').set_text_format('bold', True)\n",
    "upcomingschedule.cell('L1').set_text_format('bold', True)\n",
    "upcomingschedule.add_conditional_formatting('C1', 'C1000', 'TEXT_CONTAINS', {'backgroundColor':{'red': 0.72, 'green': 0.64, 'blue': 0.81}}, ['Personal Loan'])\n",
    "upcomingschedule.add_conditional_formatting('C1', 'C1000', 'TEXT_CONTAINS', {'backgroundColor':{'red': 0.95, 'green': 0.75, 'blue': 0.41}}, ['Sweepstakes'])\n",
    "upcomingschedule.add_conditional_formatting('C1', 'C1000', 'TEXT_CONTAINS', {'backgroundColor':{'red': 0.64, 'green': 0.72, 'blue': 0.81}}, ['Rent To Own'])\n",
    "upcomingschedule.add_conditional_formatting('C1', 'C1000', 'TEXT_CONTAINS', {'backgroundColor':{'red': 0.63, 'green': 0.85, 'blue': 0.73}}, ['Credit Card'])\n",
    "upcomingschedule.add_conditional_formatting('C1', 'C1000', 'TEXT_CONTAINS', {'backgroundColor':{'red': 0.95, 'green': 0.94, 'blue': 0.64}}, ['Financial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7967d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:54:33.808574Z",
     "start_time": "2023-08-10T15:54:25.655548Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Special Payout from Email'] = ''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Special Pub Payouts'] = offer['Special Pub Payouts'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Special Payout Alert'] = ''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Paused Alert'] =  ''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Payout Alert'] = ''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['SMS_payout_rate'] = offer['$ Payout'].str.extract(r'([\\d\\.]+)').astype(float)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['SMS_new_payout_rate'] = offer['New Payout'].str.extract(r'([\\d\\.]+)').astype(float)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Email_payout_rate'] = offer['Payout from email'].str.extract(r'([\\d\\.]+)').astype(float)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Payout Alert'] = ''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Paused Pubids list'] = offer['Paused PubIDs from email'].str.split('\\n|\\t|,|\"| ')\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['SMS current Paused Pubids list'] = offer['Paused Pubs'].str.split('\\n|\\t|,|\"| ')\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['SMS current Paused Pubids list'] = offer['SMS current Paused Pubids list'].apply(lambda x: sorted(x) if isinstance(x, (list, tuple))  else list())\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Update Needed in SMS: Paused Pubids'] = offer['Paused Pubids list'].apply(lambda x: sorted(list(set(list(x)) & set(sms_live_pubid))) if isinstance(x, (list, tuple))  else list())\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Update Needed in SMS: Paused Pubids'] = offer['Update Needed in SMS: Paused Pubids'].apply(lambda x: [int(i) for i in x if i != ''])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['SMS current Paused Pubids list'] = offer['SMS current Paused Pubids list'].apply(lambda x: [int(i) for i in x if i != ''])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Update Needed in SMS: Paused Pubids'] = offer['Update Needed in SMS: Paused Pubids'].apply(lambda x: '' if x == list() else x)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Update Needed in SMS: Paused Pubids'] = offer['Update Needed in SMS: Paused Pubids'].apply(lambda x: '\\n'.join(map(str, x)))\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Day Parting from Email'] = offer['Day Restrictions from email'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x ) + ' ' + offer['Drop Time Restrictions from email'].apply(lambda x: \"\" if x == 'None'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Day Parting'] = offer['Day Parting'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Day Parting Alert'] = ''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Budget Alert'] =''\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Cap from email1'] = offer['Cap from email'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Cap1'] = offer['Cap'].apply(lambda x: \"\" if x == 'No Cap'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['New Cap Budget1'] = offer['New Cap Budget'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Budget from email1'] = offer['Budget from email'].apply(lambda x: \"\" if x == 'None'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Cap Budget1'] = offer['Cap Budget'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_1974/3189346744.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  offer['Budget from email2'] = offer['Budget from email1'].str.extract(r'(\\d+)')\n"
     ]
    }
   ],
   "source": [
    "same_offer_from_email = offer_sms[['Hitpath ID','Scheduling Name','Email Offer ID','Status','$ Payout','New Payout','Paused Pubs','Special Pub Payouts','Day Parting','Cap', 'Cap Budget','New Cap Budget']].merge(offer_email_raw_data[['Hitpath Offer ID from email','Scheduling Name from email','Operational Status from email','Payout from email','Paused PubIDs from email','Day Restrictions from email','Drop Time Restrictions from email','Budget from email', 'Cap from email']],left_on='Email Offer ID', right_on = 'Hitpath Offer ID from email', how = 'inner')\n",
    "same_offer_from_email['Hitpath ID'] = same_offer_from_email['Hitpath ID'].astype(str).str.split('.',expand = True)[0]\n",
    "#offer_sms['Email Offer ID'] = offer_sms['Email Offer ID'].astype(str).str.split('.',expand = True)[0]\n",
    "email_list = offer_sms['Email Offer ID'].unique().tolist()\n",
    "email_list = [x for x in email_list if x !='nan']\n",
    "sms_live_pubid = publisher['PUBID'].astype(str).unique().tolist()\n",
    "# special payout for 9287 and 7878 \n",
    "offer9287['PUBID'] = offer9287['PUBID'].astype(str).str.split(\".\",expand = True)[0]\n",
    "sp9287 = offer9287.loc[(offer9287['STATUS'] == 'Live') & (offer9287['PUBID'].astype(str).isin(sms_live_pubid)) ,][['PUBID','NEW RATE']].to_string(index=False,header =False)\n",
    "offer7878['PUBID'] = offer7878['PUBID'].astype(str).str.split(\".\",expand = True)[0]\n",
    "sp7878 = offer7878.loc[(offer7878['STATUS'] == 'Live') & (offer7878['PUBID'].astype(str).isin(sms_live_pubid)) ,][['PUBID','NEW RATE']].to_string(index=False,header = False)\n",
    "if \"Empty DataFrame\" in sp7878:\n",
    "    sp7878 = ''\n",
    "offer = same_offer_from_email[same_offer_from_email['Email Offer ID'].isnull() == False]\n",
    "\n",
    "# speical payout \n",
    "offer['Special Payout from Email'] = ''\n",
    "offer['Special Pub Payouts'] = offer['Special Pub Payouts'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
    "offer.loc[offer['Email Offer ID'] == 9287,'Special Payout from Email' ] = sp9287\n",
    "offer.loc[offer['Email Offer ID'] == 7878,'Special Payout from Email' ] = sp7878\n",
    "offer['Special Payout Alert'] = ''\n",
    "offer.loc[(offer['Special Pub Payouts']!=offer['Special Payout from Email']) , 'Special Payout Alert'] = 'Please update Special Payout'\n",
    "\n",
    "offer['Paused Alert'] =  ''\n",
    "offer.loc[(offer['Status'].str.lower().str.contains('set up|pause|pitch|archive',na = False) == False) & (offer['Operational Status from email'].str.contains('Paused') ),'Paused Alert'] = 'Please Pause offer in SMS'\n",
    "\n",
    "offer['Payout Alert'] = ''\n",
    "offer['SMS_payout_rate'] = offer['$ Payout'].str.extract(r'([\\d\\.]+)').astype(float)\n",
    "offer['SMS_new_payout_rate'] = offer['New Payout'].str.extract(r'([\\d\\.]+)').astype(float)\n",
    "offer['Email_payout_rate'] = offer['Payout from email'].str.extract(r'([\\d\\.]+)').astype(float)\n",
    "offer['Payout Alert'] = ''\n",
    "offer.loc[(offer['SMS_payout_rate']!=offer['Email_payout_rate']) & (offer['SMS_new_payout_rate']!=offer['Email_payout_rate'])&(offer['$ Payout']!=offer['Payout from email']), 'Payout Alert'] = 'Please update the payout'\n",
    "\n",
    "offer['Paused Pubids list'] = offer['Paused PubIDs from email'].str.split('\\n|\\t|,|\"| ')\n",
    "offer['SMS current Paused Pubids list'] = offer['Paused Pubs'].str.split('\\n|\\t|,|\"| ')\n",
    "offer['SMS current Paused Pubids list'] = offer['SMS current Paused Pubids list'].apply(lambda x: sorted(x) if isinstance(x, (list, tuple))  else list())\n",
    "offer['Update Needed in SMS: Paused Pubids'] = offer['Paused Pubids list'].apply(lambda x: sorted(list(set(list(x)) & set(sms_live_pubid))) if isinstance(x, (list, tuple))  else list())\n",
    "offer['Update Needed in SMS: Paused Pubids'] = offer['Update Needed in SMS: Paused Pubids'].apply(lambda x: [int(i) for i in x if i != ''])\n",
    "offer['SMS current Paused Pubids list'] = offer['SMS current Paused Pubids list'].apply(lambda x: [int(i) for i in x if i != ''])\n",
    "offer.loc[offer['Update Needed in SMS: Paused Pubids'] == offer['SMS current Paused Pubids list'],'Update Needed in SMS: Paused Pubids'] = ''\n",
    "offer['Update Needed in SMS: Paused Pubids'] = offer['Update Needed in SMS: Paused Pubids'].apply(lambda x: '' if x == list() else x) \n",
    "offer['Update Needed in SMS: Paused Pubids'] = offer['Update Needed in SMS: Paused Pubids'].apply(lambda x: '\\n'.join(map(str, x)))\n",
    "offer.loc[offer['SMS current Paused Pubids list'].isnull(), 'SMS current Paused Pubids list'] = ''\n",
    "\n",
    "offer['Day Parting from Email'] = offer['Day Restrictions from email'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x ) + ' ' + offer['Drop Time Restrictions from email'].apply(lambda x: \"\" if x == 'None'  or pd.isnull(x) else x )\n",
    "offer['Day Parting'] = offer['Day Parting'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
    "offer['Day Parting Alert'] = ''\n",
    "offer.loc[offer['Day Parting'].str.replace(\" \",\"\").str.lower()!=offer['Day Parting from Email'].str.replace(\" \",\"\").str.lower(),'Day Parting Alert'] = 'Please update the Day Parting'\n",
    "\n",
    "offer['Budget Alert'] =''\n",
    "offer['Cap from email1'] = offer['Cap from email'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
    "offer['Cap1'] = offer['Cap'].apply(lambda x: \"\" if x == 'No Cap'  or pd.isnull(x) else x )\n",
    "offer['New Cap Budget1'] = offer['New Cap Budget'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
    "offer['Budget from email1'] = offer['Budget from email'].apply(lambda x: \"\" if x == 'None'  or pd.isnull(x) else x )\n",
    "offer['Cap Budget1'] = offer['Cap Budget'].apply(lambda x: \"\" if str(x).lower() == 'none'  or pd.isnull(x) else x )\n",
    "offer.loc[offer['Cap1']!=offer['Cap from email1'],'Budget Alert'] = offer['Budget Alert']+\"Please update budget cap. \"\n",
    "offer['Budget from email2'] = offer['Budget from email1'].str.extract(r'(\\d+)')\n",
    "offer.loc[(offer['Budget from email1']!=offer['Cap Budget1'])&(offer['Budget from email2']!=offer['Cap Budget1'])& (offer['Budget from email1']!=offer['New Cap Budget1']) & (offer['Budget from email2']!=offer['New Cap Budget1']), 'Budget Alert'] = offer['Budget Alert']+\"Please update budget. \"\n",
    "offer = offer.drop(['SMS_payout_rate','Email_payout_rate','Paused Pubids list','SMS current Paused Pubids list','SMS_new_payout_rate','Cap from email1','Cap1','New Cap Budget1','Budget from email1','Cap Budget1','Budget from email2'],axis = 1)\n",
    "# if offer is paused, then all alert is ''\n",
    "offer.loc[(offer['Status'] =='Internal Pause - Archive'), 'Budget Alert'] = ''\n",
    "offer.loc[(offer['Status'] =='Internal Pause - Archive'), 'Update Needed in SMS: Paused Pubids'] = ''\n",
    "offer.loc[(offer['Status'] =='Internal Pause - Archive'), 'Paused Alert'] = ''\n",
    "offer.loc[(offer['Status'] =='Internal Pause - Archive'), 'Payout Alert'] = ''\n",
    "offer.loc[(offer['Status'] =='Internal Pause - Archive'), 'Day Parting Alert'] = ''\n",
    "offer.loc[(offer['Status'] =='Internal Pause - Archive'), 'Special Payout Alert'] = ''\n",
    "#offer[(offer['SMS current Paused Pubids list'] !=offer['Update Needed in SMS: Paused Pubids'])]\n",
    "\n",
    "# communicte with Daniel to uniform the time format \n",
    "offer_upload = gc.open_by_url('https://docs.google.com/spreadsheets/d/1Y0NjJBQBSXhTangk61PrOlKJBNZat9mmZGanAPuLma4/edit#gid=0')\n",
    "offer_upload_wks  = offer_upload.sheet1\n",
    "headers = offer_upload_wks.get_row(1)\n",
    "offer_upload_wks.clear(start='A2')\n",
    "offer_upload_wks.update_row(1, headers)\n",
    "offer_upload_wks.set_dataframe(offer,(2,1))\n",
    "\n",
    "# EDIT EMAIL MESSAGE: \n",
    "need_update_offer_list = offer.loc[((offer['Update Needed in SMS: Paused Pubids']!= '') | (offer['Paused Alert']!= '') | (offer['Payout Alert']!= '') |  (offer['Day Parting Alert']!= '') | (offer['Budget Alert']!= '') | (offer['Special Payout Alert']!='')), ]['Hitpath ID' ].unique().tolist()\n",
    "need_update_offer_list_str =  ','.join(need_update_offer_list)\n",
    "if len(need_update_offer_list) >0: \n",
    "    message = \"Hi AM Team, we found the information discrepancy between SMS Offer Sheet and Email Offer Management Smartsheet for the following email offers and please update the information in the SMS Offer Sheet. Thank you!\\nHere's the list: \\n\" + need_update_offer_list_str\n",
    "    #receipient_list = ['lili@rxmg.com']\n",
    "    receipient_list =  ['offernotices@rxmg.com']\n",
    "    for i in receipient_list:\n",
    "        offer_upload.share(i, role='commenter', type='user', emailMessage=message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7e2818f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:54:33.861443Z",
     "start_time": "2023-08-10T15:54:33.824749Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'All_merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Upcoming_schedule_Swap_Report.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Upcoming_schedule_Swap_Report.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m offer_sms[\u001b[39m'\u001b[39m\u001b[39mDay Parting\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m offer_sms[\u001b[39m'\u001b[39m\u001b[39mDay Parting\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Upcoming_schedule_Swap_Report.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m offer_sms[\u001b[39m'\u001b[39m\u001b[39mDay Parting\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m offer_sms[\u001b[39m'\u001b[39m\u001b[39mDay Parting\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mM-F\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMONDAY-FRIDAY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Upcoming_schedule_Swap_Report.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m All_merge[\u001b[39m'\u001b[39m\u001b[39mHitpath Offer ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m All_merge[\u001b[39m'\u001b[39m\u001b[39mHitpath Offer ID\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m,expand \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Upcoming_schedule_Swap_Report.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m offer_sms[\u001b[39m'\u001b[39m\u001b[39mHitpath ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m offer_sms[\u001b[39m'\u001b[39m\u001b[39mHitpath ID\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m,expand \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liliguo/Desktop/github/SMS_Report/Daily_Reporting/Upcoming_schedule_Swap_Report.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m alert_report \u001b[39m=\u001b[39m All_merge\u001b[39m.\u001b[39mmerge(offer_sms[[\u001b[39m'\u001b[39m\u001b[39mHitpath ID\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mEmail Offer ID\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mScheduling Name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDay Parting\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mPaused Pubs\u001b[39m\u001b[39m'\u001b[39m]], left_on \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mHitpath Offer ID\u001b[39m\u001b[39m'\u001b[39m,right_on \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHitpath ID\u001b[39m\u001b[39m'\u001b[39m, how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'All_merge' is not defined"
     ]
    }
   ],
   "source": [
    "offer_sms['Day Parting'] = offer_sms['Day Parting'].str.upper()\n",
    "offer_sms['Day Parting'] = offer_sms['Day Parting'].str.replace(' ','')\n",
    "offer_sms['Day Parting'] = offer_sms['Day Parting'].str.replace('M-F','MONDAY-FRIDAY')\n",
    "All_merge['Hitpath Offer ID'] = All_merge['Hitpath Offer ID'].astype('str').str.split('.',expand = True)[0]\n",
    "offer_sms['Hitpath ID'] = offer_sms['Hitpath ID'].astype('str').str.split('.',expand = True)[0]\n",
    "\n",
    "alert_report = All_merge.merge(offer_sms[['Hitpath ID','Email Offer ID','Scheduling Name','Day Parting','Status','Paused Pubs']], left_on ='Hitpath Offer ID',right_on = 'Hitpath ID', how = 'left') \n",
    "\n",
    "offer_email = offer_email[offer_email['Hitpath Offer ID'].isna() == False]\n",
    "alert_report = alert_report.merge(offer_email[['Hitpath Offer ID','Operational Status']],left_on ='Email Offer ID' ,right_on ='Hitpath Offer ID', how = 'left',copy= False)\n",
    "\n",
    "alert_report['Alert'] = ''\n",
    "alert_report.loc[alert_report['Creative'].isna(),'Alert'] = 'No Creative'\n",
    "alert_report['Weekday'] = pd.to_datetime(alert_report['Date']).dt.day_name()\n",
    "alert_report.loc[alert_report['Creative'].isna(),'Alert'] = 'No Creative'\n",
    "alert_report.loc[alert_report['Status'].str.lower().str.contains('set up|pause|pitch|archive',na = False), 'Alert' ] = 'Not Live Offer'\n",
    "for i in holiday_dict: \n",
    "    alert_report.loc[(alert_report['Date'] == i) & (alert_report['Hitpath ID'].isin(holiday_dict[i])), 'Alert' ] = 'Holiday Restriction'\n",
    "alert_report.loc[(alert_report['Operational Status'].str.lower().str.contains('paused',na = False)),  'Alert'  ] = 'Not Live Offer in Email'\n",
    "alert_report.loc[(alert_report['Weekday'].isin(['Saturday','Sunday']) ) & (alert_report['Day Parting'].str.contains('MONDAY-FRIDAY',na = False)),'Alert'] = 'Day Restriction'\n",
    "alert_report['Paused Pubs'] = alert_report['Paused Pubs'].astype('str')\n",
    "alert_report['PUBID'] = alert_report['PUBID'].astype('str')\n",
    "alert_report['Paused Alert'] = alert_report.apply(lambda x:x['PUBID'] in x['Paused Pubs'], axis=1)\n",
    "alert_report.loc[alert_report['Paused Alert']== True,'Alert'] = 'Paused Pubid'\n",
    "\n",
    "alert_report['Responsible DMA'] = alert_report['DMA']\n",
    "alert_report.loc[alert_report['Send Strategy'] == 'PT','Responsible DMA' ] = 'Nathan'\n",
    "alert_report = alert_report[alert_report['Alert'] != ''][['Responsible DMA','Alert','Scheduling Name','Day Parting','Status','Date','Sub Vertical','PUBID','Dataset','Drop', 'Time', 'Segment ', 'Send Strategy', 'Offer',\n",
    "       'Creative']]\n",
    "# alert from email offer \n",
    "filename = local_folder+'swap_report.csv'\n",
    "alert_report.to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e735f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:54:34.380784Z",
     "start_time": "2023-08-10T15:54:33.861604Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap_report = pd.read_excel( local_folder+'sms-overlap.xlsx')\n",
    "\n",
    "overlap_report['pub1_Dataset'] =  overlap_report['pub1_sc'].str.split('-',expand = True)[2]+'_'+overlap_report['pub1_dp_ds']+'_'+ overlap_report['pubid1'].astype('str')\n",
    "overlap_report['pub2_Dataset'] =  overlap_report['pub2_sc'].str.split('-',expand = True)[2]+'_'+overlap_report['pub2_dp_ds']+'_'+ overlap_report['pubid2'].astype('str')\n",
    "high_overlap = overlap_report[(overlap_report['pct_overlap'] > 0.1) & (overlap_report['pct_overlap'] <1)] \n",
    "high_overlap_schedule = high_overlap[['pub1_Dataset','pub2_Dataset','pct_overlap']].merge(All_merge, how = 'left', left_on = 'pub1_Dataset', right_on = 'Dataset',copy = False)\n",
    "high_overlap_schedule = high_overlap_schedule.merge(All_merge[['Dataset','Hitpath Offer ID','Date']],how = 'left', left_on = ['pub2_Dataset','Hitpath Offer ID'], right_on = ['Dataset','Hitpath Offer ID'], copy = False )\n",
    "high_overlap_schedule['Offer Gap between Overlapped Datasets'] = abs(high_overlap_schedule['Date_x'] - high_overlap_schedule['Date_y'])\n",
    "high_overlap_schedule = high_overlap_schedule.loc[(abs((high_overlap_schedule['Date_x'] - high_overlap_schedule['Date_y']).dt.days)<=2) & ((abs((high_overlap_schedule['Date_x'] - high_overlap_schedule['Date_y']).dt.days)>=0)),]\n",
    "high_overlap_schedule = high_overlap_schedule.drop(['Dataset_x','Dataset_y'], axis = 1)\n",
    "high_overlap_schedule = high_overlap_schedule[['Hitpath Offer ID','pub1_Dataset', 'Date_x','DMA','Sub Vertical', 'Send Strategy','pub2_Dataset','Date_y','pct_overlap','Offer Gap between Overlapped Datasets']]\n",
    "high_overlap_schedule = high_overlap_schedule.rename(columns = {'Date_x':'Date','Date_y':'Overlapped_pub_Date','pub1_Dataset':'Dataset','pub2_Dataset':'Overlapped_pub'})\n",
    "high_overlap_schedule['Hitpath Offer ID'] = high_overlap_schedule['Hitpath Offer ID'].astype('int').astype('str')\n",
    "high_overlap_schedule['pct_overlap'] =( high_overlap_schedule['pct_overlap']*100).round(2).astype('str') + '%'\n",
    "high_overlap_schedule['Warning'] = \"Please move the drops in \" +high_overlap_schedule['Dataset'] +\" with offer \"+ high_overlap_schedule['Hitpath Offer ID']+ \" to 3 days away from \"+ high_overlap_schedule['Overlapped_pub_Date'].astype('str') + \" to avoid high overlap\"\n",
    "high_overlap_schedule.to_csv(local_folder+'Overlap_Accounts_Swap_Report.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec36751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T15:57:11.435954Z",
     "start_time": "2023-08-10T15:54:34.391930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connect: to ('smtp.gmail.com', 587) None\n",
      "reply: b'220 smtp.gmail.com ESMTP g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp\\r\\n'\n",
      "reply: retcode (220); Msg: b'smtp.gmail.com ESMTP g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "connect: b'smtp.gmail.com ESMTP g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "send: 'ehlo 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\\r\\n'\n",
      "reply: b'250-smtp.gmail.com at your service, [47.145.216.112]\\r\\n'\n",
      "reply: b'250-SIZE 35882577\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-STARTTLS\\r\\n'\n",
      "reply: b'250-ENHANCEDSTATUSCODES\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-CHUNKING\\r\\n'\n",
      "reply: b'250 SMTPUTF8\\r\\n'\n",
      "reply: retcode (250); Msg: b'smtp.gmail.com at your service, [47.145.216.112]\\nSIZE 35882577\\n8BITMIME\\nSTARTTLS\\nENHANCEDSTATUSCODES\\nPIPELINING\\nCHUNKING\\nSMTPUTF8'\n",
      "send: 'STARTTLS\\r\\n'\n",
      "reply: b'220 2.0.0 Ready to start TLS\\r\\n'\n",
      "reply: retcode (220); Msg: b'2.0.0 Ready to start TLS'\n",
      "send: 'ehlo 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\\r\\n'\n",
      "reply: b'250-smtp.gmail.com at your service, [47.145.216.112]\\r\\n'\n",
      "reply: b'250-SIZE 35882577\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-AUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH\\r\\n'\n",
      "reply: b'250-ENHANCEDSTATUSCODES\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-CHUNKING\\r\\n'\n",
      "reply: b'250 SMTPUTF8\\r\\n'\n",
      "reply: retcode (250); Msg: b'smtp.gmail.com at your service, [47.145.216.112]\\nSIZE 35882577\\n8BITMIME\\nAUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH\\nENHANCEDSTATUSCODES\\nPIPELINING\\nCHUNKING\\nSMTPUTF8'\n",
      "send: 'AUTH PLAIN AHNjaGVkdWxlYWxhcnRzcnhtZ0BnbWFpbC5jb20AeXlqZXRlanRqaGpoenh4aw==\\r\\n'\n",
      "reply: b'235 2.7.0 Accepted\\r\\n'\n",
      "reply: retcode (235); Msg: b'2.7.0 Accepted'\n",
      "send: 'mail FROM:<schedulealartsrxmg@gmail.com> size=1714\\r\\n'\n",
      "reply: b'250 2.1.0 OK g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.1.0 OK g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "send: 'rcpt TO:<sms@rxmg.com>\\r\\n'\n",
      "reply: b'250 2.1.5 OK g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.1.5 OK g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "send: 'data\\r\\n'\n",
      "reply: b'354  Go ahead g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp\\r\\n'\n",
      "reply: retcode (354); Msg: b'Go ahead g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "data: (354, b'Go ahead g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp')\n",
      "send: b'Content-Type: multipart/mixed; boundary=\"===============0249005367025325721==\"\\r\\nMIME-Version: 1.0\\r\\nFrom: schedulealartsrxmg@gmail.com\\r\\nTo: sms@rxmg.com\\r\\nSubject: SMS Team Upcoming Schedule & Swap \\'Report & Overlap Accounts Swap Report\\r\\n\\r\\n--===============0249005367025325721==\\r\\nContent-Type: text/plain; charset=\"us-ascii\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: 7bit\\r\\n\\r\\nHi Team,\\r\\n\\r\\nHere\\'s the Upcoming Schedule link: \\r\\nhttps://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1189721992 \\r\\n\\r\\nHere\\'s the swap details from the swap report(attached): \\r\\n\\r\\n\\r\\nHere\\'s the swap details from the Overlap Accounts Swap Report(attached) due to less than 3 days\\' offer gap between highly overlapped datasets: \\r\\n\\r\\n\\r\\nHave a nice day!\\r\\n\\r\\nThanks\\r\\nLili Guo\\r\\n\\r\\n\\r\\n--===============0249005367025325721==\\r\\nContent-Type: application/octet-stream; Name=\"swap_report.csv\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: base64\\r\\nContent-Disposition: attachment; filename=\"swap_report.csv\"\\r\\n\\r\\nUmVzcG9uc2libGUgRE1BLEFsZXJ0LFNjaGVkdWxpbmcgTmFtZSxEYXkgUGFydGluZyxTdGF0dXMs\\r\\nRGF0ZSxTdWIgVmVydGljYWwsUFVCSUQsRGF0YXNldCxEcm9wLFRpbWUsU2VnbWVudCAsU2VuZCBT\\r\\ndHJhdGVneSxPZmZlcixDcmVhdGl2ZQo=\\r\\n\\r\\n--===============0249005367025325721==\\r\\nContent-Type: application/octet-stream; Name=\"Overlap_Accounts_Swap_Report.csv\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: base64\\r\\nContent-Disposition: attachment; filename=\"Overlap_Accounts_Swap_Report.csv\"\\r\\n\\r\\nSGl0cGF0aCBPZmZlciBJRCxEYXRhc2V0LERhdGUsRE1BLFN1YiBWZXJ0aWNhbCxTZW5kIFN0cmF0\\r\\nZWd5LE92ZXJsYXBwZWRfcHViLE92ZXJsYXBwZWRfcHViX0RhdGUscGN0X292ZXJsYXAsT2ZmZXIg\\r\\nR2FwIGJldHdlZW4gT3ZlcmxhcHBlZCBEYXRhc2V0cyxXYXJuaW5nCg==\\r\\n\\r\\n--===============0249005367025325721==--\\r\\n.\\r\\n'\n",
      "reply: b'250 2.0.0 OK  1698439613 g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.0.0 OK  1698439613 g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "data: (250, b'2.0.0 OK  1698439613 g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp')\n",
      "send: 'quit\\r\\n'\n",
      "reply: b'221 2.0.0 closing connection g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp\\r\\n'\n",
      "reply: retcode (221); Msg: b'2.0.0 closing connection g22-20020a1709029f9600b001c61afa7009sm1976028plq.114 - gsmtp'\n",
      "connect: to ('smtp.gmail.com', 587) None\n",
      "reply: b'220 smtp.gmail.com ESMTP o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp\\r\\n'\n",
      "reply: retcode (220); Msg: b'smtp.gmail.com ESMTP o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "connect: b'smtp.gmail.com ESMTP o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "send: 'ehlo 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\\r\\n'\n",
      "reply: b'250-smtp.gmail.com at your service, [47.145.216.112]\\r\\n'\n",
      "reply: b'250-SIZE 35882577\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-STARTTLS\\r\\n'\n",
      "reply: b'250-ENHANCEDSTATUSCODES\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-CHUNKING\\r\\n'\n",
      "reply: b'250 SMTPUTF8\\r\\n'\n",
      "reply: retcode (250); Msg: b'smtp.gmail.com at your service, [47.145.216.112]\\nSIZE 35882577\\n8BITMIME\\nSTARTTLS\\nENHANCEDSTATUSCODES\\nPIPELINING\\nCHUNKING\\nSMTPUTF8'\n",
      "send: 'STARTTLS\\r\\n'\n",
      "reply: b'220 2.0.0 Ready to start TLS\\r\\n'\n",
      "reply: retcode (220); Msg: b'2.0.0 Ready to start TLS'\n",
      "send: 'ehlo 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\\r\\n'\n",
      "reply: b'250-smtp.gmail.com at your service, [47.145.216.112]\\r\\n'\n",
      "reply: b'250-SIZE 35882577\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-AUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH\\r\\n'\n",
      "reply: b'250-ENHANCEDSTATUSCODES\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-CHUNKING\\r\\n'\n",
      "reply: b'250 SMTPUTF8\\r\\n'\n",
      "reply: retcode (250); Msg: b'smtp.gmail.com at your service, [47.145.216.112]\\nSIZE 35882577\\n8BITMIME\\nAUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH\\nENHANCEDSTATUSCODES\\nPIPELINING\\nCHUNKING\\nSMTPUTF8'\n",
      "send: 'AUTH PLAIN AHNjaGVkdWxlYWxhcnRzcnhtZ0BnbWFpbC5jb20AeXlqZXRlanRqaGpoenh4aw==\\r\\n'\n",
      "reply: b'235 2.7.0 Accepted\\r\\n'\n",
      "reply: retcode (235); Msg: b'2.7.0 Accepted'\n",
      "send: 'mail FROM:<schedulealartsrxmg@gmail.com> size=1723\\r\\n'\n",
      "reply: b'250 2.1.0 OK o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.1.0 OK o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "send: 'rcpt TO:<offernotices@rxmg.com>\\r\\n'\n",
      "reply: b'250 2.1.5 OK o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.1.5 OK o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "send: 'data\\r\\n'\n",
      "reply: b'354  Go ahead o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp\\r\\n'\n",
      "reply: retcode (354); Msg: b'Go ahead o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "data: (354, b'Go ahead o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp')\n",
      "send: b'Content-Type: multipart/mixed; boundary=\"===============7274440633657931809==\"\\r\\nMIME-Version: 1.0\\r\\nFrom: schedulealartsrxmg@gmail.com\\r\\nTo: offernotices@rxmg.com\\r\\nSubject: SMS Team Upcoming Schedule & Swap \\'Report & Overlap Accounts Swap Report\\r\\n\\r\\n--===============7274440633657931809==\\r\\nContent-Type: text/plain; charset=\"us-ascii\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: 7bit\\r\\n\\r\\nHi Team,\\r\\n\\r\\nHere\\'s the Upcoming Schedule link: \\r\\nhttps://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1189721992 \\r\\n\\r\\nHere\\'s the swap details from the swap report(attached): \\r\\n\\r\\n\\r\\nHere\\'s the swap details from the Overlap Accounts Swap Report(attached) due to less than 3 days\\' offer gap between highly overlapped datasets: \\r\\n\\r\\n\\r\\nHave a nice day!\\r\\n\\r\\nThanks\\r\\nLili Guo\\r\\n\\r\\n\\r\\n--===============7274440633657931809==\\r\\nContent-Type: application/octet-stream; Name=\"swap_report.csv\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: base64\\r\\nContent-Disposition: attachment; filename=\"swap_report.csv\"\\r\\n\\r\\nUmVzcG9uc2libGUgRE1BLEFsZXJ0LFNjaGVkdWxpbmcgTmFtZSxEYXkgUGFydGluZyxTdGF0dXMs\\r\\nRGF0ZSxTdWIgVmVydGljYWwsUFVCSUQsRGF0YXNldCxEcm9wLFRpbWUsU2VnbWVudCAsU2VuZCBT\\r\\ndHJhdGVneSxPZmZlcixDcmVhdGl2ZQo=\\r\\n\\r\\n--===============7274440633657931809==\\r\\nContent-Type: application/octet-stream; Name=\"Overlap_Accounts_Swap_Report.csv\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: base64\\r\\nContent-Disposition: attachment; filename=\"Overlap_Accounts_Swap_Report.csv\"\\r\\n\\r\\nSGl0cGF0aCBPZmZlciBJRCxEYXRhc2V0LERhdGUsRE1BLFN1YiBWZXJ0aWNhbCxTZW5kIFN0cmF0\\r\\nZWd5LE92ZXJsYXBwZWRfcHViLE92ZXJsYXBwZWRfcHViX0RhdGUscGN0X292ZXJsYXAsT2ZmZXIg\\r\\nR2FwIGJldHdlZW4gT3ZlcmxhcHBlZCBEYXRhc2V0cyxXYXJuaW5nCg==\\r\\n\\r\\n--===============7274440633657931809==--\\r\\n.\\r\\n'\n",
      "reply: b'250 2.0.0 OK  1698439614 o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.0.0 OK  1698439614 o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "data: (250, b'2.0.0 OK  1698439614 o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp')\n",
      "send: 'quit\\r\\n'\n",
      "reply: b'221 2.0.0 closing connection o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp\\r\\n'\n",
      "reply: retcode (221); Msg: b'2.0.0 closing connection o10-20020a170902d4ca00b001c736746d33sm1971420plg.217 - gsmtp'\n",
      "connect: to ('smtp.gmail.com', 587) None\n",
      "reply: b'220 smtp.gmail.com ESMTP gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp\\r\\n'\n",
      "reply: retcode (220); Msg: b'smtp.gmail.com ESMTP gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n",
      "connect: b'smtp.gmail.com ESMTP gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n",
      "send: 'ehlo 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\\r\\n'\n",
      "reply: b'250-smtp.gmail.com at your service, [47.145.216.112]\\r\\n'\n",
      "reply: b'250-SIZE 35882577\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-STARTTLS\\r\\n'\n",
      "reply: b'250-ENHANCEDSTATUSCODES\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-CHUNKING\\r\\n'\n",
      "reply: b'250 SMTPUTF8\\r\\n'\n",
      "reply: retcode (250); Msg: b'smtp.gmail.com at your service, [47.145.216.112]\\nSIZE 35882577\\n8BITMIME\\nSTARTTLS\\nENHANCEDSTATUSCODES\\nPIPELINING\\nCHUNKING\\nSMTPUTF8'\n",
      "send: 'STARTTLS\\r\\n'\n",
      "reply: b'220 2.0.0 Ready to start TLS\\r\\n'\n",
      "reply: retcode (220); Msg: b'2.0.0 Ready to start TLS'\n",
      "send: 'ehlo 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\\r\\n'\n",
      "reply: b'250-smtp.gmail.com at your service, [47.145.216.112]\\r\\n'\n",
      "reply: b'250-SIZE 35882577\\r\\n'\n",
      "reply: b'250-8BITMIME\\r\\n'\n",
      "reply: b'250-AUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH\\r\\n'\n",
      "reply: b'250-ENHANCEDSTATUSCODES\\r\\n'\n",
      "reply: b'250-PIPELINING\\r\\n'\n",
      "reply: b'250-CHUNKING\\r\\n'\n",
      "reply: b'250 SMTPUTF8\\r\\n'\n",
      "reply: retcode (250); Msg: b'smtp.gmail.com at your service, [47.145.216.112]\\nSIZE 35882577\\n8BITMIME\\nAUTH LOGIN PLAIN XOAUTH2 PLAIN-CLIENTTOKEN OAUTHBEARER XOAUTH\\nENHANCEDSTATUSCODES\\nPIPELINING\\nCHUNKING\\nSMTPUTF8'\n",
      "send: 'AUTH PLAIN AHNjaGVkdWxlYWxhcnRzcnhtZ0BnbWFpbC5jb20AeXlqZXRlanRqaGpoenh4aw==\\r\\n'\n",
      "reply: b'235 2.7.0 Accepted\\r\\n'\n",
      "reply: retcode (235); Msg: b'2.7.0 Accepted'\n",
      "send: 'mail FROM:<schedulealartsrxmg@gmail.com> size=1717\\r\\n'\n",
      "reply: b'250 2.1.0 OK gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.1.0 OK gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n",
      "send: 'rcpt TO:<prasad@rxmg.com>\\r\\n'\n",
      "reply: b'250 2.1.5 OK gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.1.5 OK gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n",
      "send: 'data\\r\\n'\n",
      "reply: b'354  Go ahead gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp\\r\\n'\n",
      "reply: retcode (354); Msg: b'Go ahead gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n",
      "data: (354, b'Go ahead gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp')\n",
      "send: b'Content-Type: multipart/mixed; boundary=\"===============2763423833567580346==\"\\r\\nMIME-Version: 1.0\\r\\nFrom: schedulealartsrxmg@gmail.com\\r\\nTo: prasad@rxmg.com\\r\\nSubject: SMS Team Upcoming Schedule & Swap \\'Report & Overlap Accounts Swap Report\\r\\n\\r\\n--===============2763423833567580346==\\r\\nContent-Type: text/plain; charset=\"us-ascii\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: 7bit\\r\\n\\r\\nHi Team,\\r\\n\\r\\nHere\\'s the Upcoming Schedule link: \\r\\nhttps://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1189721992 \\r\\n\\r\\nHere\\'s the swap details from the swap report(attached): \\r\\n\\r\\n\\r\\nHere\\'s the swap details from the Overlap Accounts Swap Report(attached) due to less than 3 days\\' offer gap between highly overlapped datasets: \\r\\n\\r\\n\\r\\nHave a nice day!\\r\\n\\r\\nThanks\\r\\nLili Guo\\r\\n\\r\\n\\r\\n--===============2763423833567580346==\\r\\nContent-Type: application/octet-stream; Name=\"swap_report.csv\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: base64\\r\\nContent-Disposition: attachment; filename=\"swap_report.csv\"\\r\\n\\r\\nUmVzcG9uc2libGUgRE1BLEFsZXJ0LFNjaGVkdWxpbmcgTmFtZSxEYXkgUGFydGluZyxTdGF0dXMs\\r\\nRGF0ZSxTdWIgVmVydGljYWwsUFVCSUQsRGF0YXNldCxEcm9wLFRpbWUsU2VnbWVudCAsU2VuZCBT\\r\\ndHJhdGVneSxPZmZlcixDcmVhdGl2ZQo=\\r\\n\\r\\n--===============2763423833567580346==\\r\\nContent-Type: application/octet-stream; Name=\"Overlap_Accounts_Swap_Report.csv\"\\r\\nMIME-Version: 1.0\\r\\nContent-Transfer-Encoding: base64\\r\\nContent-Disposition: attachment; filename=\"Overlap_Accounts_Swap_Report.csv\"\\r\\n\\r\\nSGl0cGF0aCBPZmZlciBJRCxEYXRhc2V0LERhdGUsRE1BLFN1YiBWZXJ0aWNhbCxTZW5kIFN0cmF0\\r\\nZWd5LE92ZXJsYXBwZWRfcHViLE92ZXJsYXBwZWRfcHViX0RhdGUscGN0X292ZXJsYXAsT2ZmZXIg\\r\\nR2FwIGJldHdlZW4gT3ZlcmxhcHBlZCBEYXRhc2V0cyxXYXJuaW5nCg==\\r\\n\\r\\n--===============2763423833567580346==--\\r\\n.\\r\\n'\n",
      "reply: b'250 2.0.0 OK  1698439615 gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp\\r\\n'\n",
      "reply: retcode (250); Msg: b'2.0.0 OK  1698439615 gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n",
      "data: (250, b'2.0.0 OK  1698439615 gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp')\n",
      "send: 'quit\\r\\n'\n",
      "reply: b'221 2.0.0 closing connection gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp\\r\\n'\n",
      "reply: retcode (221); Msg: b'2.0.0 closing connection gx13-20020a056a001e0d00b0068aca503b9fsm1796475pfb.114 - gsmtp'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "toaddr =  ['sms@rxmg.com','offernotices@rxmg.com','prasad@rxmg.com']\n",
    "filename = [local_folder+'swap_report.csv',local_folder+'Overlap_Accounts_Swap_Report.csv']\n",
    "no_swap = len(alert_report)\n",
    "subject_line = f\"SMS Team Upcoming Schedule & Swap 'Report & Overlap Accounts Swap Report\"\n",
    "email_body = \"Hi Team,\\n\\nHere's the Upcoming Schedule link: \\nhttps://docs.google.com/spreadsheets/d/12vqSDueybprNphtsw7gXR5vmgcPG6_5ZNcnWzNpiasY/edit#gid=1189721992 \\n\\nHere's the swap details from the swap report(attached): \\n\"\n",
    "for i in alert_report['Responsible DMA'].unique(): \n",
    "    email_body += i +\":\"+'\\n' \n",
    "    dma = alert_report[alert_report['Responsible DMA'] == i]\n",
    "    for i in range(0,len(dma)): \n",
    "        row_dma = dma.iloc[i]\n",
    "        dma_send_strategy = row_dma['Send Strategy']\n",
    "        dma_date =row_dma['Date'].strftime('%Y-%m-%d')\n",
    "        dma_dataset = row_dma['Dataset']\n",
    "        dma_alert = row_dma['Alert']\n",
    "        email_body += f\"  The {dma_send_strategy} drop on {dma_date} in {dma_dataset} need to be swapped/updated due to {dma_alert}\\n\"\n",
    "email_body += \"\\n\\nHere's the swap details from the Overlap Accounts Swap Report(attached) due to less than 3 days' offer gap between highly overlapped datasets: \\n\"\n",
    "for i in high_overlap_schedule['DMA'].unique():\n",
    "    email_body += i +\":\"+'\\n' \n",
    "    dma = high_overlap_schedule[high_overlap_schedule['DMA'] == i] \n",
    "    for i in range(0,len(dma)):\n",
    "        row_dma = dma.iloc[i]\n",
    "        warning = row_dma['Warning']\n",
    "        \n",
    "        email_body += f\"  {warning}\\n\"\n",
    "\n",
    "email_body += '\\n\\nHave a nice day!\\n\\nThanks\\nLili Guo\\n\\n'\n",
    "\n",
    "for i in toaddr:\n",
    "    send_email.send_email(filename,subject_line,email_body,i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76accff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
