{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import infrastructure\n",
    "import filepath \n",
    "import pygsheets\n",
    "from datetime import datetime, timedelta\n",
    "import openpyxl \n",
    "import os\n",
    "from pathlib import Path\n",
    "import xlsxwriter\n",
    "import send_email\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1554: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n"
     ]
    }
   ],
   "source": [
    "#Publisher Config\n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "publisher_config = gc.open_by_url(\n",
    "    'https://docs.google.com/spreadsheets/d/1Tzda6Djr3zQmOhWu7Ief3GVR9Cjaml8238CeX7chj_U/edit#gid=1620368362') \n",
    "pub_config = publisher_config[0].get_as_df()\n",
    "pub_config.rename(columns={'DP.DS or DP.sV': 'DP.SV'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AR Smartsheet\n",
    "sms_AR = infrastructure.get_smartsheet('ar_sms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_AR['Offer ID'] = sms_AR['New Offer Name'].str.split('_').str[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,57,58,62) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#manual input\n",
    "df = pd.read_csv('SS_LC_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame by Send Strategy\n",
    "ar_df = df[df['Send Strategy'] == 'AR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-2f2f4f8aaa10>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ar_df['shortcode_DP.SV'] = ar_df['shortcode_DP.SV'].apply(lambda x: str(x)[:min(3, str(x).index('_'))] + str(x)[str(x).index('_'):] if '_' in str(x) else str(x))\n"
     ]
    }
   ],
   "source": [
    "ar_df['shortcode_DP.SV'] = ar_df['shortcode_DP.SV'].apply(lambda x: str(x)[:min(3, str(x).index('_'))] + str(x)[str(x).index('_'):] if '_' in str(x) else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-110-c0d54c8234f7>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ar_df['Hitpath_Offer_ID'] = ar_df['Hitpath_Offer_ID'].str.replace(r'\\.0$', '')\n",
      "<ipython-input-110-c0d54c8234f7>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ar_df['Hitpath_Offer_ID'] = ar_df['Hitpath_Offer_ID'].str.replace(r'\\.0$', '')\n"
     ]
    }
   ],
   "source": [
    "# remove only the \".0\" at the end of the Hitpath_Offer_ID column in ar_df\n",
    "ar_df['Hitpath_Offer_ID'] = ar_df['Hitpath_Offer_ID'].str.replace(r'\\.0$', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 30 day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-111-fac7a05c68f9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ar_df['Date'] = pd.to_datetime(ar_df['Date'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "ar_df['Date'] = pd.to_datetime(ar_df['Date'])\n",
    "\n",
    "# Calculate the date 37 days ago\n",
    "thirty_days_ago = datetime.now() - timedelta(days=37)\n",
    "\n",
    "# Calculate the date 7 days ago\n",
    "seven_days_ago = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Filter the DataFrame for the last 30 days after the last 7 days\n",
    "ar30_df = ar_df[(ar_df['Date'] <= seven_days_ago) & (ar_df['Date'] >= thirty_days_ago)]\n",
    "\n",
    "# Filter the DataFrame for the last 7 days\n",
    "ar7_df = ar_df[ar_df['Date'] >= seven_days_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter 30 day df\n",
    "filtered_ar30_df = ar30_df[['Hitpath_Offer_ID', 'Affiliate_Id', 'DP&Pub', 'Revenue', \n",
    "                            'Jump Page Clicks', 'Delivered', 'Optout', 'Clicks', 'Cost', \n",
    "                            'Ar Day', 'Shortcode Name', 'DP.SV', 'shortcode_DP.SV', \n",
    "                            'Opportunity Cost', 'Offer Vertical']]\n",
    "\n",
    "#filter 7 day df\n",
    "filtered_ar7_df = ar7_df[['Hitpath_Offer_ID', 'Affiliate_Id', 'DP&Pub', 'Revenue',\n",
    "                            'Jump Page Clicks', 'Delivered', 'Optout', 'Clicks', 'Cost',\n",
    "                            'Ar Day', 'Shortcode Name', 'DP.SV', 'shortcode_DP.SV',\n",
    "                            'Opportunity Cost', 'Offer Vertical']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ar30_df = filtered_ar30_df.groupby(['shortcode_DP.SV', 'Ar Day']).agg({'Revenue': 'sum', 'Cost': 'sum', 'Delivered': 'sum', 'Jump Page Clicks': 'sum', 'Clicks': 'sum', 'Opportunity Cost': 'sum', 'Optout': 'sum'}).reset_index()\n",
    "grouped_ar7_df = filtered_ar7_df.groupby(['shortcode_DP.SV', 'Ar Day']).agg({'Revenue': 'sum', 'Cost': 'sum', 'Delivered': 'sum', 'Jump Page Clicks': 'sum', 'Clicks': 'sum', 'Opportunity Cost': 'sum', 'Optout': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 day averages\n",
    "grouped_ar30_df['30 Day eCPM'] = grouped_ar30_df['Revenue'] / grouped_ar30_df['Delivered'] * 1000\n",
    "grouped_ar30_df['30 Day CTR'] = grouped_ar30_df['Clicks'] / grouped_ar30_df['Delivered']\n",
    "grouped_ar30_df['30 Day JCTR'] = grouped_ar30_df['Jump Page Clicks'] / grouped_ar30_df['Delivered']\n",
    "grouped_ar30_df['30 Day Optout Rate'] = grouped_ar30_df['Optout'] / grouped_ar30_df['Delivered']\n",
    "\n",
    "#7 day averages\n",
    "grouped_ar7_df['7 Day eCPM'] = grouped_ar7_df['Revenue'] / grouped_ar7_df['Delivered'] * 1000\n",
    "grouped_ar7_df['7 Day CTR'] = grouped_ar7_df['Clicks'] / grouped_ar7_df['Delivered']\n",
    "grouped_ar7_df['7 Day JCTR'] = grouped_ar7_df['Jump Page Clicks'] / grouped_ar7_df['Delivered']\n",
    "grouped_ar7_df['7 Day Optout Rate'] = grouped_ar7_df['Optout'] / grouped_ar7_df['Delivered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #percentages\n",
    "grouped_ar30_df['30 Day CTR'] = grouped_ar30_df['30 Day CTR'] * 100\n",
    "grouped_ar30_df['30 Day JCTR'] = grouped_ar30_df['30 Day JCTR'] * 100\n",
    "grouped_ar30_df['30 Day Optout Rate'] = grouped_ar30_df['30 Day Optout Rate'] * 100\n",
    "\n",
    "grouped_ar7_df['7 Day CTR'] = grouped_ar7_df['7 Day CTR'] * 100\n",
    "grouped_ar7_df['7 Day JCTR'] = grouped_ar7_df['7 Day JCTR'] * 100\n",
    "grouped_ar7_df['7 Day Optout Rate'] = grouped_ar7_df['7 Day Optout Rate'] * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = grouped_ar30_df.merge(grouped_ar7_df[['shortcode_DP.SV','Ar Day', '7 Day eCPM']], \n",
    "                                 on=['shortcode_DP.SV', 'Ar Day'], \n",
    "                                 how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percent difference between 30 day and 7 day eCPM with 30 day eCPM as the base\n",
    "merged_df['eCPM % Diff'] = (merged_df['7 Day eCPM'] - merged_df['30 Day eCPM']) / merged_df['30 Day eCPM'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most recent Offer ID for AR and Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-123-ce9b7e1a9952>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_sms_ar['shortcode_DP.SV'] = active_sms_ar['Shortcode'] + '_' + active_sms_ar['DP.DS']\n",
      "<ipython-input-123-ce9b7e1a9952>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_sms_ar['Day'] = active_sms_ar['Day'].str.replace('AR', '').astype(float)\n",
      "/Users/nathan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "#Get Active SMS ARs from sms_ar\n",
    "active_sms_ar = sms_AR[sms_AR['Status'] == 'Active']\n",
    "active_sms_ar['shortcode_DP.SV'] = active_sms_ar['Shortcode'] + '_' + active_sms_ar['DP.DS']\n",
    "#remove AR portion from Day column and convert the remaining number to an integer\n",
    "active_sms_ar['Day'] = active_sms_ar['Day'].str.replace('AR', '').astype(float)\n",
    "active_sms_ar.rename(columns={'Day': 'Ar Day'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get active ARs from merged df\n",
    "merged_df = merged_df.merge(active_sms_ar[['shortcode_DP.SV', 'Ar Day']], on=['shortcode_DP.SV', 'Ar Day'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(active_sms_ar[['shortcode_DP.SV', 'Ar Day', 'Offer ID', 'Date Started']], on=['shortcode_DP.SV', 'Ar Day'], how='left')\n",
    "#convert Date Started to datetime\n",
    "merged_df['Date Started'] = pd.to_datetime(merged_df['Date Started'])\n",
    "\n",
    "#days since swap\n",
    "merged_df['Days Since Swap'] = (datetime.now() - timedelta(days=1) - merged_df['Date Started']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(merged_df.columns)\n",
    "cols.insert(2, cols.pop(cols.index('Offer ID')))\n",
    "merged_df = merged_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column called AR Check, if eCPM % Diff is less than -25 and Days Since Swap is greater than 7, then AR Check is 'Underperforming', else if ecpm % diff is less than -25 and days since swap is less than 7, then AR Check is 'In Review', else 'Good'\n",
    "merged_df['AR Check'] = merged_df.apply(lambda row: 'Downtrending - Swap' if row['eCPM % Diff'] < -25 and row['Days Since Swap'] > 37 \n",
    "                                        else ('In Review' if row['eCPM % Diff'] < -25 and row['Days Since Swap'] <= 7\n",
    "                                        else ('Underperforming Swap' if row['eCPM % Diff'] < -25 and row['Days Since Swap'] > 7 and row['Days Since Swap'] <= 37 else 'Good')), \n",
    "                                        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert merged_df Offer ID to string\n",
    "# merged_df['Offer ID'] = merged_df['Offer ID'].astype(str).str.replace(r'\\.0$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY DMA Account\n",
    "merged_df['extracted_DP.SV'] = merged_df['shortcode_DP.SV'].str.split('_').str[-1]\n",
    "\n",
    "#merge using 'extracted_DP.SV' and 'DP.SV'\n",
    "merged_df = pd.merge(merged_df, pub_config[['DP.SV', 'DMA']], \n",
    "                     left_on='extracted_DP.SV', right_on='DP.SV', how='left')\n",
    "\n",
    "#drop temp columns\n",
    "merged_df = merged_df.drop(columns=['extracted_DP.SV', 'DP.SV'])\n",
    "\n",
    "dma_separated_dfs = {}\n",
    "for dma in merged_df['DMA'].unique():\n",
    "    if pd.notna(dma):  # Ensure that the 'DMA' value is not NaN\n",
    "        dma_separated_dfs[dma] = merged_df[merged_df['DMA'] == dma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframes for statuses sorted\n",
    "downtrending_swaps = merged_df[merged_df['AR Check'] == 'Downtrending - Swap']\n",
    "downtrending_swaps = downtrending_swaps.sort_values(by=['DMA', 'shortcode_DP.SV','Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "in_review = merged_df[merged_df['AR Check'] == 'In Review']\n",
    "in_review = in_review.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "underperforming_swaps = merged_df[merged_df['AR Check'] == 'Underperforming Swap']\n",
    "underperforming_swaps = underperforming_swaps.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output file\n",
    "filename = filepath.output_folder+'/AR Offer Alert - {}.xlsx'.format(datetime.today().strftime(\"%m_%d_%Y\"))\n",
    "\n",
    "#create writer\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    for dma, df in dma_separated_dfs.items():\n",
    "        sheet_name = f'{dma} - AR Offers'  # dynamic sheet name based on the DMA\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)  # Writing data to different sheets\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    downtrending_swaps.to_excel(writer, sheet_name='Downtrending Swaps', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    underperforming_swaps.to_excel(writer, sheet_name='Underperforming Swaps', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    in_review.to_excel(writer, sheet_name='In Review', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_body = \"Hi Team, here is the Daily AR Offer Alert Report \\n\\n\"\n",
    "email_body += \"Current Downtrending Threshold: 25%\\n\"\n",
    "email_body += \"Downtrending Swaps: eCPM % Diff < -25% and Days Since Last Swap > 37\\n\"\n",
    "email_body += \"Underperforming Swaps: eCPM % Diff < -25% and Days Since Last Swap > 7 and <= 37\\n\"\n",
    "email_body += \"In Review: eCPM % Diff < -25% and Days Since Last Swap <= 7\\n\\n\"\n",
    "\n",
    "\n",
    "email_body += \"Please check the current downtrending ARs and swap:\\n\\n\"\n",
    "#add to email_body and for each DMA, add the count of downtrending swaps \n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {downtrending_swaps[downtrending_swaps['DMA'] == dma].shape[0]} downtrending swaps\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the current underperforming swaps and swap back or to a new offer:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {underperforming_swaps[underperforming_swaps['DMA'] == dma].shape[0]} underperforming swaps\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the recently swapped ARs that are in review and pay attention to performance changes:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {in_review[in_review['DMA'] == dma].shape[0]} swaps in review\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toaddr = ['sms@rxmg.com','offernotices@rxmg.com']\n",
    "today = datetime.today().strftime(\"%m_%d_%Y\")\n",
    "subject_line = f\"SMS Daily AR Offer Alert Report - {today}\"\n",
    "\n",
    "for i in toaddr:\n",
    "    send_email.send_email([filename],subject_line,email_body,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
