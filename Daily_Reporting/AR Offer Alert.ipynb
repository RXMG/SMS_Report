{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import infrastructure\n",
    "import filepath \n",
    "import pygsheets\n",
    "from datetime import datetime, timedelta\n",
    "import openpyxl \n",
    "import os\n",
    "from pathlib import Path\n",
    "import xlsxwriter\n",
    "import send_email\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Publisher Config\n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "publisher_config = gc.open_by_url(\n",
    "    'https://docs.google.com/spreadsheets/d/1Tzda6Djr3zQmOhWu7Ief3GVR9Cjaml8238CeX7chj_U/edit#gid=1620368362') \n",
    "pub_config = publisher_config[0].get_as_df()\n",
    "pub_config.rename(columns={'DP.DS or DP.sV': 'DP.SV'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AR Smartsheet\n",
    "sms_AR = infrastructure.get_smartsheet('ar_sms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_AR['Offer ID'] = sms_AR['New Offer Name'].str.split('_').str[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0,1,2,3,4,6,8,9,10,11,12,14,16,26,27,28,29,30,31,32,33,34,35,36,37,44,48,51,54,56,58,59,63) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#manual input\n",
    "df = pd.read_csv('SS_LC_merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame by Send Strategy\n",
    "ar_df = df[df['Send Strategy'] == 'AR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-211-2f2f4f8aaa10>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ar_df['shortcode_DP.SV'] = ar_df['shortcode_DP.SV'].apply(lambda x: str(x)[:min(3, str(x).index('_'))] + str(x)[str(x).index('_'):] if '_' in str(x) else str(x))\n"
     ]
    }
   ],
   "source": [
    "ar_df['shortcode_DP.SV'] = ar_df['shortcode_DP.SV'].apply(lambda x: str(x)[:min(3, str(x).index('_'))] + str(x)[str(x).index('_'):] if '_' in str(x) else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-212-c0d54c8234f7>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ar_df['Hitpath_Offer_ID'] = ar_df['Hitpath_Offer_ID'].str.replace(r'\\.0$', '')\n",
      "<ipython-input-212-c0d54c8234f7>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ar_df['Hitpath_Offer_ID'] = ar_df['Hitpath_Offer_ID'].str.replace(r'\\.0$', '')\n"
     ]
    }
   ],
   "source": [
    "# remove only the \".0\" at the end of the Hitpath_Offer_ID column in ar_df\n",
    "ar_df['Hitpath_Offer_ID'] = ar_df['Hitpath_Offer_ID'].str.replace(r'\\.0$', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get inactive pubid from pub_config\n",
    "inactive_pubid = pub_config[pub_config['INTERNAL STATUS'] == 'INACTIVE']['PUBID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inactitve_pubid to float type\n",
    "inactive_pubid = [float(i) for i in inactive_pubid if i != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove inactive pubid from ar_df\n",
    "ar_df = ar_df[~ar_df['Affiliate_Id'].isin(inactive_pubid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 30 day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "ar_df['Date'] = pd.to_datetime(ar_df['Date'])\n",
    "\n",
    "# Calculate the date 37 days ago\n",
    "thirty_days_ago = datetime.now() - timedelta(days=37)\n",
    "\n",
    "# Calculate the date 7 days ago\n",
    "seven_days_ago = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Filter the DataFrame for the last 30 days after the last 7 days\n",
    "ar30_df = ar_df[(ar_df['Date'] <= seven_days_ago) & (ar_df['Date'] >= thirty_days_ago)]\n",
    "\n",
    "# Filter the DataFrame for the last 7 days\n",
    "ar7_df = ar_df[ar_df['Date'] >= seven_days_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter 30 day df\n",
    "filtered_ar30_df = ar30_df[['Hitpath_Offer_ID', 'Affiliate_Id', 'DP&Pub', 'Revenue', \n",
    "                            'Jump Page Clicks', 'Delivered', 'Optout', 'Clicks', 'Cost', \n",
    "                            'Ar Day', 'Shortcode Name', 'DP.SV', 'shortcode_DP.SV', \n",
    "                            'Opportunity Cost', 'Offer Vertical']]\n",
    "\n",
    "#filter 7 day df\n",
    "filtered_ar7_df = ar7_df[['Hitpath_Offer_ID', 'Affiliate_Id', 'DP&Pub', 'Revenue',\n",
    "                            'Jump Page Clicks', 'Delivered', 'Optout', 'Clicks', 'Cost',\n",
    "                            'Ar Day', 'Shortcode Name', 'DP.SV', 'shortcode_DP.SV',\n",
    "                            'Opportunity Cost', 'Offer Vertical']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ar30_df = filtered_ar30_df.groupby(['shortcode_DP.SV', 'Ar Day']).agg({'Revenue': 'sum', 'Cost': 'sum', 'Delivered': 'sum', 'Jump Page Clicks': 'sum', 'Clicks': 'sum', 'Opportunity Cost': 'sum', 'Optout': 'sum'}).reset_index()\n",
    "grouped_ar7_df = filtered_ar7_df.groupby(['shortcode_DP.SV', 'Ar Day']).agg({'Revenue': 'sum', 'Cost': 'sum', 'Delivered': 'sum', 'Jump Page Clicks': 'sum', 'Clicks': 'sum', 'Opportunity Cost': 'sum', 'Optout': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 day averages\n",
    "grouped_ar30_df['30 Day eCPM'] = grouped_ar30_df['Revenue'] / grouped_ar30_df['Delivered'] * 1000\n",
    "grouped_ar30_df['30 Day CTR'] = grouped_ar30_df['Clicks'] / grouped_ar30_df['Delivered']\n",
    "grouped_ar30_df['30 Day JCTR'] = grouped_ar30_df['Jump Page Clicks'] / grouped_ar30_df['Delivered']\n",
    "grouped_ar30_df['30 Day Optout Rate'] = grouped_ar30_df['Optout'] / grouped_ar30_df['Delivered']\n",
    "\n",
    "#7 day averages\n",
    "grouped_ar7_df['7 Day eCPM'] = grouped_ar7_df['Revenue'] / grouped_ar7_df['Delivered'] * 1000\n",
    "grouped_ar7_df['7 Day CTR'] = grouped_ar7_df['Clicks'] / grouped_ar7_df['Delivered']\n",
    "grouped_ar7_df['7 Day JCTR'] = grouped_ar7_df['Jump Page Clicks'] / grouped_ar7_df['Delivered']\n",
    "grouped_ar7_df['7 Day Optout Rate'] = grouped_ar7_df['Optout'] / grouped_ar7_df['Delivered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #percentages\n",
    "grouped_ar30_df['30 Day CTR'] = grouped_ar30_df['30 Day CTR'] * 100\n",
    "grouped_ar30_df['30 Day JCTR'] = grouped_ar30_df['30 Day JCTR'] * 100\n",
    "grouped_ar30_df['30 Day Optout Rate'] = grouped_ar30_df['30 Day Optout Rate'] * 100\n",
    "\n",
    "grouped_ar7_df['7 Day CTR'] = grouped_ar7_df['7 Day CTR'] * 100\n",
    "grouped_ar7_df['7 Day JCTR'] = grouped_ar7_df['7 Day JCTR'] * 100\n",
    "grouped_ar7_df['7 Day Optout Rate'] = grouped_ar7_df['7 Day Optout Rate'] * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = grouped_ar30_df.merge(grouped_ar7_df[['shortcode_DP.SV','Ar Day', '7 Day eCPM', '7 Day Optout Rate']], \n",
    "                                 on=['shortcode_DP.SV', 'Ar Day'], \n",
    "                                 how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percent difference between 30 day and 7 day eCPM with 30 day eCPM as the base\n",
    "merged_df['eCPM % Diff'] = (merged_df['7 Day eCPM'] - merged_df['30 Day eCPM']) / merged_df['30 Day eCPM'] * 100\n",
    "merged_df['Optout Rate % Diff'] = merged_df['7 Day Optout Rate'] - merged_df['30 Day Optout Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most recent Offer ID for AR and Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-223-ce9b7e1a9952>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_sms_ar['shortcode_DP.SV'] = active_sms_ar['Shortcode'] + '_' + active_sms_ar['DP.DS']\n",
      "<ipython-input-223-ce9b7e1a9952>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_sms_ar['Day'] = active_sms_ar['Day'].str.replace('AR', '').astype(float)\n",
      "/Users/nathan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "#Get Active SMS ARs from sms_ar\n",
    "active_sms_ar = sms_AR[sms_AR['Status'] == 'Active']\n",
    "active_sms_ar['shortcode_DP.SV'] = active_sms_ar['Shortcode'] + '_' + active_sms_ar['DP.DS']\n",
    "#remove AR portion from Day column and convert the remaining number to an integer\n",
    "active_sms_ar['Day'] = active_sms_ar['Day'].str.replace('AR', '').astype(float)\n",
    "active_sms_ar.rename(columns={'Day': 'Ar Day'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get active ARs from merged df\n",
    "merged_df = merged_df.merge(active_sms_ar[['shortcode_DP.SV', 'Ar Day']], on=['shortcode_DP.SV', 'Ar Day'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(active_sms_ar[['shortcode_DP.SV', 'Ar Day', 'Offer ID', 'Date Started']], on=['shortcode_DP.SV', 'Ar Day'], how='left')\n",
    "#convert Date Started to datetime\n",
    "merged_df['Date Started'] = pd.to_datetime(merged_df['Date Started'])\n",
    "\n",
    "#days since swap\n",
    "merged_df['Days Since Swap'] = (datetime.now() - timedelta(days=1) - merged_df['Date Started']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(merged_df.columns)\n",
    "cols.insert(2, cols.pop(cols.index('Offer ID')))\n",
    "merged_df = merged_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a new column called AR Check, if eCPM % Diff is less than -25 and Days Since Swap is greater than 7, then AR Check is 'Underperforming', else if ecpm % diff is less than -25 and days since swap is less than 7, then AR Check is 'In Review', else 'Good'\n",
    "# merged_df['AR Check'] = merged_df.apply(lambda row: 'Downtrending - Swap' if row['eCPM % Diff'] < -30 and row['Days Since Swap'] > 37 \n",
    "#                                         else ('In Review' if row['eCPM % Diff'] < -30 and row['Days Since Swap'] <= 7\n",
    "#                                         else ('Underperforming Swap' if row['eCPM % Diff'] < -30 and row['Days Since Swap'] > 7 and row['Days Since Swap'] <= 37 else 'Good')), \n",
    "#                                         axis=1)\n",
    "\n",
    "#if AR Check is 'Good' but 30 Day eCPM is less than 7, then AR Check is 'Underperforming'\n",
    "# merged_df['AR Check'] = merged_df.apply(lambda row: 'Underperforming' if row['AR Check'] == 'Good' and row['30 Day eCPM'] < 7 else row['AR Check'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['AR Check'] = merged_df.apply(lambda row: \n",
    "                                        'Downtrending - Swap' if ((row['30 Day eCPM'] > 14 and row['eCPM % Diff'] < -40 and row['Days Since Swap'] > 37) or \n",
    "                                                                  (row['30 Day eCPM'] >= 7 and row['30 Day eCPM'] <= 14 and row['eCPM % Diff'] < -25 and row['Days Since Swap'] > 37)) \n",
    "                                        else ('In Review - Swap' if ((row['30 Day eCPM'] > 14 and row['eCPM % Diff'] < -40) or \n",
    "                                                                     (row['30 Day eCPM'] >= 7 and row['30 Day eCPM'] <= 14 and row['eCPM % Diff'] < -25)) and row['Days Since Swap'] <= 7 \n",
    "                                        else ('Underperforming Swap' if ((row['30 Day eCPM'] > 14 and row['eCPM % Diff'] < -40) or \n",
    "                                                                         (row['30 Day eCPM'] >= 7 and row['30 Day eCPM'] <= 14 and row['eCPM % Diff'] < -25)) and row['Days Since Swap'] > 7 and row['Days Since Swap'] <= 37 \n",
    "                                        else 'Good')), axis=1)\n",
    "\n",
    "merged_df['AR Check'] = merged_df.apply(lambda row: 'Below Cost eCPM' if row['AR Check'] == 'Good' and row['7 Day eCPM'] < 7 else row['AR Check'], axis=1)\n",
    "merged_df['AR Check'] = merged_df.apply(lambda row: 'In Review - Swap' if row['AR Check'] == 'Below Cost eCPM' and row['7 Day eCPM'] < 7 and row['Days Since Swap'] <= 7 else row['AR Check'], axis=1)\n",
    "\n",
    "merged_df['AR Check'] = merged_df.apply(lambda row: 'Optout Rate Increase' if row['AR Check'] == 'Underperforming Swap' and row['Optout Rate % Diff'] >= 2 else row['AR Check'], axis=1)\n",
    "\n",
    "#check if 7 day eCPM exists, if not, then AR Check is \"Potential Data Issue\"\n",
    "merged_df['AR Check'] = merged_df.apply(lambda row: 'Potential Data Issue' if pd.isnull(row['7 Day eCPM']) else row['AR Check'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert merged_df Offer ID to string\n",
    "# merged_df['Offer ID'] = merged_df['Offer ID'].astype(str).str.replace(r'\\.0$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY DMA Account\n",
    "merged_df['extracted_DP.SV'] = merged_df['shortcode_DP.SV'].str.split('_').str[-1]\n",
    "\n",
    "#merge using 'extracted_DP.SV' and 'DP.SV'\n",
    "merged_df = pd.merge(merged_df, pub_config[['DP.SV', 'DMA']], \n",
    "                     left_on='extracted_DP.SV', right_on='DP.SV', how='left')\n",
    "\n",
    "#drop temp columns\n",
    "merged_df = merged_df.drop(columns=['extracted_DP.SV', 'DP.SV'])\n",
    "\n",
    "dma_separated_dfs = {}\n",
    "for dma in merged_df['DMA'].unique():\n",
    "    if pd.notna(dma):  # Ensure that the 'DMA' value is not NaN\n",
    "        dma_separated_dfs[dma] = merged_df[merged_df['DMA'] == dma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframes for statuses sorted\n",
    "good = merged_df[merged_df['AR Check'] == 'Good']\n",
    "good = good.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "downtrending_swaps = merged_df[merged_df['AR Check'] == 'Downtrending - Swap']\n",
    "downtrending_swaps = downtrending_swaps.sort_values(by=['DMA', 'shortcode_DP.SV','Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "in_review = merged_df[merged_df['AR Check'] == 'In Review - Swap']\n",
    "in_review = in_review.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "underperforming_swaps = merged_df[merged_df['AR Check'] == 'Underperforming Swap']\n",
    "underperforming_swaps = underperforming_swaps.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "below_cost = merged_df[merged_df['AR Check'] == 'Below Cost eCPM']\n",
    "below_cost = below_cost.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "optout_rate_increase = merged_df[merged_df['AR Check'] == 'Optout Rate Increase']\n",
    "optout_rate_increase = optout_rate_increase.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n",
    "\n",
    "potential_data_issue = merged_df[merged_df['AR Check'] == 'Potential Data Issue']\n",
    "potential_data_issue = potential_data_issue.sort_values(by=['DMA','shortcode_DP.SV', 'Days Since Swap'], ascending=[True, True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output file\n",
    "filename = filepath.output_folder+'/AR Offer Alert - {}.xlsx'.format(datetime.today().strftime(\"%m_%d_%Y\"))\n",
    "\n",
    "#create writer\n",
    "writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    for dma, df in dma_separated_dfs.items():\n",
    "        sheet_name = f'{dma} - AR Offers'  # dynamic sheet name based on the DMA\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)  # Writing data to different sheets\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    good.to_excel(writer, sheet_name='Good', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    downtrending_swaps.to_excel(writer, sheet_name='Downtrending - Swap', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    underperforming_swaps.to_excel(writer, sheet_name='Underperforming Swaps', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    in_review.to_excel(writer, sheet_name='In Review - Swap', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    below_cost.to_excel(writer, sheet_name='Below Cost', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    optout_rate_increase.to_excel(writer, sheet_name='Optout Rate Increase', index=False)\n",
    "\n",
    "with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "    potential_data_issue.to_excel(writer, sheet_name='Potential Data Issue', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_body = \"Hi Team, here is the Daily AR Offer Alert Report \\n\\n\"\n",
    "email_body += \"Current Downtrending Threshold: 25% to 40%\\n\"\n",
    "email_body += \"Downtrending Swaps: Downtrend eCPM difference and Days Since Last Swap > 37\\n\"\n",
    "email_body += \"Underperforming Swaps: Recently swapped ARs with downtrend and Days Since Last Swap > 7 and <= 37\\n\"\n",
    "email_body += \"In Review - Swap: Swaps to be reviewed for the next 7 days\\n\"\n",
    "email_body += \"Below Cost eCPM: 7 Day eCPM is less than $7\\n\"\n",
    "email_body += \"Optout Rate Increase: Optout Rate % Diff >= 2% and Is Also Underperforming Swap\\n\\n\"\n",
    "\n",
    "\n",
    "email_body += \"Please check the current downtrending ARs and swap:\\n\\n\"\n",
    "#add to email_body and for each DMA, add the count of downtrending swaps \n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {downtrending_swaps[downtrending_swaps['DMA'] == dma].shape[0]} downtrending swaps\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the current underperforming swaps and swap back or to a new offer:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {underperforming_swaps[underperforming_swaps['DMA'] == dma].shape[0]} underperforming swaps\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the recently swapped ARs that are in review and pay attention to performance changes:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {in_review[in_review['DMA'] == dma].shape[0]} swaps in review\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the for ARs under cost eCPM and swap or remove the AR:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {below_cost[below_cost['DMA'] == dma].shape[0]} ARs below cost\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the ARs with increased optout rates and swap:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {optout_rate_increase[optout_rate_increase['DMA'] == dma].shape[0]} swaps with an increased optout rate of 2%+\\n\"\n",
    "\n",
    "email_body += \"\\nPlease check the ARs with potential data issues:\\n\\n\"\n",
    "for dma, df in dma_separated_dfs.items():\n",
    "    if pd.notna(dma):\n",
    "        email_body += f\"{dma} - {potential_data_issue[potential_data_issue['DMA'] == dma].shape[0]} ARs with potential data issues\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode_DP.SV</th>\n",
       "      <th>Ar Day</th>\n",
       "      <th>Offer ID</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Delivered</th>\n",
       "      <th>Jump Page Clicks</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Opportunity Cost</th>\n",
       "      <th>Optout</th>\n",
       "      <th>30 Day eCPM</th>\n",
       "      <th>30 Day CTR</th>\n",
       "      <th>30 Day JCTR</th>\n",
       "      <th>30 Day Optout Rate</th>\n",
       "      <th>7 Day eCPM</th>\n",
       "      <th>7 Day Optout Rate</th>\n",
       "      <th>eCPM % Diff</th>\n",
       "      <th>Optout Rate % Diff</th>\n",
       "      <th>Date Started</th>\n",
       "      <th>Days Since Swap</th>\n",
       "      <th>AR Check</th>\n",
       "      <th>DMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>SVT_AL.PL.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12113</td>\n",
       "      <td>3175.13</td>\n",
       "      <td>220.16232</td>\n",
       "      <td>43683.0</td>\n",
       "      <td>3546.0</td>\n",
       "      <td>6246.0</td>\n",
       "      <td>2249.134625</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>72.685713</td>\n",
       "      <td>14.298469</td>\n",
       "      <td>8.117574</td>\n",
       "      <td>4.170959</td>\n",
       "      <td>56.578823</td>\n",
       "      <td>4.549752</td>\n",
       "      <td>-22.159637</td>\n",
       "      <td>0.378793</td>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Nathan Mai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SVT_AL.PL.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12088</td>\n",
       "      <td>276.89</td>\n",
       "      <td>173.91276</td>\n",
       "      <td>34506.5</td>\n",
       "      <td>534.0</td>\n",
       "      <td>1849.5</td>\n",
       "      <td>-454.971384</td>\n",
       "      <td>910.5</td>\n",
       "      <td>8.024285</td>\n",
       "      <td>5.359860</td>\n",
       "      <td>1.547535</td>\n",
       "      <td>2.638633</td>\n",
       "      <td>6.477273</td>\n",
       "      <td>2.882687</td>\n",
       "      <td>-19.279132</td>\n",
       "      <td>0.244054</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>In Review - Swap</td>\n",
       "      <td>Nathan Mai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>SVT_AL.PL.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11646</td>\n",
       "      <td>60.00</td>\n",
       "      <td>162.55008</td>\n",
       "      <td>32252.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>-625.881020</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.860350</td>\n",
       "      <td>2.526975</td>\n",
       "      <td>0.421679</td>\n",
       "      <td>1.860350</td>\n",
       "      <td>3.603459</td>\n",
       "      <td>2.049968</td>\n",
       "      <td>93.697950</td>\n",
       "      <td>0.189618</td>\n",
       "      <td>2023-10-04</td>\n",
       "      <td>272.0</td>\n",
       "      <td>Below Cost eCPM</td>\n",
       "      <td>Nathan Mai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shortcode_DP.SV  Ar Day Offer ID  Revenue       Cost  Delivered  \\\n",
       "113     SVT_AL.PL.2     0.0    12113  3175.13  220.16232    43683.0   \n",
       "114     SVT_AL.PL.2     1.0    12088   276.89  173.91276    34506.5   \n",
       "115     SVT_AL.PL.2     2.0    11646    60.00  162.55008    32252.0   \n",
       "\n",
       "     Jump Page Clicks  Clicks  Opportunity Cost  Optout  30 Day eCPM  \\\n",
       "113            3546.0  6246.0       2249.134625  1822.0    72.685713   \n",
       "114             534.0  1849.5       -454.971384   910.5     8.024285   \n",
       "115             136.0   815.0       -625.881020   600.0     1.860350   \n",
       "\n",
       "     30 Day CTR  30 Day JCTR  30 Day Optout Rate  7 Day eCPM  \\\n",
       "113   14.298469     8.117574            4.170959   56.578823   \n",
       "114    5.359860     1.547535            2.638633    6.477273   \n",
       "115    2.526975     0.421679            1.860350    3.603459   \n",
       "\n",
       "     7 Day Optout Rate  eCPM % Diff  Optout Rate % Diff Date Started  \\\n",
       "113           4.549752   -22.159637            0.378793   2024-03-20   \n",
       "114           2.882687   -19.279132            0.244054   2024-06-27   \n",
       "115           2.049968    93.697950            0.189618   2023-10-04   \n",
       "\n",
       "     Days Since Swap          AR Check         DMA  \n",
       "113            104.0              Good  Nathan Mai  \n",
       "114              5.0  In Review - Swap  Nathan Mai  \n",
       "115            272.0   Below Cost eCPM  Nathan Mai  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show me merged_df where shortcode_DP.SV is SVT_AL.PL.2\n",
    "merged_df[merged_df['shortcode_DP.SV'] == 'SVT_AL.PL.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toaddr = ['sms@rxmg.com','offernotices@rxmg.com']\n",
    "toaddr = ['nathan@rxmg.com']\n",
    "today = datetime.today().strftime(\"%m_%d_%Y\")\n",
    "subject_line = f\"SMS Daily AR Offer Alert Report - {today}\"\n",
    "\n",
    "for i in toaddr:\n",
    "    send_email.send_email([filename],subject_line,email_body,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
