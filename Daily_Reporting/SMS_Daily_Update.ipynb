{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa84859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:00:55.815503Z",
     "start_time": "2023-08-10T15:57:41.600924Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pygsheets/worksheet.py:1477: UserWarning: At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.\n",
      "  warnings.warn('At least one column name in the data frame is an empty string. If this is a concern, please specify include_tailing_empty=False and/or ensure that each column containing data has a name.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127149385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (7,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (7,9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (7,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:127: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:132: DtypeWarning: Columns (7,9,10,11,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  combined_csv = pd.read_csv(localfolder + 'SMS_master_revenue.csv', dtype={'advertiser_name':'str','campaign_name':'str'})\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/263324719.py:134: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  daily_revenue['date'] = pd.to_datetime(daily_revenue['date']).dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5617932.581938998\n",
      "5617932.581938998\n",
      "6548036.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>advertiser_name</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>affiliate_name</th>\n",
       "      <th>subid_1</th>\n",
       "      <th>subid_2</th>\n",
       "      <th>subid_3</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue</th>\n",
       "      <th>plcategory_name</th>\n",
       "      <th>plsubcategory_name</th>\n",
       "      <th>Jump Page Clicks</th>\n",
       "      <th>subid_1 uc</th>\n",
       "      <th>subid_2 uc</th>\n",
       "      <th>subid_5 uc</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>first_split</th>\n",
       "      <th>Dash_Date_from_subid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2563016</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>Progrexion</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>Lexington Law Linkout - 33824 - Progrexion (SMS)</td>\n",
       "      <td>460917.0</td>\n",
       "      <td>460917</td>\n",
       "      <td>1 - SMS LM: Jet Marketing</td>\n",
       "      <td>460917</td>\n",
       "      <td>MP_FT_460917_CT4231_JM.OP_C15_6571_82162_30Jun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>MP_FT_460917_CT4231_JM.OP_C15_6571_82162_30Jun...</td>\n",
       "      <td>MP</td>\n",
       "      <td>2021-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574054</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>Progrexion</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>Lexington Law Linkout - 33824 - Progrexion (SMS)</td>\n",
       "      <td>460939.0</td>\n",
       "      <td>460939</td>\n",
       "      <td>1 - SMS LM: Aramis_Credit</td>\n",
       "      <td>460939</td>\n",
       "      <td>03.04.21_ARM_460939_a_6571_SC_MP_j3-l_||postid||</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>03.04.21_ARM_460939_a_6571_SC_MP_j3-l_||postid||</td>\n",
       "      <td>03.04.21</td>\n",
       "      <td>2021-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599482</th>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>Progrexion</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>Lexington Law Linkout - 33824 - Progrexion (SMS)</td>\n",
       "      <td>460654.0</td>\n",
       "      <td>460654</td>\n",
       "      <td>1 - SMS: RentOwnClub</td>\n",
       "      <td>460654</td>\n",
       "      <td>MP_HZB_460654_CT4073_I.RC_C45_6269_44345_15Jun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SMS</td>\n",
       "      <td>RentOwnClub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>MP_HZB_460654_CT4073_I.RC_C45_6269_44345_15Jun...</td>\n",
       "      <td>MP</td>\n",
       "      <td>2021-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616897</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>Progrexion</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>Lexington Law Linkout - 33824 - Progrexion (SMS)</td>\n",
       "      <td>460654.0</td>\n",
       "      <td>460654</td>\n",
       "      <td>1 - SMS: RentOwnClub</td>\n",
       "      <td>460654</td>\n",
       "      <td>MP_HZB_460654_CT3983_I.RC_C15_6264_44345_6Jun2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SMS</td>\n",
       "      <td>RentOwnClub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>MP_HZB_460654_CT3983_I.RC_C15_6264_44345_6Jun2...</td>\n",
       "      <td>MP</td>\n",
       "      <td>2021-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975880</th>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>SMS_SS_SC_HZB_44345_460654_416732_6264_124652_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>SMS_SS_SC_HZB_44345_460654_416732_6264_124652_...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>2022-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875352</th>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_2Sep23...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_2Sep23...</td>\n",
       "      <td>SS</td>\n",
       "      <td>2023-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875353</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_30Aug2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_30Aug2...</td>\n",
       "      <td>SS</td>\n",
       "      <td>2023-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875354</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_31Aug2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_31Aug2...</td>\n",
       "      <td>SS</td>\n",
       "      <td>2023-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875355</th>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_3Sep23...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SS_SC_MBC_80837_461680_AR0_11468_514234_3Sep23...</td>\n",
       "      <td>SS</td>\n",
       "      <td>2023-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955608</th>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>SS_SC_FLC_51797_461681_576625_11468_503440_13J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>SS_SC_FLC_51797_461681_576625_11468_503440_13J...</td>\n",
       "      <td>SS</td>\n",
       "      <td>2023-07-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date advertiser_name  campaign_id  \\\n",
       "2563016 2021-06-30      Progrexion       8202.0   \n",
       "2574054 2021-06-24      Progrexion       8202.0   \n",
       "2599482 2021-06-15      Progrexion       8202.0   \n",
       "2616897 2021-06-06      Progrexion       8202.0   \n",
       "3975880 2022-11-02             NaN       8202.0   \n",
       "...            ...             ...          ...   \n",
       "5875352 2023-09-02             NaN       8202.0   \n",
       "5875353 2023-08-30             NaN       8202.0   \n",
       "5875354 2023-08-31             NaN       8202.0   \n",
       "5875355 2023-09-03             NaN       8202.0   \n",
       "5955608 2023-07-13             NaN       8202.0   \n",
       "\n",
       "                                            campaign_name   site_id  \\\n",
       "2563016  Lexington Law Linkout - 33824 - Progrexion (SMS)  460917.0   \n",
       "2574054  Lexington Law Linkout - 33824 - Progrexion (SMS)  460939.0   \n",
       "2599482  Lexington Law Linkout - 33824 - Progrexion (SMS)  460654.0   \n",
       "2616897  Lexington Law Linkout - 33824 - Progrexion (SMS)  460654.0   \n",
       "3975880                                               NaN       NaN   \n",
       "...                                                   ...       ...   \n",
       "5875352                                               NaN       NaN   \n",
       "5875353                                               NaN       NaN   \n",
       "5875354                                               NaN       NaN   \n",
       "5875355                                               NaN       NaN   \n",
       "5955608                                               NaN       NaN   \n",
       "\n",
       "         affiliate_id             affiliate_name subid_1  \\\n",
       "2563016        460917  1 - SMS LM: Jet Marketing  460917   \n",
       "2574054        460939  1 - SMS LM: Aramis_Credit  460939   \n",
       "2599482        460654       1 - SMS: RentOwnClub  460654   \n",
       "2616897        460654       1 - SMS: RentOwnClub  460654   \n",
       "3975880        460654                        NaN     nan   \n",
       "...               ...                        ...     ...   \n",
       "5875352        461680                        NaN     nan   \n",
       "5875353        461680                        NaN     nan   \n",
       "5875354        461680                        NaN     nan   \n",
       "5875355        461680                        NaN     nan   \n",
       "5955608        461681                        NaN     nan   \n",
       "\n",
       "                                                   subid_2 subid_3  ...  \\\n",
       "2563016  MP_FT_460917_CT4231_JM.OP_C15_6571_82162_30Jun...     NaN  ...   \n",
       "2574054   03.04.21_ARM_460939_a_6571_SC_MP_j3-l_||postid||     NaN  ...   \n",
       "2599482  MP_HZB_460654_CT4073_I.RC_C45_6269_44345_15Jun...     NaN  ...   \n",
       "2616897  MP_HZB_460654_CT3983_I.RC_C15_6264_44345_6Jun2...     NaN  ...   \n",
       "3975880  SMS_SS_SC_HZB_44345_460654_416732_6264_124652_...     NaN  ...   \n",
       "...                                                    ...     ...  ...   \n",
       "5875352  SS_SC_MBC_80837_461680_AR0_11468_514234_2Sep23...     NaN  ...   \n",
       "5875353  SS_SC_MBC_80837_461680_AR0_11468_514234_30Aug2...     NaN  ...   \n",
       "5875354  SS_SC_MBC_80837_461680_AR0_11468_514234_31Aug2...     NaN  ...   \n",
       "5875355  SS_SC_MBC_80837_461680_AR0_11468_514234_3Sep23...     NaN  ...   \n",
       "5955608  SS_SC_FLC_51797_461681_576625_11468_503440_13J...     NaN  ...   \n",
       "\n",
       "        revenue plcategory_name  plsubcategory_name Jump Page Clicks  \\\n",
       "2563016     NaN             SMS                  LM              NaN   \n",
       "2574054     NaN             SMS                  LM              NaN   \n",
       "2599482     NaN             SMS         RentOwnClub              NaN   \n",
       "2616897     NaN             SMS         RentOwnClub              NaN   \n",
       "3975880     NaN             NaN                 NaN              4.0   \n",
       "...         ...             ...                 ...              ...   \n",
       "5875352     NaN             NaN                 NaN              1.0   \n",
       "5875353     NaN             NaN                 NaN              1.0   \n",
       "5875354     NaN             NaN                 NaN              1.0   \n",
       "5875355     NaN             NaN                 NaN              1.0   \n",
       "5955608     NaN             NaN                 NaN              1.0   \n",
       "\n",
       "         subid_1 uc  subid_2 uc  subid_5 uc  \\\n",
       "2563016           0          10           0   \n",
       "2574054           0           8           0   \n",
       "2599482           0          13           0   \n",
       "2616897           0          13           0   \n",
       "3975880           0          10           0   \n",
       "...             ...         ...         ...   \n",
       "5875352           0           9           0   \n",
       "5875353           0           9           0   \n",
       "5875354           0           9           0   \n",
       "5875355           0           9           0   \n",
       "5955608           0           9           0   \n",
       "\n",
       "                                                    sub_id first_split  \\\n",
       "2563016  MP_FT_460917_CT4231_JM.OP_C15_6571_82162_30Jun...          MP   \n",
       "2574054   03.04.21_ARM_460939_a_6571_SC_MP_j3-l_||postid||    03.04.21   \n",
       "2599482  MP_HZB_460654_CT4073_I.RC_C45_6269_44345_15Jun...          MP   \n",
       "2616897  MP_HZB_460654_CT3983_I.RC_C15_6264_44345_6Jun2...          MP   \n",
       "3975880  SMS_SS_SC_HZB_44345_460654_416732_6264_124652_...         SMS   \n",
       "...                                                    ...         ...   \n",
       "5875352  SS_SC_MBC_80837_461680_AR0_11468_514234_2Sep23...          SS   \n",
       "5875353  SS_SC_MBC_80837_461680_AR0_11468_514234_30Aug2...          SS   \n",
       "5875354  SS_SC_MBC_80837_461680_AR0_11468_514234_31Aug2...          SS   \n",
       "5875355  SS_SC_MBC_80837_461680_AR0_11468_514234_3Sep23...          SS   \n",
       "5955608  SS_SC_FLC_51797_461681_576625_11468_503440_13J...          SS   \n",
       "\n",
       "        Dash_Date_from_subid  \n",
       "2563016           2021-06-30  \n",
       "2574054           2021-06-24  \n",
       "2599482           2021-06-15  \n",
       "2616897           2021-06-06  \n",
       "3975880           2022-11-02  \n",
       "...                      ...  \n",
       "5875352           2023-09-02  \n",
       "5875353           2023-08-30  \n",
       "5875354           2023-08-31  \n",
       "5875355           2023-09-03  \n",
       "5955608           2023-07-13  \n",
       "\n",
       "[1195 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import filepath\n",
    "import send_email \n",
    "import pygsheets\n",
    "import infrastructure \n",
    "\n",
    "\n",
    "localfolder=filepath.output_folder\n",
    "\n",
    "#import publisher from google sheet \n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "rxmgref = gc.open_by_url('https://docs.google.com/spreadsheets/d/1Tzda6Djr3zQmOhWu7Ief3GVR9Cjaml8238CeX7chj_U/edit#gid=1620368362') \n",
    "publisher_raw  = rxmgref.worksheet('title','Publisher Configurations').get_as_df()\n",
    "publisher_raw.to_csv(localfolder+'smartsheet/Publisher.csv')\n",
    "publisher = publisher_raw[['NEW DP.DS or DP.sV','PUBID']].drop_duplicates()\n",
    "\n",
    "# import SMS OMS\n",
    "offer_sheet = infrastructure.get_smartsheet('offers_sms')\n",
    "\n",
    "## import La Nina. \n",
    "gc = pygsheets.authorize(service_account_file=filepath.service_account_location)\n",
    "lanina = gc.open_by_url('https://docs.google.com/spreadsheets/d/1obszkCQoE0ELOR1O0CrLVETUEmEIWlGuyAmK3FgWSJg/edit#gid=1099746391') \n",
    "lanina_sheet  = lanina.worksheet('title','La Nina (Current)').get_as_df()\n",
    "lanina_sheet.to_csv(localfolder+'smartsheet/La_Nina.csv')\n",
    "\n",
    "## EMIT \n",
    "emit = infrastructure.get_smartsheet('emit')\n",
    "email_pubid = emit['Revenue Pub ID'].astype(str).str.split('.',expand = True)[0].unique().tolist()\n",
    "\n",
    "jobs = pd.read_csv(localfolder + 'SMS_SC_SS_Jobs.csv', dtype={'job_id' :'Int64'})\n",
    "creative_stats = pd.read_csv(localfolder + 'SMS_SC_SS_CreativesStats.csv', dtype={'CreativeId' :'str'})\n",
    "raw_creative_stats = creative_stats\n",
    "offers = pd.read_csv(localfolder + 'SMS_SC_SS_Offers.csv', usecols = ['name','hitpath_offer_id', 'type','status','redirect_type','conversion_event','conversion_payout','currency'] )\n",
    "historic_data = pd.read_csv(localfolder + 'SS_data.csv')#  data before Nov1\n",
    "flows = pd.read_csv(localfolder + 'SMS_SC_SS_Flows.csv')\n",
    "\n",
    "# add some information in flows\n",
    "flows['Revenue Source'] = 'Short Code - SS Flow'\n",
    "flows['Code_Type'] = 'Short Code' \n",
    "flows['Shortcode Name'] = flows['Name'].str.split('-',expand = True)[1]\n",
    "flows['Shortcode1'] = flows['Shortcode'].str.extract('(\\d{5})')\n",
    "flows = flows.drop('Shortcode',axis = 1)\n",
    "flows['Dataset'] = flows['Name'].str.split('-',expand = True)[0]\n",
    "flows['Dataset'] = flows['Dataset'].str.replace('JM.ONP','JET.ONP')\n",
    "flows['Dataset'] = flows['Dataset'].str.replace('JM.NTC','JET.NTC')\n",
    "flows = flows.rename(columns=({'CountDeliver':'Delivered', 'CostDeliver':'Cost','CountClick':'Clicks','Shortcode1':'Shortcode', 'CountUnsub':'Optout'}))\n",
    "flows['Date'] = pd.to_datetime(flows['Period'].str[:10])\n",
    "flows['AR Flow ID']=flows['Id'].astype('str')\n",
    "flows['AR Day'] = flows['OfferName'].str.extract('(\\d+)\\s*\\(')\n",
    "flows.loc[flows['AR Day'].isna(),'AR Day'] =  flows['OfferName'].str.extract('AR(\\d)')[0]\n",
    "flows.loc[flows['AR Day'].isna(),'AR Day'] = 'Null'\n",
    "flows['Hitpath ID'] = flows['OfferName'].str.extract(r'(\\d{4,5})')\n",
    "flows['AR Flow'] = flows['AR Flow ID'] + '_Day_' + flows['Shortcode Name']+'_'+  flows['AR Day']\n",
    "flows_clean = flows[['Hitpath ID','Date','Dataset','Shortcode','Shortcode Name','Revenue Source','Code_Type','Delivered','Optout','Cost','Clicks','AR Flow','AR Day','AR Flow ID']]\n",
    "flows_clean = flows_clean.merge(publisher[['NEW DP.DS or DP.sV','PUBID']], left_on ='Dataset', right_on = 'NEW DP.DS or DP.sV', how = 'left' )\n",
    "flows_clean = flows_clean.rename(columns=({'PUBID':'Affiliate_id'}))\n",
    "flows_clean.loc[flows_clean['Shortcode Name'] == 'FLC', 'Shortcode'] = '51797'\n",
    "flows_clean.loc[flows_clean['Shortcode Name'] == 'CSS', 'Shortcode'] = '70610'\n",
    "flows_clean.loc[flows_clean['Shortcode Name'] == 'HZB', 'Shortcode'] = '44345'\n",
    "flows_clean.loc[flows_clean['Shortcode Name'] == 'MBC', 'Shortcode'] = '80837'\n",
    "flows_clean.loc[flows_clean['Shortcode'] == '51797', 'Shortcode Name'] = 'FLC'\n",
    "flows_clean.loc[flows_clean['Shortcode'] == '70610', 'Shortcode Name'] = 'CSS'\n",
    "flows_clean.loc[flows_clean['Shortcode'] == '44345', 'Shortcode Name'] = 'HZB'\n",
    "flows_clean.loc[flows_clean['Shortcode'] == '80837', 'Shortcode Name'] = 'MBC'\n",
    "\n",
    "# change some segment name \n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('WW.YFA','WWM.YFA')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('ARM.CR','AI.CC')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('RH.3CS','RHD.CC')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('ED.247L','EDM.247L')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('PA.PS','PA.SWP')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('FM.YS','FSM.YS')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('CM_','CM.OSR_')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('CM.OSR.OSR','CM.OSR')\n",
    "creative_stats['Segment'] = creative_stats['Segment'].str.replace('CM.OSR.OSR.OSR','CM.OSR')\n",
    "creative_stats = creative_stats.rename(columns=({'DeliverCount':'Delivered', 'TotalCost':'Cost','ClickCount':'Clicks','UnsubCount':'Optout'}))\n",
    "creative_id_na = creative_stats.loc[creative_stats['CreativeId'].isna()]\n",
    "jobs_optout = jobs[['id','optout']]\n",
    "creative_stats =  creative_stats.merge(jobs_optout, left_on = 'JobId' ,right_on='id', how='left')\n",
    "jobid_count = creative_stats['JobId'].value_counts().to_dict()\n",
    "creative_stats['Optout'] = creative_stats.apply(lambda row: row['optout'] / jobid_count[row['JobId']], axis=1)\n",
    "creative_stats = creative_stats.groupby(['JobId', 'Tstamp', 'Offer', 'Segment', 'CreativeId', 'CreativeName','Creative']).sum().reset_index()\n",
    "print(creative_stats['Delivered'].sum())\n",
    "jobs['segments'] = jobs['segments'].str.replace('WW.YFA','WWM.YFA')\n",
    "jobs['segments'] = jobs['segments'].str.replace('ARM.CR','AI.CC')\n",
    "jobs['segments'] = jobs['segments'].str.replace('RH.3CS','RHD.CC')\n",
    "jobs['segments'] = jobs['segments'].str.replace('ED.247L','EDM.247L')\n",
    "jobs['segments'] = jobs['segments'].str.replace('PA.PS','PA.SWP')\n",
    "jobs['segments'] = jobs['segments'].str.replace('FM.YS','FSM.YS')\n",
    "jobs['segments'] = jobs['segments'].str.replace('CM_','CM.OSR_')\n",
    "jobs['segments'] = jobs['segments'].str.replace('CM.OSR.OSR','CM.OSR')\n",
    "jobs['segments'] = jobs['segments'].str.replace('CM.OSR.OSR.OSR','CM.OSR')\n",
    "\n",
    "\n",
    "#clean jobs file\n",
    "#drop columns with nulls\n",
    "jobs.isna().sum()\n",
    "drop_columns_jobs = ['remote_status']\n",
    "jobs.drop(columns=drop_columns_jobs, inplace=True, axis=1)\n",
    "jobs = jobs.rename(columns={ 'id':'job_id', 'name':'job_name'})\n",
    "#convert date fields to correct format\n",
    "jobs['start_tstamp'] = pd.to_datetime(jobs['start_tstamp'])\n",
    "jobs['end_tstamp'] = pd.to_datetime(jobs['end_tstamp'])\n",
    "jobs['scheduled_tstamp'] = pd.to_datetime(jobs['scheduled_tstamp'],format = 'mixed')\n",
    "jobs['Scheduling Time'] = jobs['scheduled_tstamp'].dt.tz_convert('US/Pacific').dt.strftime('%Y-%m-%d %H:%M')\n",
    "creative_stats =  creative_stats.merge(jobs[['job_id','Scheduling Time']], left_on = 'JobId' ,right_on='job_id', how='left')\n",
    "creative_id_na =  creative_id_na.merge(jobs[['job_id','Scheduling Time']], left_on = 'JobId' ,right_on='job_id', how='left')\n",
    "\n",
    "#clean creative_stats\n",
    "creative_stats.isna().sum()\n",
    "creative_stats['Tstamp'] = pd.to_datetime(creative_stats['Tstamp'])\n",
    "\n",
    "#clean offers\n",
    "offers.isna().sum()\n",
    "offers = offers.rename(columns={ 'id':'offer_id', 'name':'offer'})\n",
    "\n",
    "#####engagement stats for all sends#####\n",
    "#merge above df with reveneu file to get all of reveneu information\n",
    "## combine all months revenue CSVs into one master-revenue file.\n",
    "os.chdir(localfolder + \"SMS Rev\")\n",
    "\n",
    "all_files = [i for i in glob.glob('*.{}'.format('csv'))]\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_files ])\n",
    "####Exporting master revenue file####\n",
    "combined_csv.to_csv( localfolder + \"SMS_master_revenue.csv\", index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "combined_csv = pd.read_csv(localfolder + 'SMS_master_revenue.csv', dtype={'advertiser_name':'str','campaign_name':'str'})\n",
    "daily_revenue = combined_csv\n",
    "daily_revenue['date'] = pd.to_datetime(daily_revenue['date']).dt.date\n",
    "daily_revenue_gpby = daily_revenue.groupby(['affiliate_id','date'])['amount'].sum().reset_index()\n",
    "jump_page_csv = pd.read_csv( localfolder+\"jumppage_click.csv\")\n",
    "jumppage_clicks = jump_page_csv.rename(columns = {'subid_1':\"subid_2\"})\n",
    "print(combined_csv['amount'].sum())\n",
    "combined_csv = pd.concat([combined_csv,jumppage_clicks])\n",
    "print(combined_csv['amount'].sum())\n",
    "print(combined_csv['Jump Page Clicks'].sum())\n",
    "#check subids\n",
    "subs = [\"subid_1\",\"subid_2\", \"subid_5\"]\n",
    "def sid(d):\n",
    "    sid = \"subid_3\"\n",
    "    for j in subs:\n",
    "        if d[f\"{j} uc\"]>=5:\n",
    "            sid = j\n",
    "    return d[sid]\n",
    "for i in subs:\n",
    "    combined_csv[i] = combined_csv[i].astype(str)\n",
    "    combined_csv[f\"{i} uc\"] = combined_csv[i].str.count(\"_\")\n",
    "#merge all subids from 1,2 and 5 in subid\n",
    "combined_csv[\"sub_id\"] = combined_csv.apply(sid,axis=1)\n",
    "\n",
    "########## SS BEGIN #########\n",
    "combined_csv['first_split']=combined_csv['sub_id'].str.split('_').str[0]\n",
    "\"\"\" \n",
    "jumppage_clicks[\"sub_id\"] = jumppage_clicks[\"subid_1\"]\n",
    "subs = [\"sub_id\"]\n",
    "# doing same cleaning with jumpapge files  \n",
    "for i in subs:\n",
    "    jumppage_clicks[i] = jumppage_clicks[i].astype(str)\n",
    "    jumppage_clicks[f\"{i} uc\"] = jumppage_clicks[i].str.count(\"_\")\n",
    "#merge all subids from 1,2 and 5 in subid\n",
    "\n",
    "jumppage_clicks['first_split']=jumppage_clicks['sub_id'].str.split('_').str[0]\n",
    "\"\"\"\n",
    "# get the date based on subid date \n",
    "combined_csv = combined_csv.reset_index(drop=True)\n",
    "combined_csv['Dash_Date_from_subid'] = combined_csv['sub_id'].str.extract(r'(\\d{1,2}[A-Za-z]{3}\\d{2})')\n",
    "combined_csv['Dash_Date_from_subid'] = pd.to_datetime(combined_csv['Dash_Date_from_subid'], format='%d%b%y',errors='coerce')\n",
    "combined_csv['date'] = pd.to_datetime(combined_csv['date'],errors='coerce')\n",
    "combined_csv.loc[combined_csv['Dash_Date_from_subid'].isna(),'Dash_Date_from_subid'] = combined_csv['date']\n",
    "combined_csv['date'] = combined_csv['Dash_Date_from_subid']\n",
    "combined_csv.loc[combined_csv['campaign_id']==8202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5efa5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:00:58.363893Z",
     "start_time": "2023-08-10T16:00:55.862467Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274.45000000000005\n",
      "274.45000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/2988448243.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lc_lanina['Long Code Content ID'] = lc_lanina['Long Code Content ID'].astype(str).str.zfill(5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nmerged_data = merged_data[['Date','Scheduling Time', 'Offer','Hitpath_Offer_ID','DP.SV','Affiliate_Id', 'DP&Pub','Job_Id', 'Job_Name','Creative_Id','Creativename','Creative','Send Strategy', 'Shortcode', 'Start_Tstamp', 'Segments', 'Revenue','Jump Page Clicks', 'Delivered', 'Not_Delivered', 'Optout', 'Clicks',\\n       'Cost', 'Ecpm', 'Time', 'Publisher', 'Campaign', 'Route',  'Carrier', 'Dataset', 'Message',\\n       'Responder Template', 'Keyword', 'Responder', 'Router Domain Name' , 'c1', 'Responded', 'Response Rate', 'CTR',\\n        'Gross Profit' , 'Gross Margin', 'RPU' ,'Provider', 'Code_Type','Revenue Source',\\n     'Ar Day','Sub_Id','Campaign_Id','Roi','Shortcode Name','Total']]\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Long Code data from MD\n",
    "\n",
    "lc = gc.open_by_url('https://docs.google.com/spreadsheets/d/1De9UzMw5POUuS90s7dMKsYNTQVnxTj1dvAvwMhOCC5U/edit#gid=0') \n",
    "lc_wk_df  = lc.worksheet('title','Long Code').get_as_df()\n",
    "lc_wk_df['SMS Cost'] = lc_wk_df['SMS Cost'].str.split('$',expand = True)[1].astype('float')\n",
    "lc_wk_df = lc_wk_df.rename(columns = {'Offer':'Sub_Id'})\n",
    "lc_rev = combined_csv.loc[(combined_csv['first_split']=='MD') | (combined_csv['first_split']=='TB') ]\n",
    "#lc_rev = combined_csv.loc[(combined_csv['first_split']=='MD') ]\n",
    "lc_rev.loc[lc_rev['Dash_Date_from_subid'].isna(), 'Dash_Date_from_subid'] = lc_rev['date']\n",
    "lc_rev =lc_rev.rename(columns = {\"Dash_Date_from_subid\":'Date'})\n",
    "#  define the pattern\n",
    "pattern = r'(.+\\d{1,2}[A-Za-z]{3}\\d{2})'\n",
    "# extract the pattern\n",
    "lc_rev['Sub_Id'] = lc_rev['sub_id'].str.extract(pattern)\n",
    "lc_rev_summary = lc_rev.groupby(['Sub_Id','Date'])['amount'].sum().reset_index()\n",
    "lc_df = pd.concat([lc_wk_df,lc_rev_summary],axis = 0, ignore_index=True)\n",
    "lc_df = lc_df.groupby(['Sub_Id','Date']).sum().reset_index()  \n",
    "lc_df = lc_df.fillna(0)\n",
    "                           \n",
    "                           \n",
    "lc_df.loc[lc_df['Sub_Id'] == '01JUN23_8838_W4_EDU_SVT','Sub_Id'] = 'MD_LC_OMG_SVT_460918__8838_OT_01JUN23'\n",
    "lc_df.loc[lc_df['Sub_Id'] == '05Jun23_MD_LC_OMG_SVT_460918_W1_11714_T1','Sub_Id'] = 'MD_LC_OMG_SVT_460918__11714_OT_05Jun23'\n",
    "lc_df.loc[lc_df['Sub_Id'] == '11714-2_OMG_SVT','Sub_Id'] = 'MD_LC_OMG_SVT_460918__11714_OT_'\n",
    "lc_df.loc[lc_df['Sub_Id'] == 'MD_LC_OMG_SVT_460919_00066_9088__29Jul23','Sub_Id'] = 'MD_LC_OMG_SVT_460919_00066_9088_P_29Jul23'\n",
    "lc_df.loc[lc_df['Sub_Id'] == 'MD_LC_OMG_SVT_460920_00068_12076__30Jul23','Sub_Id']  = 'MD_LC_OMG_SVT_460920_00068_12076_P_30Jul23'\n",
    "lc_df['split_column'] = lc_df['Sub_Id'].str.split('_')\n",
    "lc_df['subid_uc'] = lc_df['Sub_Id'].str.count('_')\n",
    "lc_df['Date'] = lc_df['split_column'].str[8]\n",
    "lc_df['Date']= pd.to_datetime(lc_df['Date'], format='%d%b%y',errors='coerce')\n",
    "lc_df['Send Strategy'] = lc_df['split_column'].str[7]\n",
    "lc_df['Hitpath_Offer_ID'] = lc_df['split_column'].str[6]\n",
    "lc_df['Affiliate_Id'] = lc_df['split_column'].str[4]\n",
    "lc_df['Long Code Content ID'] = lc_df['split_column'].str[5]\n",
    "lc_df['Shortcode Name'] = ''\n",
    "lc_df.loc[lc_df['split_column'].str[3] == 'SVT','Shortcode Name' ] = 'SVT'\n",
    "lc_df.loc[lc_df['split_column'].str[3] == 'UAA','Shortcode Name' ] = 'UAA'\n",
    "lc_df['Send Strategy'] = lc_df['Send Strategy'].str.replace('T0','OT')\n",
    "lc_df['Send Strategy'] = lc_df['Send Strategy'].str.replace('T1','OT') \n",
    "lc_df.loc[lc_df['split_column'].str[0] == 'TB', 'Revenue Source'] = 'Long Code - Textback'\n",
    "lc_df.loc[lc_df['split_column'].str[0] == 'MD', 'Revenue Source'] = 'Long Code - Mobile Drips'\n",
    "lc_df.loc[lc_df['split_column'].str[0] == 'TB', 'Send Strategy'] = 'P'\n",
    "lc_df.loc[lc_df['split_column'].str[0] == 'TB', 'Long Code Content ID'] = np.nan\n",
    "\n",
    "# currently we don't consider split test content option \n",
    "lc_df['amount'] = lc_df['amount'].fillna(0)\n",
    "print(lc_df.loc[lc_df['split_column'].str[0] == 'MD',]['amount'].sum())\n",
    "lc_lanina = lanina_sheet[(lanina_sheet['Long Code Content ID'].isna() == False) & ((lanina_sheet['Long Code Content ID'] !=\"\"))]\n",
    "lc_lanina['Long Code Content ID'] = lc_lanina['Long Code Content ID'].astype(str).str.zfill(5)\n",
    "lc_df_full = lc_df.merge(lc_lanina[['Long Code Content ID','Reporting Content ID','Content']],copy = False, how= 'left', on = 'Long Code Content ID')\n",
    "print(lc_df_full.loc[lc_df_full['split_column'].str[0] == 'MD',]['amount'].sum())\n",
    "lc_df_full['Code_Type'] = 'Long Code'\n",
    "lc_df_full_11 = lc_df_full[lc_df_full['Date'] >= '2022-11-01']\n",
    "\n",
    "lc_df_full = lc_df_full.rename(columns = {'Qty':'Sent','Daily Success Qty':'Delivered','Fail Qty': 'Undelivered',\\\n",
    "                            'Clicks Qty':'Clicks','SMS Cost':'Cost',\\\n",
    "                            'amount':'Revenue','Long Code Content ID':'Creative_Id', 'Reporting Content ID':'Creativename','Content':'Creative'})\n",
    "\n",
    "lc_df_full = lc_df_full[['Date','Affiliate_Id', 'Hitpath_Offer_ID','Sent','Delivered','Undelivered','Clicks',\\\n",
    "       'Cost','Revenue', 'Send Strategy', 'Shortcode Name', 'Revenue Source', 'Code_Type','Sub_Id','Creative_Id','Creativename','Creative']]\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "merged_data = merged_data[['Date','Scheduling Time', 'Offer','Hitpath_Offer_ID','DP.SV','Affiliate_Id', 'DP&Pub','Job_Id', 'Job_Name','Creative_Id','Creativename','Creative','Send Strategy', 'Shortcode', 'Start_Tstamp', 'Segments', 'Revenue','Jump Page Clicks', 'Delivered', 'Not_Delivered', 'Optout', 'Clicks',\n",
    "       'Cost', 'Ecpm', 'Time', 'Publisher', 'Campaign', 'Route',  'Carrier', 'Dataset', 'Message',\n",
    "       'Responder Template', 'Keyword', 'Responder', 'Router Domain Name' , 'c1', 'Responded', 'Response Rate', 'CTR',\n",
    "        'Gross Profit' , 'Gross Margin', 'RPU' ,'Provider', 'Code_Type','Revenue Source',\n",
    "     'Ar Day','Sub_Id','Campaign_Id','Roi','Shortcode Name','Total']]\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab42e1ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:00:58.364564Z",
     "start_time": "2023-08-10T16:00:57.517134Z"
    }
   },
   "outputs": [],
   "source": [
    "#flows_clean.to_csv('/Users/liliguo/Desktop/offer wall performance/creative_forflow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd487cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:01:35.522346Z",
     "start_time": "2023-08-10T16:00:57.519352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1195254.3580549995\n"
     ]
    }
   ],
   "source": [
    "combined_csv['date'] = pd.to_datetime(combined_csv['date'])\n",
    "combined_csv_ss_only = combined_csv[(combined_csv['first_split']=='SS')  |  (combined_csv['first_split']=='SMS')] \n",
    "combined_csv_ss_only = combined_csv_ss_only[combined_csv_ss_only['date']>='2022-11-01'].reset_index(drop=True)\n",
    "print(combined_csv_ss_only['amount'].sum())\n",
    "#combined_csv_ss_only= combined_csv_ss_only.drop_duplicates()\n",
    "#count number of underscores in subid\n",
    "combined_csv_ss_only['subid_uc'] = combined_csv_ss_only.sub_id.str.count('_')\n",
    "#combined_csv_ss_only['subid_uc']=combined_csv.sub_id.str.count('_')\n",
    "\n",
    "#ignoring the subids that  are not formatted correctly ex: SS_HZB_{{datasource_id}}_{{job_id}}_ALL.SMS_10434_SM_44345_{{today_d}}{{today_mon}}{{today_yy}}_1_{{member_id}}\n",
    "#they have very less revenue under them\n",
    "#these are with sub id uc <12\n",
    "combined_csv_ss_only = combined_csv_ss_only[combined_csv_ss_only['subid_uc'] < 12]\n",
    "\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['advertiser_name'] == 'NIC','campaign_id'] = 10267\n",
    "Offer_name = combined_csv_ss_only.groupby(['campaign_id','campaign_name']).count().reset_index()[['campaign_id','campaign_name']]\n",
    "\n",
    "# get jump page sum and revenue sum \n",
    "combined_csv_ss_only['split_column'] = combined_csv_ss_only['sub_id'].str.split('_')\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['first_split'] == 'SS')  , 'offer_id'] = combined_csv_ss_only['split_column'].str[6]\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['first_split'] == 'SMS')  , 'offer_id'] = combined_csv_ss_only['split_column'].str[7]\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['offer_id'].str.isdigit() == False), 'offer_id'] =  combined_csv_ss_only['split_column'].str[5]\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['offer_id'].str.isdigit() == False), 'offer_id'] =  combined_csv_ss_only['split_column'].str[4]\n",
    "combined_csv_ss_only['offer_id'] = combined_csv_ss_only['offer_id'].astype('str').str.split('.',expand = True)[0]\n",
    "combined_csv_ss_only['campaign_id']= combined_csv_ss_only['campaign_id'].astype('str').str.split('.',expand = True)[0]\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['campaign_id'].isna()) | (combined_csv_ss_only['campaign_id'] == 'nan'),'campaign_id' ] = combined_csv_ss_only['offer_id']\n",
    "combined_csv_ss_only['Offer Type'] = 'Single Offer'\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['campaign_id'] != combined_csv_ss_only['offer_id']), 'Offer Type' ] = 'Offer Wall'\n",
    "offerwall = combined_csv_ss_only.loc[combined_csv_ss_only['Offer Type']=='Offer Wall',]\n",
    "combined_csv_ss_only = combined_csv_ss_only[['date', 'campaign_id',\n",
    "       'affiliate_id',  'amount', 'Jump Page Clicks',\n",
    "        'sub_id', 'first_split','Dash_Date_from_subid', 'subid_uc','Offer Type']]\n",
    "combined_csv_ss_only['amount'] = combined_csv_ss_only['amount'].fillna(0)\n",
    "combined_csv_ss_only[ 'Jump Page Clicks'] = combined_csv_ss_only[ 'Jump Page Clicks'].fillna(0)\n",
    "combined_csv_ss_only = combined_csv_ss_only.groupby(['date', 'campaign_id', 'affiliate_id', 'sub_id', 'first_split','Dash_Date_from_subid', 'subid_uc','Offer Type'])[[ 'amount', 'Jump Page Clicks']].sum().reset_index()\n",
    "# use for verification \n",
    "jumppageclicks1 = combined_csv_ss_only['Jump Page Clicks'].sum()\n",
    "revenue1 = combined_csv_ss_only['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25cdc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:01:36.665222Z",
     "start_time": "2023-08-10T16:01:35.522629Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38681df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:30:44.688910Z",
     "start_time": "2023-08-10T16:01:36.810599Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/2276811840.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_csv_ss_only_reformatjobs['Job_id'] = combined_csv_ss_only_reformatjobs['sub_id'].str.extract(f'({\"|\".join(job_ids)})')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6484289.0\n"
     ]
    }
   ],
   "source": [
    "#*** Extracting creative information. ****#\n",
    "# find creative id from list of creative ids from creativestats file.\n",
    "combined_csv_ss_only['split_column'] = combined_csv_ss_only['sub_id'].str.split('_')\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[combined_csv_ss_only['first_split'] == 'SS'].index , 'creative_id'] = combined_csv_ss_only['split_column'].str[7]\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[combined_csv_ss_only['first_split'] == 'SMS'].index , 'creative_id'] = combined_csv_ss_only['split_column'].str[8]\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[combined_csv_ss_only['first_split'] == 'SS'].index , 'Job_id'] = combined_csv_ss_only['split_column'].str[5]\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[combined_csv_ss_only['first_split'] == 'SMS'].index , 'Job_id'] = combined_csv_ss_only['split_column'].str[6]\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[combined_csv_ss_only['first_split'] == 'SS'].index , 'Shortcode'] = combined_csv_ss_only['split_column'].str[3]\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[combined_csv_ss_only['first_split'] == 'SMS'].index , 'Shortcode'] = combined_csv_ss_only['split_column'].str[4] \n",
    "\n",
    "\n",
    "# some AR subids in december formatted incorrectly, some residuals formatted incorrectly.\n",
    "#creative ids are length>6, creative ids len =1 are ARs, ignoring both the cases and repalcing creative ids with nans for rest of the length values\n",
    "combined_csv_ss_only['creative_idlen'] = combined_csv_ss_only['creative_id'].str.len()\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[~combined_csv_ss_only['creative_idlen'].isin([1,6])].index,'creative_id']=np.nan \n",
    "\n",
    "# shortcode is valid only when it's a 5-digit number\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['Shortcode'] == 'FLC', 'Shortcode'] = '51797'\n",
    "combined_csv_ss_only['shortcode_idlen'] = combined_csv_ss_only['Shortcode'].str.len()\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['shortcode_idlen'] != 5,'Shortcode']=np.nan \n",
    "\n",
    "#reformat jobs from residuals and AR\n",
    "combined_csv_ss_only['job_idlen'] = combined_csv_ss_only['Job_id'].str.len()\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only[~combined_csv_ss_only['job_idlen'].isin([1,6])].index,'Job_id']=np.nan \n",
    "combined_csv_ss_only_reformatjobs = combined_csv_ss_only[combined_csv_ss_only['Job_id'].isna() ]\n",
    "jobs['job_id'] =jobs['job_id'].astype('str')\n",
    "\"\"\"\n",
    "for i in jobs['job_id']:\n",
    "    check_len = combined_csv_ss_only_reformatjobs[combined_csv_ss_only_reformatjobs['sub_id'].str.contains(i)]\n",
    "    if len(check_len) > 0:\n",
    "        combined_csv_ss_only_reformatjobs.loc[check_len.index,'Job_id'] = i\n",
    "\"\"\"\n",
    "# Extract the job IDs to a set for faster membership testing\n",
    "creative_stats['JobId'] = creative_stats['JobId'].astype('str')\n",
    "job_ids = set(jobs['job_id']) | set(creative_stats['JobId']) - set(['0'])\n",
    "#creativeid = set(creative_stats['Creative_Id'])\n",
    "#combined_csv_ss_only['creative_id'] = combined_csv_ss_only_reformatjobs['sub_id'].str.extract(f'({\"|\".join(creativeid)})')\n",
    "\n",
    "# Use str.extract to extract the job ID from the sub_id column\n",
    "combined_csv_ss_only_reformatjobs['Job_id'] = combined_csv_ss_only_reformatjobs['sub_id'].str.extract(f'({\"|\".join(job_ids)})')\n",
    "\n",
    "combined_csv_ss_only =   pd.concat([combined_csv_ss_only_reformatjobs,(combined_csv_ss_only[~combined_csv_ss_only['Job_id'].isna()])] )\n",
    "\n",
    "combined_csv_ss_only = combined_csv_ss_only[combined_csv_ss_only['creative_idlen']!= 8]\n",
    "combined_csv_ss_only = combined_csv_ss_only[~combined_csv_ss_only['creative_idlen'].isna()]\n",
    "#get all creatives information.\n",
    "combined_csv_ss_only['Job_id'] = combined_csv_ss_only['Job_id'].astype('float')\n",
    "combined_csv_ss_only['creative_id'] = combined_csv_ss_only['creative_id'].replace('6Oct22', np.nan)\n",
    "combined_csv_ss_only['creative_id'] = combined_csv_ss_only['creative_id'].astype('float')\n",
    "\n",
    "creative_stats['CreativeId'] = creative_stats['CreativeId'].astype('float')\n",
    "# make sure we don't want to merge jobid = 0 \n",
    "#combined_csv_ss_only = combined_csv_ss_only.groupby(['Job_id', 'creative_id'])['amount'].sum().reset_index()\n",
    "#combined_csv_ss_creative = combined_csv_ss_only.merge(creative_stats, left_on = ['Job_id', 'creative_id'], right_on = ['JobId', 'CreativeId'], how = 'left')\n",
    "combined_csv_ss_only['date']  = pd.to_datetime(combined_csv_ss_only['date'] )\n",
    "combined_csv_ss_only['date'] = combined_csv_ss_only['date'].dt.date\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['sub_id'].str.contains( '51797', na = False), 'Shortcode'] = '51797'\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['sub_id'].str.contains( '70610',na = False), 'Shortcode'] = '70610'\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['sub_id'].str.contains( '44345',na = False), 'Shortcode'] = '44345'\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['sub_id'].str.contains( '80837',na = False), 'Shortcode'] = '80837'\n",
    "print(combined_csv_ss_only['Jump Page Clicks'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36485303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:30:55.238446Z",
     "start_time": "2023-08-10T16:30:44.738392Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558332.0\n",
      "2558332.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/1306772921.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  flows_clean_no_delivered['Affiliate_Id']= flows_clean_no_delivered['Affiliate_Id1']\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/1306772921.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  creative_id_na11['Campaign_Id'] = creative_id_na11['Offer'].str.split(' ',expand = True)[0]\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/1306772921.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  creative_id_na11['Campaign_Id']  = creative_id_na11['Campaign_Id'].astype(float)\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/1306772921.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  creative_id_na11['Shortcode Name'] = ''\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "combined_csv_ss_only['Dash_Date_from_subid'] = combined_csv_ss_only['sub_id'].str.extract(r'(\\d{1,2}[A-Za-z]{3}\\d{2})')\n",
    "# convert the dateinfo to datetime format using pd.to_datetime()\n",
    "\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['first_split'] == 'SS' , 'Dash_Date_from_subid'] = combined_csv_ss_only['split_column'].str[8]\n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['first_split'] == 'SMS' , 'Dash_Date_from_subid'] = combined_csv_ss_only['split_column'].str[9] \n",
    "combined_csv_ss_only.loc[combined_csv_ss_only['Dash_Date_from_subid'] == '1','Dash_Date_from_subid' ] = combined_csv_ss_only['split_column'].str[7] \n",
    "combined_csv_ss_only['Dash_Date_from_subid'] = pd.to_datetime(combined_csv_ss_only['Dash_Date_from_subid'], format=\"%d%b%y\", errors='coerce')\n",
    "\"\"\"\n",
    "combined_csv_ss_only['Hitpath ID'] = combined_csv_ss_only['campaign_id']\n",
    "#combined_csv_ss_only['Dash_Date_from_subid'] = pd.to_datetime(combined_csv_ss_only['Dash_Date_from_subid'], format=\"%d%b%y\")\n",
    "# flow data (51797 & 80837 & jobid = 0)\n",
    "#  by 2023/4/11, we don't include creative id. Subid has that info\n",
    "\n",
    "flows_clean1 = flows_clean.groupby(['Hitpath ID', 'Date', 'Dataset', 'Shortcode', 'Shortcode Name',\\\n",
    "       'Revenue Source', 'Code_Type', 'AR Flow', 'AR Day', 'AR Flow ID', 'NEW DP.DS or DP.sV','Affiliate_id']).sum().reset_index()\n",
    "flows_clean1.loc[flows_clean1['AR Day']=='Null', 'AR Day'] = 0 \n",
    "flows_clean1['AR Day'] = flows_clean1['AR Day'].astype(int)\n",
    "flows_clean1 = flows_clean1.groupby(['Hitpath ID', 'Date', 'Dataset', 'Shortcode', 'Shortcode Name',\n",
    "       'Revenue Source', 'Code_Type',  'NEW DP.DS or DP.sV',\n",
    "       'Affiliate_id']).sum().reset_index()\n",
    "flows_clean1['AR Day'] = flows_clean1['AR Day'].astype(str)\n",
    "combined_csv_ss_only.loc[(combined_csv_ss_only['split_column'].str[5].str.contains('AR',na = False)) ,'Hitpath ID'] =combined_csv_ss_only['split_column'].str[6]\n",
    "combined_csv_ss_ar_flow = combined_csv_ss_only[(combined_csv_ss_only['sub_id'].str.contains('AR')) |  (combined_csv_ss_only['Job_id']==0)]\n",
    "combined_csv_ss_ar_flow1 = combined_csv_ss_ar_flow.groupby(['affiliate_id','Hitpath ID','Shortcode','Dash_Date_from_subid'])[['amount','Jump Page Clicks']].sum().reset_index()\n",
    "\n",
    "combined_csv_ss_ar_flow1 = combined_csv_ss_ar_flow1.rename(columns=({'amount': 'Revenue','affiliate_id':'affiliate_id1'}))\n",
    "flows_clean1 = flows_clean1.groupby(['Hitpath ID', 'Date', 'Dataset', 'Shortcode', 'Shortcode Name',\\\n",
    "       'Revenue Source', 'Code_Type', 'AR Day', \\\n",
    "       'NEW DP.DS or DP.sV', 'Affiliate_id']).sum().reset_index()\n",
    "print(combined_csv_ss_ar_flow1['Jump Page Clicks'].sum())\n",
    "flows_clean2 = flows_clean1.merge(combined_csv_ss_ar_flow1, left_on = ['Date','Hitpath ID','Shortcode','Affiliate_id'],right_on = ['Dash_Date_from_subid','Hitpath ID','Shortcode','affiliate_id1'],how = 'outer')\n",
    "print(flows_clean2['Jump Page Clicks'].sum())\n",
    "flows_clean2['Send Strategy'] = 'AR'\n",
    "flows_clean2['Revenue Source'] = 'Short Code - SS Flow'\n",
    "flows_clean2['Code_Type'] = 'Short Code'\n",
    "flows_clean2.loc[flows_clean2['Date'].isna(), 'Date'] = flows_clean2['Dash_Date_from_subid']\n",
    "flows_clean2.loc[(flows_clean2['Shortcode'] == '51797') & (flows_clean2['Shortcode Name'].isna()), 'Shortcode Name'] = 'FLC'\n",
    "flows_clean2.loc[(flows_clean2['Shortcode'] == '80837') & (flows_clean2['Shortcode Name'].isna()), 'Shortcode Name'] = 'MBC'\n",
    "flows_clean2['Revenue'] =  flows_clean2['Revenue'].fillna(0)\n",
    "flows_clean2.columns = flows_clean2.columns.str.title()\n",
    "#flows_clean2.loc[flows_clean2['Affiliate_Id'].isna(),'Affiliate_Id' ]  = flows_clean2['Affiliate_Id1']\n",
    "flows_clean_no_delivered = flows_clean2.loc[flows_clean2['Affiliate_Id'].isna(), ] \n",
    "flows_clean_no_delivered['Affiliate_Id']= flows_clean_no_delivered['Affiliate_Id1']\n",
    "flows_clean_no_delivered = flows_clean_no_delivered.dropna(axis =1 , how ='all') \n",
    "flows_clean2 = flows_clean2.loc[flows_clean2['Affiliate_Id'].isna() == False, ] \n",
    "\n",
    "check_no_match = combined_csv_ss_ar_flow.merge(flows_clean1, how = 'left', right_on = ['Date','Hitpath ID','Shortcode','Affiliate_id'],left_on = ['Dash_Date_from_subid','Hitpath ID','Shortcode','affiliate_id'])\n",
    "check_no_match1 = check_no_match[check_no_match['Delivered'].isna()]\n",
    "check_no_match_with_flow = check_no_match1.dropna(axis =1 , how ='all') \n",
    "\n",
    "\n",
    "#jobs without creative or job \n",
    "combined_csv_ss_only1 = combined_csv_ss_only[~((combined_csv_ss_only['sub_id'].str.contains('AR')) |  (combined_csv_ss_only['Job_id']==0))]\n",
    "combined_csv_ss_only1 = pd.concat([combined_csv_ss_only1,check_no_match_with_flow]).reset_index(drop = True)\n",
    "combined_csv_ss_creative_na = combined_csv_ss_only1[(combined_csv_ss_only1['creative_id'].isna())| (combined_csv_ss_only1['creative_id']<100000)| ( (combined_csv_ss_only1['Job_id'].isna()))]\n",
    "\n",
    "#jobs with creative and job \n",
    "combined_csv_ss_creative_notna = combined_csv_ss_only1[~((combined_csv_ss_only1['creative_id'].isna()) | (combined_csv_ss_only1['creative_id']<100000)| ( (combined_csv_ss_only1['Job_id'].isna())))]\n",
    "\n",
    "# get revenue and delivery stats for jobs with creatives\n",
    "\"\"\" \n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.groupby(['Job_id', 'creative_id'])['amount'].sum().reset_index()\n",
    "merge_frame = creative_stats[['JobId', 'CreativeId']].append(combined_csv_ss_creative_notna[['Job_id', 'creative_id']]).drop_duplicates()\n",
    "creative_stats = creative_stats[creative_stats['Tstamp']>= '2022-11-01']\n",
    "print(combined_csv_ss_creative_notna['amount'].sum())\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.merge(creative_stats, left_on = ['Job_id', 'creative_id'], right_on = ['JobId', 'CreativeId'], how = 'left')\n",
    "print(combined_csv_ss_creative_notna['amount'].sum())\n",
    "\"\"\" \n",
    "# get revenue and delivery stats for jobs with creatives\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.groupby(['Job_id', 'creative_id'])[['amount','Jump Page Clicks']].sum().reset_index()\n",
    "creative_stats11 = creative_stats[creative_stats['Tstamp']>= '2022-11-01']\n",
    "creative_stats11 = creative_stats11.rename(columns=({'JobId': 'Job_id', 'CreativeId':'creative_id'}))\n",
    "creative_stats11['Job_id'] = creative_stats11['Job_id'].astype('int')\n",
    "\n",
    "merge_frame = pd.concat([creative_stats11[['Job_id', 'creative_id']],combined_csv_ss_creative_notna[['Job_id', 'creative_id']]]).drop_duplicates()\n",
    "merge_frame = merge_frame.merge(combined_csv_ss_creative_notna, how = 'left')\n",
    "merge_frame = merge_frame.merge(creative_stats11, how = 'left')\n",
    "\n",
    "combined_csv_ss_creative_notna = merge_frame.fillna(0)\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna[['Offer','Job_id', 'creative_id', 'CreativeName',\\\n",
    "       'Creative', 'Delivered', 'Cost', 'Optout', 'Clicks', 'amount','Jump Page Clicks']]\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.rename(columns=({'amount': 'Revenue'}))\n",
    "#combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.drop_duplicates()\n",
    "#combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.groupby(['date','Offer','Job_id','CreativeId', 'CreativeName', 'Creative', 'Delivered', 'Cost', 'Unsubcount', 'Clicks']).sum('Revenue').reset_index()\n",
    "\n",
    "#get jobs information from jobs file\n",
    "jobs['job_id'] =jobs['job_id'].astype('int')\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.merge(jobs[['job_id','job_name', 'shortcode', 'start_tstamp',\n",
    "       'end_tstamp', 'scheduled_tstamp', 'status_text', 'segments','Scheduling Time']], left_on = 'Job_id', right_on = 'job_id', how = 'left')\n",
    "combined_csv_ss_creative_notna['date'] = pd.to_datetime(combined_csv_ss_creative_notna['scheduled_tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.drop(columns ='job_id')\n",
    "combined_csv_ss_creative_notna.columns = combined_csv_ss_creative_notna.columns.str.title()\n",
    "# create send strategy \n",
    "combined_csv_ss_creative_notna['Send Strategy'] = np.nan \n",
    "combined_csv_ss_creative_notna.loc[ combined_csv_ss_creative_notna['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'P' in l),'Send Strategy'] = 'P'\n",
    "combined_csv_ss_creative_notna.loc[ combined_csv_ss_creative_notna['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'T' in l),'Send Strategy'] = 'OT'\n",
    "combined_csv_ss_creative_notna.loc[ combined_csv_ss_creative_notna['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'PT' in l),'Send Strategy'] = 'PT'\n",
    "combined_csv_ss_creative_notna.loc[ combined_csv_ss_creative_notna['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'AR' in l),'Send Strategy'] = 'AR'\n",
    "combined_csv_ss_creative_notna.loc[ combined_csv_ss_creative_notna['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'CT' in l),'Send Strategy'] = 'CT'\n",
    "combined_csv_ss_creative_notna.loc[ combined_csv_ss_creative_notna['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'MI' in l),'Send Strategy'] = 'MI'\n",
    "combined_csv_ss_creative_notna = combined_csv_ss_creative_notna.reset_index(drop=True)\n",
    "\n",
    "#get revenue stats for jobs without creatives.\n",
    "combined_csv_ss_creative_na = combined_csv_ss_creative_na[['date','Job_id', 'campaign_id','amount','sub_id','Jump Page Clicks']]\n",
    "combined_csv_ss_creative_na = combined_csv_ss_creative_na.rename(columns=({'amount': 'Revenue'}))\n",
    "#get delivery and click stats for jobs without creatives from job file\n",
    " \n",
    "creative_id_na['Date'] = pd.to_datetime(creative_id_na['Tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "creative_id_na11=creative_id_na[creative_id_na['Date'] >= '2022-11-01']\n",
    "creative_id_na11['Campaign_Id'] = creative_id_na11['Offer'].str.split(' ',expand = True)[0]\n",
    "creative_id_na11.loc[creative_id_na11['Campaign_Id'].str.isdigit() == False,'Campaign_Id' ]  = np.nan\n",
    "creative_id_na11['Campaign_Id']  = creative_id_na11['Campaign_Id'].astype(float)\n",
    "creative_id_na11['Shortcode Name'] = ''\n",
    "creative_id_na11.loc[creative_id_na11['Offer'].str.contains('CSS', na = False),'Shortcode Name'] = 'CSS'\n",
    "creative_id_na11.loc[creative_id_na11['Offer'].str.contains('HZB', na = False),'Shortcode Name'] = 'HZB'\n",
    "# the jobid didn't use in the combined_csv_ss_creative_notna\n",
    "#unjoined_creative_stats11 = creative_stats11[~creative_stats11['Job_id'].isin(combined_csv_ss_creative_notna['Job_Id'])]\n",
    "creative_stats11['Date'] = pd.to_datetime(creative_stats11['Tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "creative_stats11['Campaign_Id'] = creative_stats11['Offer'].str.split(' ',expand = True)[0]\n",
    "creative_stats11.loc[creative_stats11['Campaign_Id'].str.isdigit() == False,'Campaign_Id' ]  = np.nan\n",
    "creative_stats11['Campaign_Id']  = creative_stats11['Campaign_Id'].astype(float)\n",
    "creative_stats11['Shortcode Name'] = ''\n",
    "creative_stats11.loc[creative_stats11['Offer'].str.contains('CSS', na = False),'Shortcode Name'] = 'CSS'\n",
    "creative_stats11.loc[creative_stats11['Offer'].str.contains('HZB', na = False),'Shortcode Name'] = 'HZB'\n",
    "\n",
    "#\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['sub_id'].str.contains('70610' ,na=False ),'shortcode']= '70610'\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['sub_id'].str.contains('44345',na=False),'shortcode']= '44345'\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['sub_id'].str.contains('70610' ,na=False ),'Shortcode Name']= 'CSS'\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['sub_id'].str.contains('44345',na=False),'Shortcode Name']= 'HZB'\n",
    "combined_csv_ss_creative_na['campaign_id'] = combined_csv_ss_creative_na['sub_id'].str.split('_',expand = True)[6]\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['campaign_id'].str.isdigit()== False, 'campaign_id'] = combined_csv_ss_creative_na['sub_id'].str.split('_',expand = True)[5]\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['campaign_id'].str.isdigit()== False, 'campaign_id'] = combined_csv_ss_creative_na['sub_id'].str.split('_',expand = True)[4]\n",
    "combined_csv_ss_creative_na['affiliate_id'] = combined_csv_ss_creative_na['sub_id'].str.extract(r'(46\\d{4})')\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['campaign_id'].str.isdigit() == False,'campaign_id' ]  = np.nan\n",
    "combined_csv_ss_creative_na['campaign_id'] = combined_csv_ss_creative_na['campaign_id'].astype(float)\n",
    "#combined_csv_ss_creative_na['date'] = pd.to_datetime(combined_csv_ss_creative_na['scheduled_tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "job_11 = jobs[jobs['scheduled_tstamp'] >= '2022-11-01']\n",
    "#creative_stats_limit = creative_stats11[creative_stats11['Job_id'].isin(combined_csv_ss_creative_na['Job_id'].unique().tolist())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98e6fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:31:58.443111Z",
     "start_time": "2023-08-10T16:30:55.238240Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_csv_ss_creative_na = combined_csv_ss_creative_na.merge(creative_id_na11[['Date','Scheduling Time','JobId','Offer','Campaign_Id', 'Segment', 'CreativeId', 'CreativeName','Shortcode Name',\n",
    "       'Creative','Delivered',  'Optout', 'Clicks', 'Cost']], left_on = ['Job_id','campaign_id','date','Shortcode Name'], right_on = ['JobId','Campaign_Id','Date','Shortcode Name'], how = 'outer', copy = False)\n",
    "combined_csv_ss_creative_na = combined_csv_ss_creative_na.merge(job_11[['job_id','job_name', 'offer', 'shortcode', 'scheduled_tstamp', 'status_text', 'segments', \n",
    "        'delivered', 'optout', 'clicks', 'cost']], left_on = ['Job_id'], right_on =['job_id'] , how = 'left' , copy = False)\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['date'].isna(), 'date'] = combined_csv_ss_creative_na['Date']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['campaign_id'].isna(), 'campaign_id'] = combined_csv_ss_creative_na['Campaign_Id']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Offer'].isna(), 'Offer'] = combined_csv_ss_creative_na['offer']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Delivered'].isna(), 'Delivered'] = combined_csv_ss_creative_na['delivered']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Optout'].isna(), 'Optout'] = combined_csv_ss_creative_na['optout']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Clicks'].isna(), 'Clicks'] = combined_csv_ss_creative_na['clicks']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Cost'].isna(), 'Cost'] = combined_csv_ss_creative_na['cost']\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Job_id'].isna(), 'Job_id'] = combined_csv_ss_creative_na['JobId']\n",
    "combined_csv_ss_creative_na = combined_csv_ss_creative_na.drop(columns = ['job_id','Campaign_Id','Date','offer', 'delivered', 'optout', 'clicks', 'cost','JobId'])\n",
    "#combined_csv_ss_creative_na = combined_csv_ss_creative_na.reset_index()\n",
    "#combined_csv_ss_creative_na['date'] = pd.to_datetime(combined_csv_ss_creative_na['scheduled_tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "combined_csv_ss_creative_na.columns = combined_csv_ss_creative_na.columns.str.title()\n",
    "\n",
    "# create send strategy \n",
    "combined_csv_ss_creative_na['Send Strategy'] = np.nan \n",
    "combined_csv_ss_creative_na.loc[ combined_csv_ss_creative_na['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'P' in l),'Send Strategy'] = 'P'\n",
    "combined_csv_ss_creative_na.loc[ combined_csv_ss_creative_na['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'T' in l),'Send Strategy'] = 'T'\n",
    "combined_csv_ss_creative_na.loc[ combined_csv_ss_creative_na['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'AR' in l),'Send Strategy'] = 'AR'\n",
    "combined_csv_ss_creative_na.loc[ combined_csv_ss_creative_na['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'CT' in l),'Send Strategy'] = 'CT'\n",
    "combined_csv_ss_creative_na.loc[ combined_csv_ss_creative_na['Job_Name'].str.split('_|[|]| ').str[-2:].astype('str').apply(lambda l: 'MI' in l),'Send Strategy'] = 'MI'\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Job_Id'] == 0, 'Send Strategy'] = 'AR'\n",
    "combined_csv_ss_creative_na.loc[combined_csv_ss_creative_na['Job_Id'] == 0, 'Revenue Source'] =  'Short Code - SS Jobs'\n",
    "#combined_csv_ss_creative_na = combined_csv_ss_creative_na.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f3c129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/4057437970.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_csv_ss_exclude['date'] = pd.to_datetime(combined_csv_ss_exclude['date'])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/4057437970.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_csv_push['date'] = pd.to_datetime(combined_csv_push['date'])\n",
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/4057437970.py:24: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  combined_csv_ss_last =  combined_csv_ss_rest[ (combined_csv['affiliate_name'].str.lower().str.contains(\"push\", na = False) == False)]\n"
     ]
    }
   ],
   "source": [
    "#case #3: revenue for email \n",
    "combined_csv_ss_exclude = combined_csv\n",
    "combined_csv_ss_exclude['affiliate_id'] = combined_csv_ss_exclude['affiliate_id'].astype(str).str.split(\".\",expand = True)[0]\n",
    "combined_csv_ss_exclude['site_id'] = combined_csv_ss_exclude['site_id'].astype(str).str.split(\".\",expand = True)[0]\n",
    "\n",
    "combined_csv_ss_exclude =  combined_csv_ss_exclude.loc[(combined_csv_ss_exclude['affiliate_id'].isin(email_pubid)) | (combined_csv_ss_exclude['site_id'].isin(email_pubid)),] \n",
    "combined_csv_ss_exclude['date'] = pd.to_datetime(combined_csv_ss_exclude['date'])\n",
    "combined_csv_ss_exclude = combined_csv_ss_exclude[[ 'amount', 'date']]\n",
    "combined_csv_ss_exclude = combined_csv_ss_exclude.rename(columns=({'amount': 'Revenue','date': 'Date'}))\n",
    "combined_csv_ss_exclude_11 = combined_csv_ss_exclude[combined_csv_ss_exclude['Date']>='2022-11-01'].reset_index(drop=True)\n",
    "# case #4: push revenue \n",
    "email_pubid_int = emit['Revenue Pub ID'].unique().tolist()\n",
    "combined_csv_ss_rest =  combined_csv[(combined_csv['first_split']!='SS') & (combined_csv['first_split']!='SMS') & (combined_csv['affiliate_id'].astype(float).isin(email_pubid_int)== False) & (combined_csv['site_id'].astype(float).isin(email_pubid_int)== False) & (combined_csv['first_split']!='MD') &  (combined_csv['first_split']!='TB')  ] \n",
    "#combined_csv_ss_rest =  combined_csv[(combined_csv['first_split']!='SS') & (combined_csv['first_split']!='SMS') & (combined_csv['subid_2'].str.contains('FLC|MBC',na = False)== False)& (combined_csv['affiliate_id'].astype(float).isin(email_pubid_int)== False) & (combined_csv['site_id'].astype(float).isin(email_pubid_int)== False) & (combined_csv['first_split']!='MD')   ] \n",
    "\n",
    "combined_csv_push = combined_csv_ss_rest.loc[combined_csv_ss_rest['affiliate_name'].str.lower().str.contains(\"push\", na = False),]\n",
    "combined_csv_push['date'] = pd.to_datetime(combined_csv_push['date'])\n",
    "combined_csv_push = combined_csv_push[[ 'amount', 'date']]\n",
    "combined_csv_push = combined_csv_push.rename(columns=({'amount': 'Revenue','date': 'Date'}))\n",
    "combined_csv_push_11 =  combined_csv_push[combined_csv_push['Date']>='2022-11-01'].reset_index(drop=True)\n",
    "\n",
    "# case #5: revenue the rest of the revenue. \n",
    "\n",
    "combined_csv_ss_last =  combined_csv_ss_rest[ (combined_csv['affiliate_name'].str.lower().str.contains(\"push\", na = False) == False)] \n",
    "combined_csv_ss_last_11 = combined_csv_ss_last[combined_csv_ss_last['date']>='2022-11-01'].reset_index(drop=True)\n",
    "\n",
    "# identify Revenue Sourc\n",
    "combined_csv_ss_creative_na['Revenue Source'] = 'Short Code - SS Jobs'\n",
    "combined_csv_ss_creative_notna['Revenue Source'] = 'Short Code - SS Jobs'\n",
    "combined_csv_ss_exclude['Revenue Source'] = 'Email'\n",
    "combined_csv_push['Revenue Source'] = 'Push'\n",
    "historic_data['Revenue Source'] = 'Short Code - SS Jobs'\n",
    "historic_data['Send Strategy'] = np.nan\n",
    "#combined_csv_ss_creative_na = combined_csv_ss_creative_na.drop_duplicates()\n",
    "SS_New_data = pd.concat([combined_csv_ss_creative_notna,combined_csv_ss_creative_na,flows_clean2,combined_csv_ss_exclude, combined_csv_push], axis=0)\n",
    "SS_New_data['Ecpm'] = SS_New_data['Revenue'] * 1000/SS_New_data['Delivered']\n",
    "SS_New_data['Roi'] = SS_New_data['Cost'] - SS_New_data['Revenue']\n",
    "#SS_New_data['Sent'] = SS_New_data['Total']\n",
    "\n",
    "#combining historic data(before Nov 1) with new data to get SS full data.\n",
    "#SS_New_data = SS_New_data[historic_data.columns]\n",
    "\n",
    "\n",
    "SS_Full_data = pd.concat([SS_New_data,historic_data], axis = 0)\n",
    "SS_Full_data['Date'] = pd.to_datetime(SS_Full_data['Date'])\n",
    "SS_Full_data = SS_Full_data.sort_values('Date', ascending=False)\n",
    "SS_Full_data.loc[(SS_Full_data['Job_Id'].isna()) & (SS_Full_data['Revenue Source']==  'Short Code - SS Jobs') ,'Revenue Source'] = 'Short Code - Opt In'\n",
    "SS_Full_data.loc[ (SS_Full_data['Job_Id'].isna()) & (SS_Full_data['Sub_Id'].str.contains('AR', na = False)) ,'Revenue Source'] =  'Short Code - SS Flow'\n",
    "SS_Full_data.loc[ (SS_Full_data['Job_Id'].isna())&  (SS_Full_data['Sub_Id'].str.contains('AR', na = False)) ,'Send Strategy'] = 'AR'\n",
    "SS_Full_data.loc[(SS_Full_data['Job_Id'].isna()) & (SS_Full_data['Revenue Source']==  'Short Code - Opt In') ,'Send Strategy'] = 'Opt In'\n",
    "SS_Full_data.loc[(SS_Full_data['Job_Id']==0) & (SS_Full_data['Revenue Source']==  'Short Code - SS Jobs') & (SS_Full_data['Send Strategy'].isna()) ,'Send Strategy'] = 'AR'\n",
    "SS_Full_data.to_csv(localfolder + 'SS_Fulldata.csv', index =False)  \n",
    "\n",
    "######## SS END ########\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880be988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "2022-11    4544.49\n",
       "2022-12    5084.78\n",
       "2023-01    1560.90\n",
       "2023-02    1055.98\n",
       "2023-03     335.37\n",
       "2023-04     872.45\n",
       "2023-05     896.70\n",
       "2023-06      25.75\n",
       "2023-07       6.35\n",
       "2023-08     140.34\n",
       "2023-09       1.70\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not attribute to our data yet, including TB\n",
    "\n",
    "combined_csv_ss_last_11['month'] = combined_csv_ss_last_11['date'].astype(str).str[:7]\n",
    "combined_csv_ss_last_11.to_csv('/Users/liliguo/Desktop/check.csv')\n",
    "combined_csv_ss_last_11.groupby('month')['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3c53c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>advertiser_name</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>affiliate_name</th>\n",
       "      <th>subid_1</th>\n",
       "      <th>subid_2</th>\n",
       "      <th>subid_3</th>\n",
       "      <th>...</th>\n",
       "      <th>plcategory_name</th>\n",
       "      <th>plsubcategory_name</th>\n",
       "      <th>Jump Page Clicks</th>\n",
       "      <th>subid_1 uc</th>\n",
       "      <th>subid_2 uc</th>\n",
       "      <th>subid_5 uc</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>first_split</th>\n",
       "      <th>Dash_Date_from_subid</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>What If Media</td>\n",
       "      <td>6764.0</td>\n",
       "      <td>Top Credit Card Finder CPC - What If Media (SMS2)</td>\n",
       "      <td>460931</td>\n",
       "      <td>460931</td>\n",
       "      <td>1 - SMS LM: Spark Revenue (sweeps)</td>\n",
       "      <td>460931</td>\n",
       "      <td>11.14.20_SPK_OCTRAW_TB_LC_TCF_6764</td>\n",
       "      <td>1046007337.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>11.14.20_SPK_OCTRAW_TB_LC_TCF_6764</td>\n",
       "      <td>11.14.20</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>2022-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>What If Media</td>\n",
       "      <td>6764.0</td>\n",
       "      <td>Top Credit Card Finder CPC - What If Media (SMS2)</td>\n",
       "      <td>460931</td>\n",
       "      <td>460931</td>\n",
       "      <td>460931_SPK.GFN_SMS</td>\n",
       "      <td>460931</td>\n",
       "      <td>09.25.20_SPK_460931_c_6688_SC_MP</td>\n",
       "      <td>1199142400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>09.25.20_SPK_460931_c_6688_SC_MP</td>\n",
       "      <td>09.25.20</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>2022-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>Digital Bulldogs / Commission Soup</td>\n",
       "      <td>8612.0</td>\n",
       "      <td>Aspire Cash Back Reward Card - Email Program -...</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247_PA.PS_SMS</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247_80837_MBC_W1</td>\n",
       "      <td>1202364331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1202364331.0</td>\n",
       "      <td>1202364331.0</td>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>2022-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>Spark</td>\n",
       "      <td>11238.0</td>\n",
       "      <td>Inflation Sweeps - SMS ONLY - Spark (SMS)</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247_PA.PS_SMS</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247_80837_MBC_W1</td>\n",
       "      <td>1202049251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1202049251.0</td>\n",
       "      <td>1202049251.0</td>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>2022-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>Spark</td>\n",
       "      <td>11224.0</td>\n",
       "      <td>No Fee Credit - SMS ONLY - Spark (SMS)</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247_PA.PS_SMS</td>\n",
       "      <td>461247</td>\n",
       "      <td>461247_80837_MBC_W1</td>\n",
       "      <td>1203258336.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1203258336.0</td>\n",
       "      <td>1203258336.0</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>C3 Data, LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>461313</td>\n",
       "      <td>461313</td>\n",
       "      <td>LM_SMS_NorthPointDirect_RentToOwn</td>\n",
       "      <td>461313</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>2023-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>Spark</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>Credit America - Spark (SMS)</td>\n",
       "      <td>461452</td>\n",
       "      <td>461452</td>\n",
       "      <td>LM_SMS_Comceptual_OpinionShareResearch</td>\n",
       "      <td>461452</td>\n",
       "      <td>test</td>\n",
       "      <td>1237841126</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1237841126</td>\n",
       "      <td>1237841126</td>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>2023-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>Unlimited Net Resource - Public</td>\n",
       "      <td>5660.0</td>\n",
       "      <td>2023 Credit Card - CPC (PPC + Multisales)</td>\n",
       "      <td>460654</td>\n",
       "      <td>460654</td>\n",
       "      <td>I_SMS_RXMG_RentOwnClub</td>\n",
       "      <td>ROC_4.12</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>Internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>2023-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>RxMG RTO</td>\n",
       "      <td>5786.0</td>\n",
       "      <td>Rent Own Club - CPC - INTERNAL TRANSACTIONS ON...</td>\n",
       "      <td>460654</td>\n",
       "      <td>460654</td>\n",
       "      <td>I_SMS_RXMG_RentOwnClub</td>\n",
       "      <td>ROC_SC_MP_6342_HZB-all-2_w0</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>Internal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ROC_SC_MP_6342_HZB-all-2_w0</td>\n",
       "      <td>ROC</td>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>2023-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5113</th>\n",
       "      <td>2023-07-22</td>\n",
       "      <td>AdMediary</td>\n",
       "      <td>6709.0</td>\n",
       "      <td>Survey Junkie - Admediary (SMS)</td>\n",
       "      <td>460931</td>\n",
       "      <td>460931</td>\n",
       "      <td>1 - SMS LM: Spark Revenue (sweeps)</td>\n",
       "      <td>460931</td>\n",
       "      <td>7.30_SPK_LC_6709</td>\n",
       "      <td>1025779269</td>\n",
       "      <td>...</td>\n",
       "      <td>SMS</td>\n",
       "      <td>LM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1025779269</td>\n",
       "      <td>1025779269</td>\n",
       "      <td>2023-07-22</td>\n",
       "      <td>2023-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5114 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                     advertiser_name  campaign_id  \\\n",
       "0    2022-12-05                       What If Media       6764.0   \n",
       "1    2022-12-06                       What If Media       6764.0   \n",
       "2    2022-12-25  Digital Bulldogs / Commission Soup       8612.0   \n",
       "3    2022-12-23                               Spark      11238.0   \n",
       "4    2022-12-30                               Spark      11224.0   \n",
       "...         ...                                 ...          ...   \n",
       "5109 2023-07-12                        C3 Data, LLC          NaN   \n",
       "5110 2023-07-25                               Spark      11855.0   \n",
       "5111 2023-07-24     Unlimited Net Resource - Public       5660.0   \n",
       "5112 2023-07-20                            RxMG RTO       5786.0   \n",
       "5113 2023-07-22                           AdMediary       6709.0   \n",
       "\n",
       "                                          campaign_name site_id affiliate_id  \\\n",
       "0     Top Credit Card Finder CPC - What If Media (SMS2)  460931       460931   \n",
       "1     Top Credit Card Finder CPC - What If Media (SMS2)  460931       460931   \n",
       "2     Aspire Cash Back Reward Card - Email Program -...  461247       461247   \n",
       "3             Inflation Sweeps - SMS ONLY - Spark (SMS)  461247       461247   \n",
       "4                No Fee Credit - SMS ONLY - Spark (SMS)  461247       461247   \n",
       "...                                                 ...     ...          ...   \n",
       "5109                                                NaN  461313       461313   \n",
       "5110                       Credit America - Spark (SMS)  461452       461452   \n",
       "5111          2023 Credit Card - CPC (PPC + Multisales)  460654       460654   \n",
       "5112  Rent Own Club - CPC - INTERNAL TRANSACTIONS ON...  460654       460654   \n",
       "5113                    Survey Junkie - Admediary (SMS)  460931       460931   \n",
       "\n",
       "                              affiliate_name                      subid_1  \\\n",
       "0         1 - SMS LM: Spark Revenue (sweeps)                       460931   \n",
       "1                         460931_SPK.GFN_SMS                       460931   \n",
       "2                           461247_PA.PS_SMS                       461247   \n",
       "3                           461247_PA.PS_SMS                       461247   \n",
       "4                           461247_PA.PS_SMS                       461247   \n",
       "...                                      ...                          ...   \n",
       "5109       LM_SMS_NorthPointDirect_RentToOwn                       461313   \n",
       "5110  LM_SMS_Comceptual_OpinionShareResearch                       461452   \n",
       "5111                  I_SMS_RXMG_RentOwnClub                     ROC_4.12   \n",
       "5112                  I_SMS_RXMG_RentOwnClub  ROC_SC_MP_6342_HZB-all-2_w0   \n",
       "5113      1 - SMS LM: Spark Revenue (sweeps)                       460931   \n",
       "\n",
       "                                 subid_2       subid_3  ... plcategory_name  \\\n",
       "0     11.14.20_SPK_OCTRAW_TB_LC_TCF_6764  1046007337.0  ...             SMS   \n",
       "1       09.25.20_SPK_460931_c_6688_SC_MP  1199142400.0  ...             SMS   \n",
       "2                    461247_80837_MBC_W1  1202364331.0  ...             SMS   \n",
       "3                    461247_80837_MBC_W1  1202049251.0  ...             SMS   \n",
       "4                    461247_80837_MBC_W1  1203258336.0  ...             SMS   \n",
       "...                                  ...           ...  ...             ...   \n",
       "5109                                 nan           NaN  ...             SMS   \n",
       "5110                                test    1237841126  ...             SMS   \n",
       "5111                                 nan           NaN  ...             SMS   \n",
       "5112                                 nan           NaN  ...             SMS   \n",
       "5113                    7.30_SPK_LC_6709    1025779269  ...             SMS   \n",
       "\n",
       "     plsubcategory_name  Jump Page Clicks subid_1 uc  subid_2 uc  subid_5 uc  \\\n",
       "0                    LM               NaN          0           6           0   \n",
       "1                    LM               NaN          0           6           0   \n",
       "2                    LM               NaN          0           3           0   \n",
       "3                    LM               NaN          0           3           0   \n",
       "4                    LM               NaN          0           3           0   \n",
       "...                 ...               ...        ...         ...         ...   \n",
       "5109                 LM               NaN          0           0           0   \n",
       "5110                 LM               NaN          0           0           0   \n",
       "5111           Internal               NaN          1           0           0   \n",
       "5112           Internal               NaN          5           0           0   \n",
       "5113                 LM               NaN          0           3           0   \n",
       "\n",
       "                                  sub_id   first_split Dash_Date_from_subid  \\\n",
       "0     11.14.20_SPK_OCTRAW_TB_LC_TCF_6764      11.14.20           2022-12-05   \n",
       "1       09.25.20_SPK_460931_c_6688_SC_MP      09.25.20           2022-12-06   \n",
       "2                           1202364331.0  1202364331.0           2022-12-25   \n",
       "3                           1202049251.0  1202049251.0           2022-12-23   \n",
       "4                           1203258336.0  1203258336.0           2022-12-30   \n",
       "...                                  ...           ...                  ...   \n",
       "5109                                 NaN           NaN           2023-07-12   \n",
       "5110                          1237841126    1237841126           2023-07-25   \n",
       "5111                                 NaN           NaN           2023-07-24   \n",
       "5112         ROC_SC_MP_6342_HZB-all-2_w0           ROC           2023-07-20   \n",
       "5113                          1025779269    1025779269           2023-07-22   \n",
       "\n",
       "        month  \n",
       "0     2022-12  \n",
       "1     2022-12  \n",
       "2     2022-12  \n",
       "3     2022-12  \n",
       "4     2022-12  \n",
       "...       ...  \n",
       "5109  2023-07  \n",
       "5110  2023-07  \n",
       "5111  2023-07  \n",
       "5112  2023-07  \n",
       "5113  2023-07  \n",
       "\n",
       "[5114 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv_ss_last_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54acff91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:31:59.037237Z",
     "start_time": "2023-08-10T16:31:58.487041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/3977380537.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  MP_campaigns['ACTDATE']= pd.to_datetime(MP_campaigns['ACTDATE'])\n"
     ]
    }
   ],
   "source": [
    "######## MP BEGIN ########\n",
    "#Read MP file and clean. All stats present in MP_Campaigns file.\n",
    "\n",
    "MP_campaigns = pd.read_csv(localfolder + 'SMS_SC_MP_Campaigns.csv')\n",
    "MP_campaigns = MP_campaigns[~MP_campaigns['ACTDATE'].isna()]\n",
    "MP_campaigns = MP_campaigns[~MP_campaigns['ACTDATE'].isin(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])]\n",
    "MP_campaigns['ACTDATE']= pd.to_datetime(MP_campaigns['ACTDATE'])\n",
    "#a = MP_campaigns.isna().sum()\n",
    "drop_columns = ['Daily Opt Out', 'Unnamed: 28', 'Unnamed: 53', 'Reference', 'c1NEW' , 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 64', 'Unnamed: 72', 'Unnamed: 73']\n",
    "MP_campaigns.drop(columns=drop_columns, inplace=True, axis=1)\n",
    "MP_campaigns= MP_campaigns[~MP_campaigns['Done.'].isna()]\n",
    "MP_campaigns.columns = MP_campaigns.columns.str.strip()\n",
    "\n",
    "# remove % and $ symbold\n",
    "MP_campaigns['REV'] = MP_campaigns['REV'].str.strip()\n",
    "MP_campaigns['REV'] = MP_campaigns['REV'].replace('$ -', np.nan)\n",
    "MP_campaigns['REV'] = MP_campaigns['REV'].str.replace('$','')\n",
    "MP_campaigns['REV'] = MP_campaigns['REV'].str.replace(',','')\n",
    "MP_campaigns['REV'] = MP_campaigns['REV'].astype('float')\n",
    "\n",
    "MP_campaigns['COST'] = MP_campaigns['COST'].str.strip()\n",
    "MP_campaigns['COST'] = MP_campaigns['COST'].replace('$ -', np.nan)\n",
    "MP_campaigns['COST'] = MP_campaigns['COST'].str.replace('$','')\n",
    "MP_campaigns['COST'] = MP_campaigns['COST'].astype('float')\n",
    "\n",
    "MP_campaigns['eCPM'] = MP_campaigns['eCPM'].str.strip()\n",
    "MP_campaigns['eCPM'] = MP_campaigns['eCPM'].replace('$ -', np.nan)\n",
    "MP_campaigns['eCPM'] = MP_campaigns['eCPM'].str.replace('$','')\n",
    "MP_campaigns['eCPM'] = MP_campaigns['eCPM'].astype('float')\n",
    "\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].str.strip()\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].str.replace('$','')\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].replace('-',np.nan)\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].replace(' -',np.nan)\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].astype(str).str.replace('\\((.*)\\)', '-\\\\1')\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].str.replace(',','')\n",
    "MP_campaigns['gPROFIT'] = MP_campaigns['gPROFIT'].astype('float')\n",
    "\n",
    "MP_campaigns['CLICK %'] = MP_campaigns['CLICK %'].str.strip()\n",
    "MP_campaigns['CLICK %'] = MP_campaigns['CLICK %'].str.replace('%','')\n",
    "MP_campaigns['CLICK %'] = MP_campaigns['CLICK %'].astype('float')\n",
    "\n",
    "MP_campaigns['gMARGIN'] = MP_campaigns['gMARGIN'].str.strip()\n",
    "MP_campaigns['gMARGIN'] = MP_campaigns['gMARGIN'].str.replace('%','')\n",
    "MP_campaigns['gMARGIN'] = MP_campaigns['gMARGIN'].astype('float')\n",
    "\n",
    "MP_campaigns.to_csv(localfolder + 'MP_data.csv', index =False)  \n",
    "\n",
    "###### MP ENDS #######\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a37a9e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:25.685817Z",
     "start_time": "2023-08-10T16:31:59.036893Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/6860352.py:3: DtypeWarning: Columns (0,3,4,11,13,14,15,16,17,18,20,23,25,31,32,34,35,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  SS_data = pd.read_csv(localfolder + 'SS_Fulldata.csv')\n"
     ]
    }
   ],
   "source": [
    "#4 merge SS and MP: not possible as there are columns in MP not in SS.\n",
    "LC_data = pd.read_csv(localfolder + 'SMS_LC_Campaigns_clean.csv')\n",
    "SS_data = pd.read_csv(localfolder + 'SS_Fulldata.csv')\n",
    "\n",
    "lc_df_full = lc_df_full.reset_index(drop=True)\n",
    "LC_data = LC_data.reset_index(drop=True)\n",
    "LC_data = pd.concat([lc_df_full,LC_data], axis=0, ignore_index=True)\n",
    "LC_data.loc[LC_data['Affiliate_Id'].isna(),'Affiliate_Id'] = LC_data['pubID']\n",
    "LC_data.loc[LC_data['Hitpath_Offer_ID'].isna(),'Hitpath_Offer_ID' ] = LC_data['sid']\n",
    "LC_data['Affiliate_Id'] = LC_data['Affiliate_Id'].astype(str).str.split('.',expand = True)[0]\n",
    "LC_data['Hitpath_Offer_ID'] = LC_data['Hitpath_Offer_ID'].astype(str).str.split('.',expand = True)[0]\n",
    "LC_data['Revenue Source'] = 'Long Code'\n",
    "SS_data['Code_Type'] = 'Short Code'\n",
    "LC_data['Code_Type'] = 'Long Code'\n",
    "SS_data.loc[SS_data['Revenue Source'] == 'Email', 'Code_Type'] = 'Email'\n",
    "SS_data['Hitpath_Offer_ID'] = SS_data['Offer'].astype('str').str.extract(r'\\b(\\d{4,5})\\b')\n",
    "SS_data['Affiliate_Id'] = SS_data['Affiliate_Id'].astype(str).str.split('.',expand = True)[0]\n",
    "#LC_data= LC_data.rename(columns=({'eCPM' : 'Ecpm', 'Clicked': 'Clicks'}))\n",
    "\n",
    "#merge short code and longcode\n",
    "merged_data = pd.concat([SS_data,LC_data], axis=0, ignore_index=True)\n",
    "\n",
    "#merged_data['Hitpath_Offer_ID'] = merged_data['Offer'].astype('str').str.extract(r'\\b(\\d{4,5})\\b')\n",
    "merged_data.loc[merged_data['Revenue Source']=='Short Code - SS Flow','Hitpath_Offer_ID'] =merged_data['Hitpath Id'].astype('str').str.split('.',expand = True)[0]\n",
    "merged_data['DP.SV'] = merged_data['New Dp.Ds Or Dp.Sv']\n",
    "merged_data.loc[merged_data['DP.SV'].isnull(), 'DP.SV'] =  merged_data['Segments'].str.split('_',expand = True)[1]\n",
    "new_publisher = publisher[['NEW DP.DS or DP.sV','PUBID']]\n",
    "new_publisher = new_publisher['PUBID'].astype(str).str.split('.',expand = True)[0]\n",
    "merged_data = merged_data.merge(publisher[['NEW DP.DS or DP.sV','PUBID']], left_on ='DP.SV', right_on = 'NEW DP.DS or DP.sV', how = 'left' )\n",
    "merged_data.loc[(merged_data['Affiliate_Id'].isna()) |  (merged_data['Affiliate_Id']=='nan'), 'Affiliate_Id'] = merged_data['PUBID']\n",
    "merged_data['Affiliate_Id'] = merged_data['Affiliate_Id'].astype(str).str.split('.',expand = True)[0]\n",
    "merged_data['DP&Pub'] = merged_data['DP.SV']+'_'+ merged_data['Affiliate_Id']\n",
    "\n",
    "merged_data = merged_data[['Date','Scheduling Time', 'Offer','Hitpath_Offer_ID','DP.SV','Affiliate_Id', 'DP&Pub','Job_Id', 'Job_Name','Creative_Id','Creativename','Creative','Send Strategy', 'Shortcode', 'Start_Tstamp', 'Segments', 'Revenue','Jump Page Clicks', 'Delivered', 'Not_Delivered', 'Optout', 'Clicks',\n",
    "       'Cost', 'Ecpm', 'Time', 'Publisher', 'Campaign', 'Route',  'Carrier', 'Dataset', 'Message',\n",
    "       'Responder Template', 'Keyword', 'Responder', 'Router Domain Name' , 'c1', 'Responded', 'Response Rate', 'CTR',\n",
    "        'Gross Profit' , 'Gross Margin', 'RPU' ,'Provider', 'Code_Type','Revenue Source',\n",
    "     'Ar Day','Sub_Id','Campaign_Id','Roi','Shortcode Name','Total']]\n",
    "\n",
    "merged_data.loc[merged_data['Shortcode'] == 51797, 'Shortcode Name'] = 'FLC'\n",
    "merged_data.loc[merged_data['Shortcode'] == 70610, 'Shortcode Name'] = 'CSS'\n",
    "merged_data.loc[merged_data['Shortcode'] == 44345, 'Shortcode Name'] = 'HZB'\n",
    "merged_data.loc[merged_data['Shortcode'] == 80837, 'Shortcode Name'] = 'MBC'\n",
    "merged_data.loc[merged_data['Shortcode'] == 31232, 'Shortcode Name'] = 'DSS'\n",
    "merged_data.loc[merged_data['Shortcode Name'] == 'FLC', 'Shortcode'] = 51797\n",
    "merged_data.loc[merged_data['Shortcode Name'] == 'CSS', 'Shortcode'] = 70610\n",
    "merged_data.loc[merged_data['Shortcode Name'] == 'HZB', 'Shortcode'] = 44345\n",
    "merged_data.loc[merged_data['Shortcode Name'] == 'MBC', 'Shortcode'] = 80837\n",
    "merged_data.loc[merged_data['Shortcode Name'] == 'DSS', 'Shortcode'] = 31232\n",
    "merged_data.loc[merged_data['Delivered'] == '','Delivered'] = np.nan\n",
    "merged_data['Delivered'] =  merged_data['Delivered'].astype(float)\n",
    "merged_data.loc[(merged_data['Shortcode Name'] == 'MBC') | (merged_data['Shortcode Name'] == 'FLC'),'Cost']  =  0.00563 *  merged_data['Delivered'] +  merged_data['Cost']\n",
    "merged_data.loc[(merged_data['Shortcode Name'] == 'UAA') | (merged_data['Shortcode Name'] == 'SVT') | (merged_data['Shortcode Name'] == 'DSS'), 'Cost']  =  0.00545 *  merged_data['Delivered'] \n",
    "Offer_name[ 'campaign_id'] = Offer_name[ 'campaign_id'].astype('str')\n",
    "merged_data = merged_data.merge(Offer_name,left_on = 'Hitpath_Offer_ID',right_on = 'campaign_id',how = 'left')\n",
    "merged_data['Job_Id']  = merged_data['Job_Id'].astype(str).str.split('.',expand = True)[0].str.strip()\n",
    "merged_data['Date'] = pd.to_datetime(merged_data['Date'],format ='mixed').dt.strftime(\"%Y-%m-%d\")\n",
    "merged_data['shortcode_DP.SV'] = merged_data['Shortcode Name'] + \"_\" + merged_data['DP.SV']\n",
    "merged_data.loc[merged_data['shortcode_DP.SV']=='_', 'shortcode_DP.SV'] = np.nan\n",
    "# calculate opportunity cost\n",
    "merged_data['Opportunity Cost Send Strategy'] =  True\n",
    "merged_data.loc[merged_data['Send Strategy'].isin(['Null','Opt In',np.nan]), 'Opportunity Cost Send Strategy'] = False\n",
    "merged_data = merged_data.sort_values('Date')\n",
    "temp1= merged_data.groupby(['Affiliate_Id','Opportunity Cost Send Strategy','Date']).agg({'Revenue':'sum','Delivered':'sum'}).reset_index()\n",
    "temp1[['rolling Revenue','rolling Delivered']] = temp1.groupby('Affiliate_Id').shift(1).rolling(30)[['Revenue','Delivered']].sum().reset_index(drop=True)\n",
    "temp1['Dataset_Agg_30D_eCPM'] = temp1['rolling Revenue'] * 1000/ temp1['rolling Delivered']\n",
    "dataset_agg_eCPM =  temp1[['Affiliate_Id','Date','Opportunity Cost Send Strategy','Dataset_Agg_30D_eCPM']]\n",
    "merged_data = merged_data.merge(dataset_agg_eCPM, how = 'left')\n",
    "merged_data['Opportunity Cost'] = merged_data['Revenue'] - merged_data['Dataset_Agg_30D_eCPM'] * merged_data['Delivered'] /1000 \n",
    "merged_data = merged_data.sort_values(by = 'Date',ascending = False)\n",
    "merged_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "merged_data.to_csv(localfolder + 'SS_LC_merged_data.csv', index =False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c320658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DSS'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[merged_data['Segments']== 'DSS_TLG.PL_30DC']['Shortcode Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9416546e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:25.691033Z",
     "start_time": "2023-08-10T16:34:22.182771Z"
    }
   },
   "outputs": [],
   "source": [
    "engagement_daily = merged_data.groupby(['Date','Affiliate_Id'])[['Delivered','Clicks','Jump Page Clicks','Optout','Cost']].sum()\n",
    "engagement_daily = engagement_daily[~np.all(engagement_daily==0,axis = 1)]\n",
    "engagement_daily = engagement_daily.reset_index()\n",
    "daily_revenue_gpby = daily_revenue_gpby.rename(columns = {'amount':'Revenue','affiliate_id': 'Affiliate_Id', 'date': 'Date'})\n",
    "#Pl_data = daily_revenue_gpby.merge(engagement_daily, left_on =['affiliate_id','date'] ,right_on = ['Affiliate_Id','Date'],copy = False, how = 'outer')\n",
    "daily_revenue_gpby['Date'] = pd.to_datetime(daily_revenue_gpby['Date'])\n",
    "engagement_daily['Date'] =  pd.to_datetime(engagement_daily['Date'])\n",
    "Pl_data = pd.concat([daily_revenue_gpby,engagement_daily], axis=0, ignore_index=True)\n",
    "Pl_data['PUBID'] =Pl_data['Affiliate_Id'].astype('str').str.split(\".\",expand = True)[0]\n",
    "Pl_data = Pl_data.fillna(0)\n",
    "Pl_data = Pl_data[[ 'Date', 'PUBID','Revenue', 'Delivered', 'Clicks',\\\n",
    "      'Jump Page Clicks', 'Optout','Cost']]\n",
    "Pl_data = Pl_data.groupby(['PUBID','Date']).sum().reset_index()\n",
    "#Pl_data.to_csv(localfolder+'p&l_data.csv',index =False)\n",
    "\n",
    "api_key = pd.read_csv(localfolder+'SMS_SC_SS_Apikey.csv')\n",
    "publisher1 = publisher\n",
    "publisher1['NEW DP.DS or DP.sV'] = publisher1['NEW DP.DS or DP.sV'].str.replace('WWM.YFA.2','WWM.YFA')\n",
    "publisher1['NEW DP.DS or DP.sV'] = publisher1['NEW DP.DS or DP.sV'].str.replace('ZM.PL.2','ZM.PL')\n",
    "api_key_sms = api_key.merge(publisher1, left_on = 'DP.SV',right_on ='NEW DP.DS or DP.sV',how = 'inner' )\n",
    "api_key_sms = api_key_sms[['DP.SV','PUBID','Date', 'AcceptedTotal', 'AcceptedNew',\\\n",
    "       'AcceptedDuplicate', 'RejectedTotal', 'RejectedMobile',\\\n",
    "       'RejectedBlacklist', 'RejectedData', 'CostData', 'CostChecks',\\\n",
    "       'CostTotal']]\n",
    "api_key_sms['Date'] = pd.to_datetime(api_key_sms['Date'])\n",
    "Pl_data['Date'] =  pd.to_datetime(Pl_data['Date'] )\n",
    "Pl_data['PUBID']  = Pl_data['PUBID'].astype('str').str.split(\".\",expand = True)[0]\n",
    "api_key_sms['PUBID']  = api_key_sms['PUBID'].astype('str').str.split(\".\",expand = True)[0]\n",
    "rev_accept_df = pd.concat([Pl_data, api_key_sms], axis=0, ignore_index=True)\n",
    "rev_accept_df = rev_accept_df.fillna(0)\n",
    "rev_accept_df['PUBID']  = rev_accept_df['PUBID'].astype('str').str.split(\".\",expand = True)[0]\n",
    "rev_accept_df = rev_accept_df.drop(columns = 'DP.SV')\n",
    "rev_accept_df = rev_accept_df.groupby(['PUBID','Date']).sum().reset_index()\n",
    "\n",
    "\n",
    "sms_post = pd.read_csv(localfolder + 'SMSposts.csv')\n",
    "sms_post['Date'] = pd.to_datetime(sms_post['Dates'])\n",
    "sms_post['PUBID'] = sms_post['Pub Id'].astype('str').str.split(\".\",expand = True)[0]\n",
    "sms_post = sms_post.drop(columns = ['Dates','Pub Id','Pub Name'])\n",
    "post_data = pd.concat([rev_accept_df,sms_post], axis=0, ignore_index=True)\n",
    "post_data = post_data.fillna(0)\n",
    "post_data = post_data.groupby(['PUBID','Date']).sum().reset_index()\n",
    "publisher_raw['PUBID'] = publisher_raw['PUBID'].astype('str').str.split(\".\",expand = True)[0]\n",
    "post_data = post_data.merge(publisher_raw[['PUBID', 'NEW PUBLISHER','NEW DP.DS or DP.sV','DMA', 'INTERNAL STATUS',\n",
    "       'DATA TEAM STATUS', 'Sub Vertical ', 'SCOPE', 'COMPANY (DP)','DP ID']], how = 'left', on = 'PUBID')\n",
    "post_data.to_csv(localfolder+'p&l_data.csv',index =False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2184449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a828a65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132437.40225999997\n",
      "132437.40225999997\n",
      "132437.40226000003\n",
      "132437.40226\n"
     ]
    }
   ],
   "source": [
    "# offerwall reporting \n",
    "offer_sheet = infrastructure.get_smartsheet('offers_sms')\n",
    "offer_sheet = offer_sheet[offer_sheet['Hitpath ID'].isna() == False]\n",
    "offer_sheet['Hitpath ID'] = offer_sheet['Hitpath ID'].astype(str).str.split(\".\",expand = True)[0]\n",
    "offerwall = offerwall.rename(columns = {'offer_id':'Offer Wall ID'})\n",
    "print(offerwall[ 'amount'].sum())\n",
    "offerwall_update = offerwall.merge(offer_sheet[['Hitpath ID','Scheduling Name']], copy = False, how = 'left', left_on = 'Offer Wall ID', right_on = 'Hitpath ID')\n",
    "print(offerwall_update[ 'amount'].sum())\n",
    "offerwall_update = offerwall_update.rename(columns = {'Scheduling Name':\"Offer Wall Scheduling Name\" })\n",
    "offerwall_update = offerwall_update.merge(offer_sheet[['Hitpath ID','Scheduling Name']], copy = False, how = 'left', left_on = 'campaign_id', right_on = 'Hitpath ID')\n",
    "offerwall_update.loc[offerwall_update['Scheduling Name'].isna(),'Scheduling Name' ] = offerwall_update['campaign_name']\n",
    "\n",
    "offerwall_update = offerwall_update.rename(columns = {'Scheduling Name':\"Child Offer Campaign Name\" })\n",
    "offerwall_update[['Dash_Date_from_subid','affiliate_id','campaign_id',\"Child Offer Campaign Name\",'sub_id','Offer Wall ID',\"Offer Wall Scheduling Name\" ]] = offerwall_update[['Dash_Date_from_subid','affiliate_id','campaign_id',\"Child Offer Campaign Name\",'sub_id','Offer Wall ID',\"Offer Wall Scheduling Name\" ]].fillna(\"NULL\")\n",
    "offerwall_rev = offerwall_update.groupby(['Dash_Date_from_subid','affiliate_id','campaign_id',\"Child Offer Campaign Name\",'sub_id','Offer Wall ID',\"Offer Wall Scheduling Name\" ])[[ 'amount', 'Jump Page Clicks']].sum().reset_index()\n",
    "print(offerwall_rev[ 'amount'].sum())\n",
    "offerwall_rev['split_column'] = offerwall_rev['sub_id'].str.split('_')\n",
    "offerwall_rev['Send Strategy'] = 'P'\n",
    "offerwall_rev.loc[offerwall_rev['split_column'].str[5].str.contains(\"AR\",na = False),'Send Strategy'] = 'AR'\n",
    "offerwall_rev = offerwall_rev.rename(columns = {'amount':'Child Offer Revenue','Jump Page Clicks':'Child Offer Jump Page Clicks', 'campaign_id':'Child Offer ID'})\n",
    "merged_data_update = merged_data.add_suffix('- Offer Wall')\n",
    "offerwall_engage_subid = merged_data_update.groupby(['Sub_Id- Offer Wall'])[['Delivered- Offer Wall','Clicks- Offer Wall','Optout- Offer Wall','Cost- Offer Wall','Revenue- Offer Wall','Jump Page Clicks- Offer Wall']].sum().reset_index()\n",
    "offerwall_engage =  merged_data_update.groupby(['Date- Offer Wall','Affiliate_Id- Offer Wall','Hitpath_Offer_ID- Offer Wall','Send Strategy- Offer Wall'])[['Delivered- Offer Wall','Clicks- Offer Wall','Optout- Offer Wall','Cost- Offer Wall','Revenue- Offer Wall','Jump Page Clicks- Offer Wall']].sum().reset_index()\n",
    "offerwall_rev['affiliate_id'] = offerwall_rev['affiliate_id'].astype(str).str.split('.',expand = True)[0]\n",
    "offerwall_rev['Offer Wall ID'] = offerwall_rev['Offer Wall ID'].astype(str).str.split('.',expand = True)[0]\n",
    "offerwall_engage['Date- Offer Wall'] = pd.to_datetime(offerwall_engage['Date- Offer Wall'])\n",
    "offerwall_rev['Dash_Date_from_subid'] = pd.to_datetime(offerwall_rev['Dash_Date_from_subid'])\n",
    "offerwall_performance = offerwall_rev.merge(offerwall_engage_subid, left_on = ['sub_id'], right_on =['Sub_Id- Offer Wall'], how = 'left' )\n",
    "offerwall_performance_1 = offerwall_performance.loc[offerwall_performance['Sub_Id- Offer Wall'].isna() == False]\n",
    "offerwall_performance_2 = offerwall_performance.loc[offerwall_performance['Sub_Id- Offer Wall'].isna()== True].drop(columns = ['Sub_Id- Offer Wall','Delivered- Offer Wall','Clicks- Offer Wall','Optout- Offer Wall','Cost- Offer Wall','Revenue- Offer Wall','Jump Page Clicks- Offer Wall'])\n",
    "offerwall_performance_2 = offerwall_performance_2.groupby(['Dash_Date_from_subid','affiliate_id','Offer Wall ID','Send Strategy','Child Offer ID'])[[ 'Child Offer Revenue', 'Child Offer Jump Page Clicks']].sum().reset_index()\n",
    "offerwall_performance_2 = offerwall_performance_2.merge(offerwall_engage, left_on = ['Dash_Date_from_subid','affiliate_id','Offer Wall ID','Send Strategy'], right_on = ['Date- Offer Wall','Affiliate_Id- Offer Wall','Hitpath_Offer_ID- Offer Wall','Send Strategy- Offer Wall'], how ='left')\n",
    "offerwall_report = pd.concat([offerwall_performance_1,offerwall_performance_2])\n",
    "print(offerwall_report['Child Offer Revenue'].sum())\n",
    "offerwall_report.to_csv(localfolder + \"offerwall_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31148ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:25.694035Z",
     "start_time": "2023-08-10T16:34:24.083225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nfrom google.oauth2 import service_account\\nfrom googleapiclient.discovery import build\\nfrom googleapiclient.http import MediaFileUpload\\n# Replace with your JSON credentials file path and the folder ID where you want to upload the file\\nCREDENTIALS_FILE = filepath.service_account_location\\nFOLDER_ID = \\'1EQWlxXm8lQ5m8uLQPq0czH1-BStjy2a7\\'\\n\\ndef authenticate_drive():\\n    creds = service_account.Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=[\\'https://www.googleapis.com/auth/drive\\'])\\n    return build(\\'drive\\', \\'v3\\', credentials=creds)\\n\\ndef upload_file(service, file_path, folder_id):\\n    file_name = os.path.basename(file_path)\\n    file_metadata = {\\n        \\'name\\': file_name,\\n        \\'parents\\': folder_id\\n    }\\n\\n    media = MediaFileUpload(file_path, resumable=True)\\n\\n    file = service.files().create(body=file_metadata, media_body=media, fields=\\'id\\').execute()\\n\\n    print(f\"File ID: {file.get(\\'id\\')}\")\\n\\nif __name__ == \\'__main__\\':\\n    # Replace \\'your_file_path\\' with the path to the file you want to upload\\n    file_path_to_upload = localfolder + \\'SS_LC_merged_data.csv\\'\\n\\n    service = authenticate_drive()\\n    upload_file(service, file_path_to_upload, FOLDER_ID)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "# Replace with your JSON credentials file path and the folder ID where you want to upload the file\n",
    "CREDENTIALS_FILE = filepath.service_account_location\n",
    "FOLDER_ID = '1EQWlxXm8lQ5m8uLQPq0czH1-BStjy2a7'\n",
    "\n",
    "def authenticate_drive():\n",
    "    creds = service_account.Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=['https://www.googleapis.com/auth/drive'])\n",
    "    return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "def upload_file(service, file_path, folder_id):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_metadata = {\n",
    "        'name': file_name,\n",
    "        'parents': folder_id\n",
    "    }\n",
    "\n",
    "    media = MediaFileUpload(file_path, resumable=True)\n",
    "\n",
    "    file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "\n",
    "    print(f\"File ID: {file.get('id')}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace 'your_file_path' with the path to the file you want to upload\n",
    "    file_path_to_upload = localfolder + 'SS_LC_merged_data.csv'\n",
    "\n",
    "    service = authenticate_drive()\n",
    "    upload_file(service, file_path_to_upload, FOLDER_ID)\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9b71",
   "metadata": {},
   "source": [
    "## Verification Data Quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ea99754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:25.695062Z",
     "start_time": "2023-08-10T16:34:24.532432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1899-12-31       0.000000\n",
       "1999-12-31     652.800000\n",
       "2020-07-27    1681.000000\n",
       "2020-07-28     775.750000\n",
       "2020-07-29     924.200000\n",
       "                 ...     \n",
       "2023-09-02    4261.200000\n",
       "2023-09-03    4637.510500\n",
       "2023-09-04    5589.322495\n",
       "2023-09-05    5052.458588\n",
       "2023-09-06     210.550000\n",
       "Name: Revenue, Length: 1137, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jump page clicks \n",
    "merged_data.groupby('Date')['Revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a7a9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:25.696011Z",
     "start_time": "2023-08-10T16:34:24.682346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1899-12-31        0.0\n",
       "1999-12-31        0.0\n",
       "2020-07-27        0.0\n",
       "2020-07-28        0.0\n",
       "2020-07-29        0.0\n",
       "               ...   \n",
       "2023-09-02    11675.0\n",
       "2023-09-03    12904.0\n",
       "2023-09-04    13174.0\n",
       "2023-09-05    12068.0\n",
       "2023-09-06      442.0\n",
       "Name: Jump Page Clicks, Length: 1137, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jump page clicks \n",
    "merged_data.groupby('Date')['Jump Page Clicks'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6732c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.383814Z",
     "start_time": "2023-08-10T16:34:24.982665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-08-18    6342.0\n",
       "2023-08-19    5414.0\n",
       "2023-08-20    5318.0\n",
       "2023-08-21    6446.0\n",
       "2023-08-22    6028.0\n",
       "2023-08-23    6583.0\n",
       "2023-08-24    6435.0\n",
       "2023-08-25    7013.0\n",
       "2023-08-26    5822.0\n",
       "2023-08-27    6600.0\n",
       "2023-08-28    7143.0\n",
       "2023-08-29    7402.0\n",
       "2023-08-30    6983.0\n",
       "2023-08-31    6661.0\n",
       "2023-09-01    5976.0\n",
       "2023-09-02    5341.0\n",
       "2023-09-03    5227.0\n",
       "2023-09-04    5561.0\n",
       "2023-09-05    5927.0\n",
       "2023-09-06       0.0\n",
       "Name: Optout, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optout \n",
    "merged_data.groupby('Date')['Optout'].sum().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53f53eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.433804Z",
     "start_time": "2023-08-10T16:34:25.433057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JobId</th>\n",
       "      <th>Tstamp</th>\n",
       "      <th>Offer</th>\n",
       "      <th>Segment</th>\n",
       "      <th>CreativeId</th>\n",
       "      <th>CreativeName</th>\n",
       "      <th>Creative</th>\n",
       "      <th>DeliverCount</th>\n",
       "      <th>DeliverCost</th>\n",
       "      <th>UnsubCount</th>\n",
       "      <th>...</th>\n",
       "      <th>ClickCount</th>\n",
       "      <th>ConversionCount</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>Net</th>\n",
       "      <th>OOPerc</th>\n",
       "      <th>DeliverClickPerc</th>\n",
       "      <th>ClickConvPerc</th>\n",
       "      <th>ProfitPerc</th>\n",
       "      <th>ECPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Welcome to CSS Alerts! Access Your Account: {{...</td>\n",
       "      <td>6734</td>\n",
       "      <td>47.1380</td>\n",
       "      <td>308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.29</td>\n",
       "      <td>-49.29</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237891</td>\n",
       "      <td>2021-10-01 17:00:00+00:00</td>\n",
       "      <td>B2USRA - Cheris Studio Benefits A</td>\n",
       "      <td>B2 USRA - Day 1</td>\n",
       "      <td>93966.0</td>\n",
       "      <td>DAY 1</td>\n",
       "      <td>CS: Your Membership Request for Assistance has...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-02 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Welcome to CSS Alerts! Access Your Account: {{...</td>\n",
       "      <td>6859</td>\n",
       "      <td>48.0130</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.95</td>\n",
       "      <td>-49.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238383</td>\n",
       "      <td>2021-10-02 17:00:00+00:00</td>\n",
       "      <td>B2USRA - Cheris Studio Benefits A</td>\n",
       "      <td>B2 USRA - Day 1</td>\n",
       "      <td>93966.0</td>\n",
       "      <td>DAY 1</td>\n",
       "      <td>CS: Your Membership Request for Assistance has...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-03 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Welcome to CSS Alerts! Access Your Account: {{...</td>\n",
       "      <td>6794</td>\n",
       "      <td>47.5580</td>\n",
       "      <td>311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.74</td>\n",
       "      <td>-49.74</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31105</th>\n",
       "      <td>592990</td>\n",
       "      <td>2023-09-05 17:00:55+00:00</td>\n",
       "      <td>6322 - BB VAST MBC</td>\n",
       "      <td>MBC_WWM.YFA.2_1PLD.16-30DC_TMO</td>\n",
       "      <td>461620.0</td>\n",
       "      <td>VAST.6322.SC.MBC-P.1</td>\n",
       "      <td>MBC: Your application has been accepted!   Vie...</td>\n",
       "      <td>865</td>\n",
       "      <td>1.2975</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31106</th>\n",
       "      <td>592966</td>\n",
       "      <td>2023-09-05 17:00:56+00:00</td>\n",
       "      <td>6322 - BB VAST MBC</td>\n",
       "      <td>MBC_PN.SWP_30DC_TMO</td>\n",
       "      <td>461620.0</td>\n",
       "      <td>VAST.6322.SC.MBC-P.1</td>\n",
       "      <td>MBC: Your application has been accepted!   Vie...</td>\n",
       "      <td>32406</td>\n",
       "      <td>48.6090</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>4285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.80</td>\n",
       "      <td>-48.80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31107</th>\n",
       "      <td>592968</td>\n",
       "      <td>2023-09-05 17:00:57+00:00</td>\n",
       "      <td>5871 - NC BD MBC</td>\n",
       "      <td>MBC_PN.SWP_30DC_TMO</td>\n",
       "      <td>516714.0</td>\n",
       "      <td>BD.5871.SC.MBC.451671</td>\n",
       "      <td>MBC: You may be eligible for these assistance ...</td>\n",
       "      <td>953</td>\n",
       "      <td>1.4295</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31108</th>\n",
       "      <td>593081</td>\n",
       "      <td>2023-09-05 19:00:01+00:00</td>\n",
       "      <td>7878 - DA ADT DSS</td>\n",
       "      <td>DSS_TLG.PL_30DC</td>\n",
       "      <td>516812.0</td>\n",
       "      <td>ADT.7878.SC.DSS.451552</td>\n",
       "      <td>DSS: Your new home security offer comes with a...</td>\n",
       "      <td>931</td>\n",
       "      <td>1.3965</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31109</th>\n",
       "      <td>593081</td>\n",
       "      <td>2023-09-05 19:00:01+00:00</td>\n",
       "      <td>7878 - DA ADT DSS</td>\n",
       "      <td>DSS_TLG.PL_30DC</td>\n",
       "      <td>516811.0</td>\n",
       "      <td>ADT.7878.SC.DSS.451551</td>\n",
       "      <td>DSS: You received a $100 home security reward ...</td>\n",
       "      <td>981</td>\n",
       "      <td>1.4715</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31110 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        JobId                     Tstamp                              Offer  \\\n",
       "0           0  2021-10-01 00:00:00+00:00                                NaN   \n",
       "1      237891  2021-10-01 17:00:00+00:00  B2USRA - Cheris Studio Benefits A   \n",
       "2           0  2021-10-02 00:00:00+00:00                                NaN   \n",
       "3      238383  2021-10-02 17:00:00+00:00  B2USRA - Cheris Studio Benefits A   \n",
       "4           0  2021-10-03 00:00:00+00:00                                NaN   \n",
       "...       ...                        ...                                ...   \n",
       "31105  592990  2023-09-05 17:00:55+00:00                 6322 - BB VAST MBC   \n",
       "31106  592966  2023-09-05 17:00:56+00:00                 6322 - BB VAST MBC   \n",
       "31107  592968  2023-09-05 17:00:57+00:00                   5871 - NC BD MBC   \n",
       "31108  593081  2023-09-05 19:00:01+00:00                  7878 - DA ADT DSS   \n",
       "31109  593081  2023-09-05 19:00:01+00:00                  7878 - DA ADT DSS   \n",
       "\n",
       "                              Segment CreativeId            CreativeName  \\\n",
       "0                                 NaN        NaN                     NaN   \n",
       "1                     B2 USRA - Day 1    93966.0                   DAY 1   \n",
       "2                                 NaN        NaN                     NaN   \n",
       "3                     B2 USRA - Day 1    93966.0                   DAY 1   \n",
       "4                                 NaN        NaN                     NaN   \n",
       "...                               ...        ...                     ...   \n",
       "31105  MBC_WWM.YFA.2_1PLD.16-30DC_TMO   461620.0    VAST.6322.SC.MBC-P.1   \n",
       "31106             MBC_PN.SWP_30DC_TMO   461620.0    VAST.6322.SC.MBC-P.1   \n",
       "31107             MBC_PN.SWP_30DC_TMO   516714.0   BD.5871.SC.MBC.451671   \n",
       "31108                 DSS_TLG.PL_30DC   516812.0  ADT.7878.SC.DSS.451552   \n",
       "31109                 DSS_TLG.PL_30DC   516811.0  ADT.7878.SC.DSS.451551   \n",
       "\n",
       "                                                Creative  DeliverCount  \\\n",
       "0      Welcome to CSS Alerts! Access Your Account: {{...          6734   \n",
       "1      CS: Your Membership Request for Assistance has...             0   \n",
       "2      Welcome to CSS Alerts! Access Your Account: {{...          6859   \n",
       "3      CS: Your Membership Request for Assistance has...             0   \n",
       "4      Welcome to CSS Alerts! Access Your Account: {{...          6794   \n",
       "...                                                  ...           ...   \n",
       "31105  MBC: Your application has been accepted!   Vie...           865   \n",
       "31106  MBC: Your application has been accepted!   Vie...         32406   \n",
       "31107  MBC: You may be eligible for these assistance ...           953   \n",
       "31108  DSS: Your new home security offer comes with a...           931   \n",
       "31109  DSS: You received a $100 home security reward ...           981   \n",
       "\n",
       "       DeliverCost  UnsubCount  ...  ClickCount  ConversionCount  Revenue  \\\n",
       "0          47.1380         308  ...           0                0      0.0   \n",
       "1           0.0000           0  ...           0                0      0.0   \n",
       "2          48.0130         277  ...           0                0      0.0   \n",
       "3           0.0000           0  ...           0                0      0.0   \n",
       "4          47.5580         311  ...           0                0      0.0   \n",
       "...            ...         ...  ...         ...              ...      ...   \n",
       "31105       1.2975           7  ...          55                0      0.0   \n",
       "31106      48.6090         124  ...        4285                0      0.0   \n",
       "31107       1.4295           1  ...          41                0      0.0   \n",
       "31108       1.3965          44  ...          86                0      0.0   \n",
       "31109       1.4715          44  ...         132                0      0.0   \n",
       "\n",
       "       TotalCost    Net  OOPerc  DeliverClickPerc  ClickConvPerc  ProfitPerc  \\\n",
       "0          49.29 -49.29     4.6               0.0            0.0        -200   \n",
       "1           0.00   0.00     0.0               0.0            0.0           -   \n",
       "2          49.95 -49.95     4.0               0.0            0.0        -200   \n",
       "3           0.00   0.00     0.0               0.0            0.0           -   \n",
       "4          49.74 -49.74     4.6               0.0            0.0        -200   \n",
       "...          ...    ...     ...               ...            ...         ...   \n",
       "31105       1.31  -1.31     0.8               6.4            0.0      -200.0   \n",
       "31106      48.80 -48.80     0.4              13.2            0.0      -200.0   \n",
       "31107       1.43  -1.43     0.1               4.3            0.0      -200.0   \n",
       "31108       1.46  -1.46     4.7               9.2            0.0      -200.0   \n",
       "31109       1.54  -1.54     4.5              13.5            0.0      -200.0   \n",
       "\n",
       "      ECPM  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "31105  0.0  \n",
       "31106  0.0  \n",
       "31107  0.0  \n",
       "31108  0.0  \n",
       "31109  0.0  \n",
       "\n",
       "[31110 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_creative_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7939cb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.783993Z",
     "start_time": "2023-08-10T16:34:25.482646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-08-17     4057\n",
       "2023-08-18     4261\n",
       "2023-08-19     6507\n",
       "2023-08-20     5558\n",
       "2023-08-21    10285\n",
       "2023-08-22     4946\n",
       "2023-08-23     8320\n",
       "2023-08-24     6434\n",
       "2023-08-25     6187\n",
       "2023-08-26     4079\n",
       "2023-08-27     5274\n",
       "2023-08-28     4643\n",
       "2023-08-29     3948\n",
       "2023-08-30     2267\n",
       "2023-08-31     6028\n",
       "2023-09-01     4410\n",
       "2023-09-02     2140\n",
       "2023-09-03     3634\n",
       "2023-09-04     4283\n",
       "2023-09-05     3147\n",
       "Name: UnsubCount, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_creative_stats['date'] = pd.to_datetime(raw_creative_stats['Tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "raw_creative_stats.groupby('date')['UnsubCount'].sum().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12f4b122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.844129Z",
     "start_time": "2023-08-10T16:34:26.383315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2023-08-17    4257\n",
       "2023-08-18    4275\n",
       "2023-08-19    3656\n",
       "2023-08-20    3671\n",
       "2023-08-21    4231\n",
       "2023-08-22    4243\n",
       "2023-08-23    4399\n",
       "2023-08-24    4387\n",
       "2023-08-25    4522\n",
       "2023-08-26    4250\n",
       "2023-08-27    4101\n",
       "2023-08-28    4737\n",
       "2023-08-29    4906\n",
       "2023-08-30    4785\n",
       "2023-08-31    4523\n",
       "2023-09-01    4027\n",
       "2023-09-02    3556\n",
       "2023-09-03    3740\n",
       "2023-09-04    3770\n",
       "2023-09-05    3980\n",
       "Name: Optout, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows['date'] = pd.to_datetime(flows['Period'],format = 'mixed').dt.strftime(\"%Y-%m-%d\")\n",
    "flows.groupby('date')['Optout'].sum().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7640e128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.993412Z",
     "start_time": "2023-08-10T16:34:26.387227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Name', 'Period', 'ListName', 'OfferName',\n",
       "       'CountAutoresponderWelcome', 'CountAutoresponderHelp',\n",
       "       'CountAutoresponderStop', 'CountMarketing', 'CountOther', 'Cost',\n",
       "       'Delivered', 'Clicks', 'CountPreview', 'Optout', 'CountConversion',\n",
       "       'Revenue', 'Net', 'DeliverClickPerc', 'ClickConvPerc', 'Ecpm',\n",
       "       'NetEcpm', 'Profit%', 'Revenue Source', 'Code_Type', 'Shortcode Name',\n",
       "       'Shortcode', 'Dataset', 'Date', 'AR Flow ID', 'AR Day', 'Hitpath ID',\n",
       "       'AR Flow', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e3aeb20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.995103Z",
     "start_time": "2023-08-10T16:34:26.387741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37890.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate SMS Flow Report\n",
    "may1_flow = flows_clean[(flows_clean['Date'] >= '2023-04-01') & (flows_clean['Date'] <= '2023-05-02') ]\n",
    "may1_flow[(may1_flow['Shortcode Name'] =='CSS') &  (may1_flow['Hitpath ID'] == '6363')]['Delivered'].sum()\n",
    "may1_flow = flows_clean2[(flows_clean2['Date'] >= '2023-04-01') & (flows_clean2['Date'] <= '2023-05-02')]\n",
    "may1_flow[(may1_flow['Shortcode Name'] =='CSS') &  (may1_flow['Hitpath Id'] == '6363')]['Delivered'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e84243f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:26.995933Z",
     "start_time": "2023-08-10T16:34:26.388415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212424.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate SMS Offer Report \n",
    "combined_csv_ss_creative_na['Offer ID'] = combined_csv_ss_creative_na['Offer'].astype('str').str.extract(r'\\b(\\d{4,5})\\b')\n",
    "combined_csv_ss_creative_na['Date'] = pd.to_datetime(combined_csv_ss_creative_na['Date'])\n",
    "may1_creative_na = combined_csv_ss_creative_na[(combined_csv_ss_creative_na['Date'] >= '2023-04-01') & ((combined_csv_ss_creative_na['Date'] <= '2023-05-02'))]\n",
    "may1_creative_na[may1_creative_na['Offer ID'] == '6363']['Delivered'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1def51ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:33.036847Z",
     "start_time": "2023-08-10T16:34:26.389069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shortcode Name</th>\n",
       "      <th>Hitpath_Offer_ID</th>\n",
       "      <th>Delivered_x</th>\n",
       "      <th>Shortcodes</th>\n",
       "      <th>Offer.1</th>\n",
       "      <th>Delivered_y</th>\n",
       "      <th>Delivered_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CSS</td>\n",
       "      <td>6363</td>\n",
       "      <td>250314.0</td>\n",
       "      <td>CSS</td>\n",
       "      <td>6363</td>\n",
       "      <td>318261.0</td>\n",
       "      <td>-67947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11244</td>\n",
       "      <td>125126.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11244</td>\n",
       "      <td>103070.0</td>\n",
       "      <td>22056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11245</td>\n",
       "      <td>116638.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11245</td>\n",
       "      <td>95476.0</td>\n",
       "      <td>21162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11246</td>\n",
       "      <td>111604.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11246</td>\n",
       "      <td>91435.0</td>\n",
       "      <td>20169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11247</td>\n",
       "      <td>107278.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11247</td>\n",
       "      <td>88099.0</td>\n",
       "      <td>19179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11603</td>\n",
       "      <td>99295.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11603</td>\n",
       "      <td>82114.0</td>\n",
       "      <td>17181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11604</td>\n",
       "      <td>94319.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11604</td>\n",
       "      <td>78536.0</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11605</td>\n",
       "      <td>103486.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11605</td>\n",
       "      <td>85195.0</td>\n",
       "      <td>18291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FLC</td>\n",
       "      <td>11644</td>\n",
       "      <td>140719.0</td>\n",
       "      <td>FLC</td>\n",
       "      <td>11644</td>\n",
       "      <td>117553.0</td>\n",
       "      <td>23166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>HZB</td>\n",
       "      <td>10518</td>\n",
       "      <td>71452.0</td>\n",
       "      <td>HZB</td>\n",
       "      <td>10518</td>\n",
       "      <td>71412.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>HZB</td>\n",
       "      <td>6270</td>\n",
       "      <td>236462.0</td>\n",
       "      <td>HZB</td>\n",
       "      <td>6270</td>\n",
       "      <td>286543.0</td>\n",
       "      <td>-50081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>HZB</td>\n",
       "      <td>6322</td>\n",
       "      <td>523338.0</td>\n",
       "      <td>HZB</td>\n",
       "      <td>6322</td>\n",
       "      <td>523257.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>HZB</td>\n",
       "      <td>7878</td>\n",
       "      <td>146330.0</td>\n",
       "      <td>HZB</td>\n",
       "      <td>7878</td>\n",
       "      <td>146291.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11248</td>\n",
       "      <td>171273.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11248</td>\n",
       "      <td>196332.0</td>\n",
       "      <td>-25059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11249</td>\n",
       "      <td>128785.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11249</td>\n",
       "      <td>152667.0</td>\n",
       "      <td>-23882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11250</td>\n",
       "      <td>90229.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11250</td>\n",
       "      <td>113231.0</td>\n",
       "      <td>-23002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11251</td>\n",
       "      <td>49776.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11251</td>\n",
       "      <td>72139.0</td>\n",
       "      <td>-22363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11577</td>\n",
       "      <td>32636.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11577</td>\n",
       "      <td>54600.0</td>\n",
       "      <td>-21964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11578</td>\n",
       "      <td>26871.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11578</td>\n",
       "      <td>48231.0</td>\n",
       "      <td>-21360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11579</td>\n",
       "      <td>24222.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11579</td>\n",
       "      <td>43921.0</td>\n",
       "      <td>-19699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>MBC</td>\n",
       "      <td>11580</td>\n",
       "      <td>209584.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>11580</td>\n",
       "      <td>236687.0</td>\n",
       "      <td>-27103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>MBC</td>\n",
       "      <td>6322</td>\n",
       "      <td>19559.0</td>\n",
       "      <td>MBC</td>\n",
       "      <td>6322</td>\n",
       "      <td>19640.0</td>\n",
       "      <td>-81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Shortcode Name Hitpath_Offer_ID  Delivered_x Shortcodes Offer.1  \\\n",
       "29             CSS             6363     250314.0        CSS    6363   \n",
       "43             FLC            11244     125126.0        FLC   11244   \n",
       "44             FLC            11245     116638.0        FLC   11245   \n",
       "45             FLC            11246     111604.0        FLC   11246   \n",
       "46             FLC            11247     107278.0        FLC   11247   \n",
       "49             FLC            11603      99295.0        FLC   11603   \n",
       "50             FLC            11604      94319.0        FLC   11604   \n",
       "51             FLC            11605     103486.0        FLC   11605   \n",
       "52             FLC            11644     140719.0        FLC   11644   \n",
       "62             HZB            10518      71452.0        HZB   10518   \n",
       "85             HZB             6270     236462.0        HZB    6270   \n",
       "87             HZB             6322     523338.0        HZB    6322   \n",
       "93             HZB             7878     146330.0        HZB    7878   \n",
       "100            MBC            11248     171273.0        MBC   11248   \n",
       "101            MBC            11249     128785.0        MBC   11249   \n",
       "102            MBC            11250      90229.0        MBC   11250   \n",
       "103            MBC            11251      49776.0        MBC   11251   \n",
       "105            MBC            11577      32636.0        MBC   11577   \n",
       "106            MBC            11578      26871.0        MBC   11578   \n",
       "107            MBC            11579      24222.0        MBC   11579   \n",
       "108            MBC            11580     209584.0        MBC   11580   \n",
       "113            MBC             6322      19559.0        MBC    6322   \n",
       "\n",
       "     Delivered_y  Delivered_diff  \n",
       "29      318261.0        -67947.0  \n",
       "43      103070.0         22056.0  \n",
       "44       95476.0         21162.0  \n",
       "45       91435.0         20169.0  \n",
       "46       88099.0         19179.0  \n",
       "49       82114.0         17181.0  \n",
       "50       78536.0         15783.0  \n",
       "51       85195.0         18291.0  \n",
       "52      117553.0         23166.0  \n",
       "62       71412.0            40.0  \n",
       "85      286543.0        -50081.0  \n",
       "87      523257.0            81.0  \n",
       "93      146291.0            39.0  \n",
       "100     196332.0        -25059.0  \n",
       "101     152667.0        -23882.0  \n",
       "102     113231.0        -23002.0  \n",
       "103      72139.0        -22363.0  \n",
       "105      54600.0        -21964.0  \n",
       "106      48231.0        -21360.0  \n",
       "107      43921.0        -19699.0  \n",
       "108     236687.0        -27103.0  \n",
       "113      19640.0           -81.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the difference between Tableau Data & SMS Report\n",
    "may1 = merged_data[(merged_data['Date'] >= '2023-04-01') & (merged_data['Date'] <= '2023-05-02') ]\n",
    "may1['Delivered'].sum()\n",
    "import_df = pd.read_csv('/Users/liliguo/Downloads/sms_report_2023-05-01_2023-05-02.csv')\n",
    "import_df = pd.read_csv('/Users/liliguo/Downloads/sms_report_2023-04-01_2023-05-03.csv')\n",
    "import_df\n",
    "a = may1.groupby(['Shortcode Name','Hitpath_Offer_ID'])['Delivered'].sum().reset_index()\n",
    "b = import_df.groupby(['Shortcodes','Offer.1'])['Delivered'].sum().reset_index()\n",
    "c = a.merge(b[['Shortcodes','Offer.1','Delivered']], left_on = ['Shortcode Name','Hitpath_Offer_ID'], right_on = ['Shortcodes','Offer.1'],how = 'left')\n",
    "c['Delivered_diff'] = c['Delivered_x'] -  c['Delivered_y']\n",
    "c[(c['Delivered_diff']!=0) & (c['Delivered_diff'].isna() == False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2273794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:33.037755Z",
     "start_time": "2023-08-10T16:34:32.082188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-145394.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['Delivered_diff'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7c17bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.906980Z",
     "start_time": "2023-08-10T16:34:32.082989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The revenue discrepency after November between raw file and Tableau data is $ 1065.45\n",
      "The total revenue after November is $ 1343092.83\n",
      "The revenue discrepency is 0.0 % of the total revenue after November\n"
     ]
    }
   ],
   "source": [
    "# Check & Examination: \n",
    "# Revenue files sum up after November \n",
    "rev_file = combined_csv[combined_csv['date']>='2022-11-01'].reset_index(drop=True)['amount'].sum()\n",
    "# Revenue we made after November\n",
    "after_merge = combined_csv_ss_creative_na['Revenue'].sum() + combined_csv_ss_creative_notna['Revenue'].sum() + combined_csv_ss_exclude_11['Revenue'].sum() +flows_clean2['Revenue'].sum() + combined_csv_ss_last_11['amount'].sum() + lc_df_full_11['amount'].sum() + combined_csv_push_11['Revenue'].sum()\n",
    "\n",
    "print(\"The revenue discrepency after November between raw file and Tableau data is $\",round((rev_file - after_merge),2))\n",
    "print(\"The total revenue after November is $\", round(rev_file,2))\n",
    "print(\"The revenue discrepency is\", round((rev_file - after_merge) /rev_file,2)*100, \"% of the total revenue after November\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5509357e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.907309Z",
     "start_time": "2023-08-10T16:34:34.890413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14524.809999999998"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " combined_csv_ss_last_11['amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aca4deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.907771Z",
     "start_time": "2023-08-10T16:34:34.893878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Cost after November is $ 389818.49\n",
      "Margin is 71.0 %\n"
     ]
    }
   ],
   "source": [
    "after_merge_cost = combined_csv_ss_creative_na['Cost'].sum() + combined_csv_ss_creative_notna['Cost'].sum()\n",
    "print(\"The total Cost after November is $\", round(after_merge_cost,2))\n",
    "print(\"Margin is\", round((rev_file - after_merge_cost) /rev_file,2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "523eb27c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.908260Z",
     "start_time": "2023-08-10T16:34:34.932283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jump Page Clicks discrepancy: 25821.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Jump Page Clicks discrepancy:\",merged_data['Jump Page Clicks'].sum() - jumppageclicks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a351a0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.909123Z",
     "start_time": "2023-08-10T16:34:34.932885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\njobs[\\'date\\'] = pd.to_datetime(jobs[\\'scheduled_tstamp\\']).dt.strftime(\"%Y-%m-%d\")\\ncombined_csv_ss_creative_na[\\'Date\\'] =  pd.to_datetime(combined_csv_ss_creative_na[\\'Date\\'] ).dt.strftime(\"%Y-%m-%d\")\\njob_11 = jobs[jobs[\\'scheduled_tstamp\\'] >= \\'2022-11-01\\']\\njob_11_by_date = job_11.groupby(\\'date\\')[\\'cost\\'].sum().reset_index(name = \\'cost\\')\\ncombined_csv_ss_creative_na_cost_only = combined_csv_ss_creative_na.groupby(\\'Date\\')[\\'Cost\\'].sum().reset_index(name = \\'na_cc_Cost\\')\\ncombined_csv_ss_creative_na_cost_only[\\'Date\\'] =  pd.to_datetime(combined_csv_ss_creative_na_cost_only[\\'Date\\'] ).dt.strftime(\"%Y-%m-%d\")\\ncombined_csv_ss_creative_notna_cost_only = combined_csv_ss_creative_notna.groupby(\\'Date\\')[\\'Cost\\'].sum().reset_index(name = \\'not_na_cc_Cost\\')\\ncombined_csv_ss_creative_notna_cost_only[\\'Date\\'] = pd.to_datetime(combined_csv_ss_creative_notna_cost_only[\\'Date\\'] ).dt.strftime(\"%Y-%m-%d\")\\njob_11_by_date1 = job_11_by_date.merge(combined_csv_ss_creative_na_cost_only,left_on = \\'date\\', right_on = \\'Date\\', how = \\'left\\',copy = False)\\njob_11_by_date2 = job_11_by_date1.merge(combined_csv_ss_creative_notna_cost_only,left_on = \\'date\\', right_on = \\'Date\\', how = \\'left\\', copy = False)\\njob_11_by_date2[\\'na_cc_Cost\\'] = job_11_by_date2[\\'na_cc_Cost\\'].fillna(0)\\njob_11_by_date2[\\'diff\\'] = job_11_by_date2[\\'na_cc_Cost\\'] + job_11_by_date2[\\'not_na_cc_Cost\\'] - job_11_by_date2[\\'cost\\']\\njob_11_by_date2[\\'diff\\'] = round(job_11_by_date2[\\'diff\\'],0)\\njob_11_by_date2[job_11_by_date2[\\'diff\\']!=0]\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "jobs['date'] = pd.to_datetime(jobs['scheduled_tstamp']).dt.strftime(\"%Y-%m-%d\")\n",
    "combined_csv_ss_creative_na['Date'] =  pd.to_datetime(combined_csv_ss_creative_na['Date'] ).dt.strftime(\"%Y-%m-%d\")\n",
    "job_11 = jobs[jobs['scheduled_tstamp'] >= '2022-11-01']\n",
    "job_11_by_date = job_11.groupby('date')['cost'].sum().reset_index(name = 'cost')\n",
    "combined_csv_ss_creative_na_cost_only = combined_csv_ss_creative_na.groupby('Date')['Cost'].sum().reset_index(name = 'na_cc_Cost')\n",
    "combined_csv_ss_creative_na_cost_only['Date'] =  pd.to_datetime(combined_csv_ss_creative_na_cost_only['Date'] ).dt.strftime(\"%Y-%m-%d\")\n",
    "combined_csv_ss_creative_notna_cost_only = combined_csv_ss_creative_notna.groupby('Date')['Cost'].sum().reset_index(name = 'not_na_cc_Cost')\n",
    "combined_csv_ss_creative_notna_cost_only['Date'] = pd.to_datetime(combined_csv_ss_creative_notna_cost_only['Date'] ).dt.strftime(\"%Y-%m-%d\")\n",
    "job_11_by_date1 = job_11_by_date.merge(combined_csv_ss_creative_na_cost_only,left_on = 'date', right_on = 'Date', how = 'left',copy = False)\n",
    "job_11_by_date2 = job_11_by_date1.merge(combined_csv_ss_creative_notna_cost_only,left_on = 'date', right_on = 'Date', how = 'left', copy = False)\n",
    "job_11_by_date2['na_cc_Cost'] = job_11_by_date2['na_cc_Cost'].fillna(0)\n",
    "job_11_by_date2['diff'] = job_11_by_date2['na_cc_Cost'] + job_11_by_date2['not_na_cc_Cost'] - job_11_by_date2['cost']\n",
    "job_11_by_date2['diff'] = round(job_11_by_date2['diff'],0)\n",
    "job_11_by_date2[job_11_by_date2['diff']!=0]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fbc176c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.910159Z",
     "start_time": "2023-08-10T16:34:34.933318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost discrepency after November between raw file and Tableau data is $ -30468.7\n",
      "The total revenue after November is $ 359349.79\n",
      "The cost discrepency is -8.0 % of the total cost after November\n"
     ]
    }
   ],
   "source": [
    "job_cost = jobs[jobs['scheduled_tstamp'] >= '2022-11-01']['cost'].sum()\n",
    "cost_diff = (job_cost - after_merge_cost)\n",
    "cost_pec = cost_diff / job_cost\n",
    "print(\"The cost discrepency after November between raw file and Tableau data is $\",round(cost_diff,2))\n",
    "print(\"The total revenue after November is $\", round(job_cost,2))\n",
    "print(\"The cost discrepency is\", round(cost_pec,2)*100, \"% of the total cost after November\")\n",
    "# normal, because we added kaylera cost      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "162aab05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.910963Z",
     "start_time": "2023-08-10T16:34:34.981921Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/3293252533.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  march['job0'] = 'NOt 0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job0\n",
       "NOt 0    8016657.0\n",
       "Name: Delivered, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "march = combined_csv_ss_creative_notna[(combined_csv_ss_creative_notna['Date'] >= '2023-03-01') & (combined_csv_ss_creative_notna['Date'] <= '2023-03-31')]\n",
    "combined_csv_ss_creative_na\n",
    "march['job0'] = 'NOt 0'\n",
    "march.loc[march['Job_Id']=='0','job0'] = '0'\n",
    "march.groupby('job0')['Delivered'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ba669d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.912065Z",
     "start_time": "2023-08-10T16:34:34.982745Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/9wfkcg6j573945pbm52zxh_80000gn/T/ipykernel_5409/3781066462.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  march['job0'] = 'NOt 0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job0   Send Strategy\n",
       "NOt 0  AR               464052.0\n",
       "Name: Delivered, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv_ss_creative_na['Date'] = pd.to_datetime(combined_csv_ss_creative_na['Date'])\n",
    "march = combined_csv_ss_creative_na[(combined_csv_ss_creative_na['Date'] >= '2023-03-01') & (combined_csv_ss_creative_na['Date'] <= '2023-03-31')]\n",
    "march['job0'] = 'NOt 0'\n",
    "march.loc[march['Job_Id']=='0','job0'] = '0'\n",
    "march.groupby(['job0','Send Strategy'])['Delivered'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc849ca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.960984Z",
     "start_time": "2023-08-10T16:34:34.997084Z"
    }
   },
   "outputs": [],
   "source": [
    "a = march.groupby('Job_Id')['Delivered'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f5e59a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.961579Z",
     "start_time": "2023-08-10T16:34:35.032328Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv('/Users/liliguo/Downloads/sms_report_2023-03-01_2023-04-01 (1).csv')\n",
    "b = temp.groupby('JobId')['DeliverCount'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4dac526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.964663Z",
     "start_time": "2023-08-10T16:34:35.034889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Id</th>\n",
       "      <th>Delivered</th>\n",
       "      <th>JobId</th>\n",
       "      <th>DeliverCount</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499243</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499244</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499245</td>\n",
       "      <td>4331</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499246</td>\n",
       "      <td>4070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499247</td>\n",
       "      <td>1627</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5485</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>532393</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>532394</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>532395</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>532396</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>532397</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5489 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Job_Id  Delivered   JobId  DeliverCount  Diff\n",
       "1        NaN        NaN  499243           600   NaN\n",
       "2        NaN        NaN  499244          2000   NaN\n",
       "3        NaN        NaN  499245          4331   NaN\n",
       "4        NaN        NaN  499246          4070   NaN\n",
       "5        NaN        NaN  499247          1627   NaN\n",
       "...      ...        ...     ...           ...   ...\n",
       "5485     NaN        NaN  532393             0   NaN\n",
       "5486     NaN        NaN  532394             2   NaN\n",
       "5487     NaN        NaN  532395            83   NaN\n",
       "5488     NaN        NaN  532396            87   NaN\n",
       "5489     NaN        NaN  532397          2014   NaN\n",
       "\n",
       "[5489 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.merge(b, left_on = 'Job_Id',right_on = 'JobId',how = 'outer')\n",
    "c['Diff'] = c['Delivered'] - c['DeliverCount']\n",
    "c[c['Diff']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "070eadb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.965596Z",
     "start_time": "2023-08-10T16:34:35.331947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579747.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[merged_data['Date'] == '2023-05-01']['Delivered'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2735e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-10T16:34:43.965909Z",
     "start_time": "2023-08-10T16:34:35.333002Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
