{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e682692",
   "metadata": {},
   "source": [
    "# Zebra\n",
    "The Jump Page Testing System in SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07f454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsheets import Sheets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "import smartsheet\n",
    "import infrastructure\n",
    "import pygsheets\n",
    "from scipy.stats import zscore\n",
    "# import filepaths\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "import filepath\n",
    "import infrastructure\n",
    "\n",
    "bold = \"\\033[1m\"\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bc1ee",
   "metadata": {},
   "source": [
    "### Read in Files\n",
    "\n",
    "<strong>Requirements</strong>\n",
    "- Lexi\n",
    "- EIMT\n",
    "- Offer_WK\n",
    "- Cobra (mamba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f40544",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### - Getting Lexi - #########################\n",
    "def reading_lexi():\n",
    "    global lexi\n",
    "    print(\"Reading in SMS Lexi...\")\n",
    "    sms_lexi = pd.read_csv(filepath.input_folder + '/SS_LC_merged_data.csv')\n",
    "    sms_lexi = sms_lexi.drop('Offer Vertical', axis=1)\n",
    "    lexi = infrastructure.transform_sms_df(sms_lexi)\n",
    "    lexi['Hitpath Offer ID'] = lexi['Hitpath Offer ID'].astype(str).str.replace('.0', '')\n",
    "    df = lexi\n",
    "    return print(\"SMS Lexi is loaded.\")\n",
    "\n",
    "######################### - Getting Smartsheet - #########################\n",
    "def reading_smartsheet():\n",
    "    print(\"Gathering EIMT and Offer Workbook\")\n",
    "    global EMIT\n",
    "    global offer_wk\n",
    "    # use smartsheet api to get offer workbook and EIMT\n",
    "    EMIT = infrastructure.get_publisher()\n",
    "    offer_wk = infrastructure.get_smartsheet('offers_sms')\n",
    "    offer_wk['Hitpath Offer ID'] = offer_wk['Hitpath Offer ID'].astype(str).str.replace('.0', '')\n",
    "    return print(\"Smartsheets are loaded.\")\n",
    "def reading_cobra():\n",
    "    global cobra\n",
    "    cobra = infrastructure.get_mamba_full_slot()\n",
    "    cobra['Hitpath Offer ID'] = cobra['Hitpath Offer ID'].astype(str).str.replace('.0', '')\n",
    "\n",
    "    # Want to avoid using inactive accounts, so only consider accounts that have data within the past 3 days\n",
    "    lexi3 = lexi[lexi['Date'] > pd.Timestamp(lexi['Date'].max() - timedelta(2))]\n",
    "    active_accounts = lexi3['shortcode_DP.SV'].unique().tolist()\n",
    "    cobra = cobra[cobra['shortcode_DP.SV'].isin(active_accounts)]\n",
    "    \n",
    "    return print(\"Mamba are loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdbcdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in SMS Lexi...\n",
      "SMS Lexi is loaded.\n",
      "Gathering EIMT and Offer Workbook\n",
      "Smartsheets are loaded.\n",
      "Mamba are loaded.\n"
     ]
    }
   ],
   "source": [
    "reading_lexi()\n",
    "reading_smartsheet()\n",
    "reading_cobra()\n",
    "# lexi = lexi.merge(offer_wk[['Hitpath Offer ID','Vertical']], left_on = 'Hitpath Offer ID',right_on = 'Hitpath Offer ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceddc73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UAA_SPK.SWP2', 'FLC_SPK.SWP2', 'DSS_ZM.PL.2', 'HZB_ZM.PL.2', 'SVT_B2.F', 'HZB_B2.F', 'MBC_NPD.RTO', 'FLC_NPD.RTO', 'MBC_I.RC', 'FLC_I.RC', 'DSS_SM.SRV', 'HZB_SM.SRV', 'HZB_CM.OSR', 'MBC_CM.OSR', 'MBC_WWM.YFA.2', 'FLC_WWM.YFA.2', 'SVT_AMD.PL', 'HZB_AMD.PL', 'SVT_AL.PL.4', 'HZB_AL.PL.4', 'SVT_AL.PL.3', 'HZB_AL.PL.3', 'A4F_I.A4F', 'FBH_I.FBH', 'DSS_TLG.PL', 'HZB_TLG.PL', 'FRH_I.FRH', 'FLC_EDM.247L', 'MBC_EDM.247L', 'MBC_PN.SWP', 'FLC_PN.SWP', 'MBC_PA.PS', 'HZB_PA.PS', 'UAA_FSM.YS', 'HZB_FSM.YS', 'SVT_DOT.PL', 'HZB_DOT.PL', 'DSS_IM.SVY', 'HZB_IM.SVY', 'FLC_I.CC', 'MBC_I.CC', 'HZB_RHD.CC', 'DSS_RHD.CC', 'UAA_SPK.CR2', 'FLC_SPK.CR2', 'MBC_PN.FC', 'FLC_PN.FC', 'MFA_I.MFA', 'N3G_I.N3G', 'SVT_AL.PL', 'HZB_AL.PL', 'SVT_AL.PL.2', 'HZB_AL.PL.2', 'DSS_GR.PL', 'FLC_GR.PL', 'DSS_JET.ZTA', 'FLC_JET.ZTA']\n"
     ]
    }
   ],
   "source": [
    "mamba_dic_df = infrastructure.get_mamba_directory()\n",
    "mamba_dic_df['Text ID'] = mamba_dic_df['Account'].str.split('_', expand=True)[2]\n",
    "current_active_segment = mamba_dic_df['Segment'].str.split('\\n').tolist()\n",
    "current_active_segment = [item for sublist in current_active_segment for item in sublist if item]\n",
    "current_active_sc_sv = mamba_dic_df['Account'].str[:-7].unique().tolist()\n",
    "#EMIT[\"Dataset\"] = EMIT[\"Text ID\"].str.cat(EMIT[\"Text DP\"], sep = \"_\")\n",
    "#DPPub_to_Dataset = dict(zip(EMIT['shortcode_DP.SV'], EMIT['Dataset']))\n",
    "#Dataset_to_DPPub = dict(zip(EMIT['Dataset'], EMIT['shortcode_DP.SV']))\n",
    "print(current_active_sc_sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a900a19",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d80f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_CT_eligiblity(default_max_drops, offer, lexi, cobra):\n",
    "    \"\"\" \n",
    "    #sheets = Sheets.from_files(filepaths.gsheets)\n",
    "    #viper_settings = sheets.get(CT_settings_url)\n",
    "\n",
    "    #CT_settings = viper_settings.find('Testing Settings').to_frame()\n",
    "    #CT_settings = CT_settings.fillna(default_max_drops) # MAX NUMBER OF P DROPS IS DEFAULTED TO 2\n",
    "    #CT_settings_dict = dict(zip(CT_settings['shortcode_DP.SV'],CT_settings['Max Number of CT']))\n",
    "    \"\"\"\n",
    "    CT_settings_dict = {}\n",
    "    for i in current_active_sc_sv: \n",
    "        CT_settings_dict[i] = default_max_drops\n",
    "    # Dates and Parameter Stuff\n",
    "    ## Calculate the starting date of the current week\n",
    "    current_date = datetime.today()\n",
    "    start_of_week = datetime.today() - timedelta(days=current_date.weekday() + 1)\n",
    "    start_date = datetime.today()\n",
    "    end_date = start_date + timedelta(14)\n",
    "\n",
    "    \n",
    "    # Manipulating Cobra\n",
    "    #cobra['shortcode_DP.SV'] = cobra['Dataset'].map(dataset_convertor)\n",
    "    cobra_temp = cobra.groupby([pd.Grouper(key='Date', freq='W'), 'shortcode_DP.SV'])['Send Strategy'].count().reset_index()\n",
    "    cobra_temp = cobra_temp[['shortcode_DP.SV', 'Date']]\n",
    "    Account_CT_Checklist = cobra_temp[cobra_temp['Date'] >= (start_of_week - timedelta(1))].sort_values(by = ['shortcode_DP.SV', 'Date'], ascending = True)\n",
    "    #Account_CT_Checklist = pd.DataFrame({'shortcode_DP.SV': cobra_temp[cobra_temp['Date'] >  dt.date.today()]['shortcode_DP.SV'].unique()})\n",
    "    cobra_CT = cobra[cobra['Send Strategy'] == 'CT']\n",
    "\n",
    "         # use pd.Grouper to get current and future week\n",
    "    cobra_weekly_CT = cobra_CT.groupby([pd.Grouper(key='Date', freq='W'), 'shortcode_DP.SV'])['Send Strategy'].count().reset_index()\n",
    "    cobra_weekly_CT.rename(columns={'Send Strategy': 'CT Count'}, inplace=True)\n",
    "    cobra_weekly_CT = cobra_weekly_CT[cobra_weekly_CT['Date'] > (start_of_week - timedelta(1))]\n",
    "    cobra_weekly_CT['Max CT'] = cobra_weekly_CT['shortcode_DP.SV'].map(CT_settings_dict)\n",
    "    cobra_weekly_CT['CT available'] = cobra_weekly_CT['Max CT'] - cobra_weekly_CT['CT Count']\n",
    "    Account_CT_Checklist = pd.merge(Account_CT_Checklist, cobra_weekly_CT, on=['shortcode_DP.SV','Date'], how='left')\n",
    "    # earliest possible date\n",
    "    default_earliest_date = dt.date.today() + timedelta(2)\n",
    "    \n",
    "# See if account has a P drop to swap and is under its Max CT, if so, swap the P drop to a CT\n",
    "    cobra_P = cobra[cobra['Send Strategy'] == 'P']\n",
    "    cobra_P = cobra_P[cobra_P['Hitpath Offer ID'] == offer]\n",
    "    #cobra_P = cobra_P[cobra_P['Date'].dt.date >= default_earliest_date]\n",
    "    cobra_weekly_P = cobra_P.groupby([pd.Grouper(key='Date', freq='W'), 'shortcode_DP.SV'])['Send Strategy'].count().reset_index()\n",
    "    cobra_weekly_P.rename(columns={'Send Strategy': 'P Available to Swap to CT'}, inplace=True)\n",
    "    cobra_weekly_P = cobra_weekly_P[cobra_weekly_P['Date'] > (start_of_week - timedelta(1))]\n",
    "    Account_CT_Checklist = pd.merge(Account_CT_Checklist, cobra_weekly_P, on=['shortcode_DP.SV','Date'], how='left')\n",
    "\n",
    "# If not, but is under Max CT and has sent the offer more than 1 P drop in last 30 days, send in P slot\n",
    "## Can send in normal P slot?\n",
    "    date_threshhold = max(lexi['Date']) - timedelta(30)\n",
    "    lexi_30 = lexi[lexi['Date'] > date_threshhold]\n",
    "    lexi_30 = lexi_30[lexi_30['Send Strategy'] == 'P']\n",
    "    lexi_30 = lexi_30[lexi_30['Hitpath Offer ID'] == offer]\n",
    "    lexi_30 = lexi_30.groupby(['shortcode_DP.SV'])['Send Strategy'].count().reset_index()\n",
    "    lexi_30.rename(columns={'Send Strategy': 'Sent in Last 30 Days'}, inplace=True)\n",
    "    lexi_30['Can it Send in P Slot?'] = lexi_30['Sent in Last 30 Days'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    Account_CT_Checklist = pd.merge(Account_CT_Checklist, lexi_30[['shortcode_DP.SV', 'Can it Send in P Slot?']], on=['shortcode_DP.SV'], how='left')\n",
    "\n",
    "# If not, but is under max CT and has not send the offer more than once in last 30 days, send outside P slot\n",
    "## Needs to send outside normal P slots?\n",
    "\n",
    "    \n",
    "# If account has not sent the offer at all\n",
    "\n",
    "\n",
    "# Cleaning up NaNs\n",
    "    Account_CT_Checklist['CT Count'].fillna(0, inplace=True)\n",
    "    Account_CT_Checklist['P Available to Swap to CT'].fillna(0, inplace=True)\n",
    "    Account_CT_Checklist['Can it Send in P Slot?'].fillna(0, inplace=True)\n",
    "    Account_CT_Checklist['Max CT'] = Account_CT_Checklist['shortcode_DP.SV'].map(CT_settings_dict)\n",
    "    Account_CT_Checklist['CT available'] = Account_CT_Checklist['Max CT'] - Account_CT_Checklist['CT Count']\n",
    "     \n",
    "    '''\n",
    "    print(\"The start date:\", start_date.strftime(\"%Y-%m-%d\"))\n",
    "    print(\"The end date:\", end_date.strftime(\"%Y-%m-%d\"))\n",
    "    print(\"The start date of the current week is:\", start_of_week.strftime(\"%Y-%m-%d\"))\n",
    "    '''\n",
    "    \n",
    "    return Account_CT_Checklist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09a9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offer_vertical_gaps(df):\n",
    "    df = lexi.copy()\n",
    "    df.sort_values(by = ['shortcode_DP.SV','Hitpath Offer ID','Send Strategy','Date'], ascending = True, inplace = True)\n",
    "    df['Offer Gap'] = df.groupby(['shortcode_DP.SV','Send Strategy','Hitpath Offer ID'])['Date'].diff()\n",
    "    df['Offer Gap'] = df['Offer Gap'].dt.days\n",
    "    df.loc[df['Send Strategy'] != 'P', 'Offer Gap'] = np.nan\n",
    "    # filter for last 60 days\n",
    "    date_threshhold = max(df['Date']) - timedelta(60)\n",
    "    df = df[df['Date'] > date_threshhold]\n",
    "    \n",
    "    #df = df.rename(columns={\"Vertical\": \"Offer Vertical\"})\n",
    "    df_gap = df[(df['Offer Gap'] > 0) & (df['Offer Gap'] < 30)]\n",
    "    df_gap = df_gap.groupby(['Data Vertical','Offer Vertical'])['Offer Gap'].mean().reset_index()\n",
    "    return df_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd919bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_account_rankings(df, offer,cobra):\n",
    "    \n",
    "        # offer info\n",
    "    \n",
    "    #offer_vertical = offer_wk[offer_wk['Hitpath Offer ID'] == offer]['Vertical'].iloc[0]\n",
    "    \n",
    "    filtered_df = offer_wk[offer_wk['Hitpath Offer ID'] == offer]\n",
    "\n",
    "    # check if the filtered DataFrame is not empty\n",
    "    if not filtered_df.empty:\n",
    "        offer_vertical = filtered_df['Vertical'].iloc[0]\n",
    "    else:\n",
    "        offer_vertical = None\n",
    "    \n",
    "    print(offer, offer_vertical)\n",
    "        \n",
    "        # filter for last 60 days\n",
    "    date_threshhold = max(df['Date']) - timedelta(60)\n",
    "    df = df[df['Date'] > date_threshhold]\n",
    "    \n",
    "        # get account ranking for offer\n",
    "    df_offer = df[df['Hitpath Offer ID'] == offer]\n",
    "    df_offer = df_offer.groupby('SC_DP&Pub')[['Revenue', 'Delivered', 'Clicks', 'Jump Page Clicks', 'Opportunity Cost']].sum().reset_index()\n",
    "    df_offer['eCPM'] = 1000 * (df_offer['Revenue']/df_offer['Delivered'])\n",
    "    df_offer['OCRR'] = (df_offer['Opportunity Cost']/df_offer['Revenue'])\n",
    "    df_offer['Jump Page CTR'] = df_offer['Jump Page Clicks']/df_offer['Delivered']\n",
    "        # Create rank columns for each column\n",
    "    rank_columns = df_offer[['Revenue', 'Delivered','Jump Page CTR','OCRR']].apply(lambda x: x.rank(ascending=False))\n",
    "        # Add rank columns to the original DataFrame\n",
    "    df_offer = pd.concat([df_offer, rank_columns.add_suffix('_rank')], axis=1)\n",
    "    df_offer['Average Rank'] = df_offer.iloc[:,8:].mean(axis=1)\n",
    "    df_offer = df_offer.sort_values(by = 'Average Rank', ascending = True)\n",
    "    df_offer['Overall Rank'] = df_offer['Average Rank'].rank()\n",
    "    \n",
    "        # offer vertical ranking\n",
    "    df_vertical = df[df['Offer Vertical'] == offer_vertical]\n",
    "    df_vertical = df_vertical.groupby('SC_DP&Pub')[['Revenue', 'Delivered', 'Clicks','Jump Page Clicks', 'Opportunity Cost']].sum().reset_index()\n",
    "    df_vertical['eCPM (OV)'] = 1000 * (df_vertical['Revenue']/df_vertical['Delivered'])\n",
    "    df_vertical['OCRR (OV)'] = (df_vertical['Opportunity Cost']/df_vertical['Revenue'])\n",
    "    df_vertical['Jump Page CTR (OV)'] = df_vertical['Jump Page Clicks']/df_vertical['Delivered']\n",
    "        # Create rank columns for each column\n",
    "    rank_columns = df_vertical[['Revenue', 'Delivered','Jump Page CTR (OV)','OCRR (OV)']].apply(lambda x: x.rank(ascending=False))\n",
    "        # Add rank columns to the original DataFrame\n",
    "    df_vertical = pd.concat([df_vertical, rank_columns.add_suffix('_rank (OV)')], axis=1)\n",
    "    df_vertical['Average Rank (OV)'] = df_offer.iloc[:,8:].mean(axis=1)\n",
    "    df_vertical = df_vertical.sort_values(by = 'Average Rank (OV)', ascending = True)\n",
    "    df_vertical['Overall Rank'] = df_vertical['Average Rank (OV)'].rank()\n",
    "    df_vertical['Overall Rank'] = df_vertical['Overall Rank'].apply(lambda x: x + 5 if not pd.isnull(x) else x)\n",
    "    df_vertical = df_vertical[['SC_DP&Pub','Overall Rank']]\n",
    "    df_vertical['Rank Origin'] = 'Offer Vertical'\n",
    "    \n",
    "        # Create column that checks eligibility\n",
    "    #static_eligbility = check_ESP_eligibility(df=EMIT)\n",
    "    #df_offer['CT Eligibility'] = df_offer['shortcode_DP.SV'].isin(static_eligbility).astype(int)\n",
    "    #df_offer_eligble = df_offer[df_offer['CT Eligibility'] == 1]\n",
    "    df_offer_eligble = df_offer.copy()\n",
    "    \n",
    "        # calculate Tiers\n",
    "        # Replace -inf with NaN\n",
    "    df_offer_eligble['OCRR'] = df_offer_eligble['OCRR'].replace(float('-inf'), np.nan)\n",
    "        # Calculate the z-scores\n",
    "    df_offer_eligble['OCRR Z-Scores'] = zscore(df_offer_eligble['OCRR'], nan_policy='omit')\n",
    "    \n",
    "    Tier_1 = .5\n",
    "    Tier_2 = .25\n",
    "    Tier_3 = 0\n",
    "    Tier_4 = -.25\n",
    "    \n",
    "    conditions = [\n",
    "        (df_offer_eligble['OCRR Z-Scores'] >= Tier_1),\n",
    "        (df_offer_eligble['OCRR Z-Scores'] < Tier_1) &  (df_offer_eligble['OCRR Z-Scores'] >= Tier_2),\n",
    "        (df_offer_eligble['OCRR Z-Scores'] < Tier_2) &  (df_offer_eligble['OCRR Z-Scores'] >= Tier_3),\n",
    "        (df_offer_eligble['OCRR Z-Scores'] < Tier_3) &  (df_offer_eligble['OCRR Z-Scores'] >= Tier_4),\n",
    "        (df_offer_eligble['OCRR Z-Scores'] < Tier_4)\n",
    "    ]\n",
    "    \n",
    "    message = ['Tier 1', 'Tier 2', 'Tier 3',\n",
    "               'Tier 4','Tier 5']\n",
    "    \n",
    "    df_offer_eligble['Account Tier'] = np.select(conditions, message)\n",
    "    df_tier_summary = pd.DataFrame(df_offer_eligble['Account Tier'].value_counts())\n",
    "    df_tier_summary['Tier'] = df_tier_summary.index\n",
    "    df_tier_summary = df_tier_summary.reset_index()\n",
    "    df_tier_summary.rename(columns={'Account Tier': 'Accounts per Tier'}, inplace=True)\n",
    "    df_tier_summary = df_tier_summary[['Tier', 'Accounts per Tier']].reset_index(drop = True)\n",
    "    df_tier_summary = df_tier_summary.sort_values(by = 'Tier', ascending = True)\n",
    "    df_tier_summary = tabulate(df_tier_summary, headers='keys', tablefmt='grid')\n",
    "    \n",
    "    #print(\"For Hitpath Offer ID\", offer, \"the account Tier distribution is: \\n\", df_tier_summary )\n",
    "    \n",
    "    accounts_ranked = df_offer_eligble[['SC_DP&Pub','Overall Rank']].sort_values(by = ['Overall Rank'], ascending = True)\n",
    "    accounts_ranked['Rank Origin'] = 'Account'\n",
    "    \n",
    "    accounts_ranked = pd.concat([accounts_ranked, df_vertical], ignore_index=True)\n",
    "    accounts_ranked = accounts_ranked[~((accounts_ranked['Rank Origin'] == 'Offer Vertical') & accounts_ranked.duplicated('SC_DP&Pub'))]\n",
    "    accounts_ranked['PubID'] = accounts_ranked['SC_DP&Pub'].str[-6:]\n",
    "    accounts_ranked['shortcode_DP.SV'] = accounts_ranked['SC_DP&Pub'].str[:-7]\n",
    "    \n",
    "    # filter out accounts that are paused to the offer\n",
    "    paused_pubs = offer_wk[offer_wk['Hitpath Offer ID'] == offer]['Paused Pubs'].str.split('\\n|\\t|,|\"| ')\n",
    "    accounts_ranked = accounts_ranked[~accounts_ranked['PubID'].isin(paused_pubs)]\n",
    "\n",
    "    # give account has a CT slot available some extra credit \n",
    "    # earliest possible date\n",
    "    default_earliest_date = dt.date.today() + timedelta(2)\n",
    "    cobra_P = cobra[cobra['Send Strategy'] == 'P']\n",
    "    cobra_P = cobra_P[cobra_P['Hitpath Offer ID'] == offer]\n",
    "    cobra_weekly_P_pubid = cobra_P[cobra_P['Date'].dt.date >= default_earliest_date]['shortcode_DP.SV'].unique().tolist()\n",
    "    accounts_ranked['CT Slot Available'] = accounts_ranked['shortcode_DP.SV'].isin(cobra_weekly_P_pubid).astype(int)\n",
    "    accounts_ranked = accounts_ranked.loc[accounts_ranked['CT Slot Available']>0, ]\n",
    "    accounts_ranked = accounts_ranked.sort_values(by = ['Overall Rank'], ascending = True)\n",
    "    return accounts_ranked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15daeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_date(date, offer):\n",
    "    \n",
    "    days_restrictions = offer_wk[offer_wk['Hitpath Offer ID'] == offer]['Day Restrictions'].iloc[0]\n",
    "    days_allowed = str(days_restrictions)\n",
    "    \n",
    "    # Parse the input date\n",
    "    #input_date = pd.Timestamp(date)\n",
    "    input_date = date\n",
    "    \n",
    "    # If days_allowed is None or 'None', return the input date as it is\n",
    "    if days_allowed is None or days_allowed.lower() == 'none' or days_allowed.lower() == 'nan':\n",
    "        return pd.Timestamp(input_date)\n",
    "\n",
    "    # Create a dictionary to map weekdays to numbers (Monday = 0, Tuesday = 1, etc.)\n",
    "    weekdays = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "\n",
    "    # Check if the days_allowed contains a single value or a range\n",
    "    if ' - ' in days_allowed:\n",
    "        lower_bound, upper_bound = days_allowed.split(' - ')\n",
    "    else:\n",
    "        lower_bound = upper_bound = days_allowed\n",
    "\n",
    "    # Calculate the target weekday numbers for the lower and upper bounds\n",
    "    target_lower = weekdays[lower_bound]\n",
    "    target_upper = weekdays[upper_bound]\n",
    "\n",
    "    # Calculate the current weekday number of the input date\n",
    "    current_weekday = input_date.weekday()\n",
    "\n",
    "    # Calculate the difference between the current weekday and the target lower bound\n",
    "    weekday_difference = (target_lower - current_weekday) % 7\n",
    "\n",
    "    # Adjust the input date by adding the weekday difference\n",
    "    adjusted_date = input_date + timedelta(days=weekday_difference)\n",
    "\n",
    "    # If the adjusted date is still outside the days allowed, add 1 day until it falls within the allowed range\n",
    "    while adjusted_date.weekday() < target_lower or adjusted_date.weekday() > target_upper:\n",
    "        adjusted_date += timedelta(days=1)\n",
    "\n",
    "    # Return the adjusted date as a string in the format 'MM/DD/YYYY'\n",
    "    return pd.Timestamp(adjusted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1458bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drop_date(offer_gaps_df,CT_eligibility_df,account, offer, cobra, end_date):\n",
    "    print(\"#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\")\n",
    "    print(\"Searching for available date for\", account)\n",
    "    \n",
    "    cobra = cobra[cobra['Send Strategy'] == 'P']\n",
    "    \n",
    "    all_drop_dates = cobra[['shortcode_DP.SV','Hitpath Offer ID', 'Date']]\n",
    "    all_drop_dates = all_drop_dates[all_drop_dates['Hitpath Offer ID'] == offer]\n",
    "    all_drop_dates = all_drop_dates[all_drop_dates['shortcode_DP.SV'] == account]\n",
    "    all_drop_dates['Date'] = pd.to_datetime(all_drop_dates['Date'])\n",
    "    \n",
    "    last_drop_dates = cobra.groupby(['shortcode_DP.SV','Hitpath Offer ID'])['Date'].max().reset_index()\n",
    "    last_drop_dates = last_drop_dates[last_drop_dates['Hitpath Offer ID'] == offer]\n",
    "    last_drop_dates = last_drop_dates[last_drop_dates['shortcode_DP.SV'] == account]\n",
    "    \n",
    "    account_dv = lexi[lexi['shortcode_DP.SV'] == account]['Data Vertical'].iloc[0]\n",
    "    offer_vertical = offer_wk[offer_wk['Hitpath Offer ID'] == offer]['Vertical'].iloc[0]\n",
    "    offer_gap = offer_gaps_df[offer_gaps_df['Data Vertical'] == account_dv]\n",
    "    offer_gap_df = offer_gap[offer_gap['Offer Vertical'] == offer_vertical]\n",
    "    \n",
    "    if len(offer_gap_df) == 0:\n",
    "        offer_gap = 10\n",
    "    elif len(offer_gap_df) != 0:\n",
    "        offer_gap = offer_gap_df['Offer Gap'].iloc[0].round(0)\n",
    "    else:\n",
    "        offer_gap = 10\n",
    "\n",
    "    # earliest possible date\n",
    "    default_earliest_date = dt.date.today() + timedelta(2)\n",
    "    \n",
    "    # next upcoming drop based on offer gap\n",
    "    if len(last_drop_dates) == 0:\n",
    "        next_drop_date = default_earliest_date\n",
    "    if len(last_drop_dates) != 0:\n",
    "        next_drop_date = last_drop_dates['Date'].iloc[0] +  timedelta(offer_gap)\n",
    "    \n",
    "    # first week it's avaible to drop\n",
    "    # check the eligibility of accounts\n",
    "    CT_eligibility_Pub = CT_eligibility_df[CT_eligibility_df['shortcode_DP.SV'] == account]\n",
    "    CT_eligibility_Pub = CT_eligibility_Pub[CT_eligibility_Pub['CT available'] > 0 ]\n",
    "    the_date = next_drop_date\n",
    "    result = 0 \n",
    "    CT_eligibility_Pub = CT_eligibility_Pub[CT_eligibility_Pub['P Available to Swap to CT'] >= 1 ]\n",
    "    if len(CT_eligibility_Pub) > 0:\n",
    "        \n",
    "        earliest_week = CT_eligibility_Pub['Date'].iloc[0]\n",
    "        earliest_week = max(pd.to_datetime(default_earliest_date), \n",
    "                   pd.to_datetime(earliest_week)\n",
    "                  )\n",
    "        input_date = pd.to_datetime(earliest_week)\n",
    "        if len(all_drop_dates[all_drop_dates['Date'] > input_date]['Date']) > 0:\n",
    "            print(\"     There is an existing P drop, will swap.\")\n",
    "            next_drop_date = pd.to_datetime(all_drop_dates[all_drop_dates['Date'] > input_date]['Date'].min())\n",
    "            print(\"     Swapping drop on\", next_drop_date)\n",
    "            the_date = next_drop_date\n",
    "            result = 1\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    if (CT_eligibility_Pub['P Available to Swap to CT'].iloc[0] != 1):\n",
    "        print(\"     No existing P drop, we will add in a drop.\")\n",
    "        earliest_week = CT_eligibility_Pub['Date'].iloc[0]\n",
    "        print(\"     The earliest available week to test with proper gapping is\", next_drop_date)\n",
    "\n",
    "    the_date = max(pd.to_datetime(default_earliest_date), \n",
    "                   pd.to_datetime(next_drop_date), \n",
    "                   pd.to_datetime(earliest_week)\n",
    "                  )\n",
    "    \n",
    "    # check to make sure it's on a weekday and not on a restricted day\n",
    "    the_date = adjust_date(the_date, offer)\n",
    "\n",
    "    print(\"     Earliest available drop is\", the_date)\n",
    "    \n",
    "    if the_date.date() >= dt.date.today()+ timedelta(end_date):\n",
    "        print(\"     This account is NOT eligible to CT this offer.\")\n",
    "        print(\" \")\n",
    "        result = 0\n",
    "    elif the_date.date() < dt.date.today() + timedelta(end_date):\n",
    "        print(\"     This account is eligible to CT this offer.\")\n",
    "        print(\" \")\n",
    "        result = 1  \n",
    "    \"\"\"     \n",
    "    return the_date, result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f812d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_P_drops(df):\n",
    "\n",
    "    # Get the current date\n",
    "    current_date = datetime.today()\n",
    "\n",
    "    # Calculate the date 1 week prior\n",
    "    one_week_prior = current_date - timedelta(days=7)\n",
    "\n",
    "    # Filter the dataframe to include only rows within the date range and where the 'Send Strategy' column contains 'P'\n",
    "    filtered_df = df[(df['Date'] >= one_week_prior) & (df['Date'] <= current_date) & (df['Send Strategy'] == 'P')]\n",
    "\n",
    "    # Group the filtered dataframe by 'Date' and count the occurrences of 'P' per day\n",
    "    p_counts = filtered_df.groupby(['shortcode_DP.SV','Date'])['Send Strategy'].count().reset_index()\n",
    "    average_frequency = p_counts.groupby(['shortcode_DP.SV'])['Send Strategy'].mean().reset_index()\n",
    "\n",
    "    # Calculate the average frequency of 'P' per day\n",
    "    average_frequency['Send Strategy'] = np.floor(average_frequency['Send Strategy'])\n",
    "    \n",
    "    Account_P_Max = dict(zip(average_frequency['shortcode_DP.SV'], average_frequency['Send Strategy']))\n",
    "\n",
    "    return Account_P_Max\n",
    "def choose_drop_slot(cobra, account, date, offer, P_drop_dict, eligibility_df):\n",
    "\n",
    "    # get schedule that day in that account\n",
    "    cobra_pub = cobra[cobra['shortcode_DP.SV'] == account]\n",
    "    cobra_pub = cobra_pub[cobra_pub['Date'] == date]\n",
    "    \n",
    "    # if drop exists on that day, overwrite\n",
    "    cobra_pub_offer = cobra_pub[cobra_pub['Hitpath Offer ID'] == offer]\n",
    "    if len(cobra_pub_offer) > 0:\n",
    "        cobra_pub_2 = cobra_pub[((cobra_pub['Hitpath Offer ID']=='nan')| (cobra_pub['Hitpath Offer ID'] == '') |  (cobra_pub['Hitpath Offer ID'].isna())) & (cobra_pub['Drop'] == 2)]\n",
    "        if len(cobra_pub_2) > 0:\n",
    "            return 2\n",
    "    else:   \n",
    "        print(\"The day can't be added JT, there's test drop already\")\n",
    "def swap_existing_slot(cobra, account, date, offer): \n",
    "    # if drop_number == None:\n",
    "    cobra_slot = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Date'] == date) & (cobra['Drop'] == 2)]\n",
    "    # get existing drop send strategy \n",
    "    send_strategy = cobra_slot['Send Strategy'].values[0]\n",
    "    if send_strategy != 'JT':\n",
    "        new_cobra_slot_date = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Drop'] == 2)& (cobra['Date'] >= date) & ((cobra['Hitpath Offer ID']=='nan')| (cobra['Hitpath Offer ID'] == '') |  (cobra['Hitpath Offer ID'].isna()))]['Date'].min()\n",
    "        new_cobra_slot = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Date'] == new_cobra_slot_date) & (cobra['Drop'] == 1)]\n",
    "        time = new_cobra_slot['Time'].values[0]\n",
    "        if time == '':\n",
    "            time = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Time']!='') & (cobra['Drop'] == 1)].sort_values(by = 'Date', ascending = False)['Time'].values[0]\n",
    "        # Segment - unified \n",
    "        segment = new_cobra_slot['Segment '].values[0]\n",
    "        if segment == '':\n",
    "            segment = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Segment ']!='') & (cobra['Drop'] == 1)].sort_values(by = 'Date', ascending = False)['Segment '].values[0]\n",
    "        \n",
    "        campaign = cobra_slot['Offer'].values[0]\n",
    "        # Job Name - unified \n",
    "        date1 = date.strftime(\"%d%b%y\")  \n",
    "        job_name = \"SS_\"+segment[:3] + \"_\"+segment[4:].replace(\".\",'-').replace(\"_\",'-')+\"_\"+ offer +\"_\"+ send_strategy + \"_\" +   date1\n",
    "        # Offset - seperate, keep first one from original \n",
    "        # Creative - seperate, keep first one from original\n",
    "        limit = cobra_slot['Limit'].values[0]\n",
    "        offset  =  cobra_slot['Offset'].values[0]\n",
    "        # Creative \n",
    "        creative = cobra_slot['Creative'].values[0]\n",
    "\n",
    "    return time, segment, send_strategy, campaign, limit,offset, creative,job_name,new_cobra_slot_date\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890db6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cobra_slot(cobra, account, date, offer, Drop_Number, CCIDs):\n",
    "    global limit_size\n",
    "    result = 1\n",
    "    cobra_slot = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Date'] == date) & (cobra['Drop'] == 1)]\n",
    "    sc = account.split('_')[0]\n",
    "    # Time - check orginal, if not, then use default\n",
    "    time = cobra_slot['Time'].values[0]\n",
    "    if time == '':\n",
    "        time = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Time']!='') & (cobra['Drop'] == 1)].sort_values(by = 'Date', ascending = False)['Time'].values[0]\n",
    "    # Segment - unified \n",
    "    segment = cobra_slot['Segment '].values[0]\n",
    "    if segment == '':\n",
    "        segment = cobra[(cobra['shortcode_DP.SV'] == account) & (cobra['Segment ']!='') & (cobra['Drop'] == 1)].sort_values(by = 'Date', ascending = False)['Segment '].values[0]\n",
    "    # Offer - unified\n",
    "    ss_offer = infrastructure.get_ss_offer()\n",
    "    try: \n",
    "        campaign = ss_offer.loc[(ss_offer['SS Offers (updated)'].str.contains(CCIDs, na = False)) & (ss_offer['SS Offers (updated)'].str[-4:].str.contains(sc, na = False)), 'SS Offers (updated)' ].values[0]\n",
    "    except: \n",
    "        print(\"The offer is not added in the SS.\")\n",
    "    # Job Name - unified \n",
    "    date1 = date.strftime(\"%d%b%y\")  \n",
    "    job_name = \"SS_\"+segment[:3] + \"_\"+segment[4:].replace(\".\",'-').replace(\"_\",'-')+\"_\"+ offer +\"_\"+ \"JT\" + \"_\" +   date1\n",
    "    # Offset - seperate, keep first one from original \n",
    "    # Creative - seperate, keep first one from original\n",
    "    if Drop_Number == 1:\n",
    "        limit = cobra_slot['Limit'].values[0]\n",
    "        offset  =  cobra_slot['Offset'].values[0]\n",
    "    else: \n",
    "        get_limit_size = limit_size(offer_id_test = offer ,df = lexi,account = account)\n",
    "        result = get_limit_size[1] \n",
    "        limit = get_limit_size[0]\n",
    "        offset = 0 \n",
    "    # Creative \n",
    "    creative = cobra_slot['Creative'].values[0]\n",
    "    \n",
    "    return time, segment, campaign, limit,offset, creative,job_name,result \n",
    "        \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27a476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define limit and offset size if we want to add a new CT drop \n",
    "def limit_size(offer_id_test,df,account):\n",
    "    #input\n",
    "    #df = lexi\n",
    "    #offer_id_test = '12342'\n",
    "    test_offer_info = offer_wk.loc[offer_wk['Hitpath Offer ID'] == offer_id_test]\n",
    "    try:\n",
    "        payout = float(test_offer_info['$ Payout'].replace(r'[^0-9\\.]','',regex=True))\n",
    "    except:\n",
    "        payout = 1\n",
    "    vertical = offer_wk.loc[offer_wk['Hitpath Offer ID'] == offer_id_test, 'Vertical'].iloc[0]\n",
    "    if(payout  > 50.00):\n",
    "        payout = payout/2\n",
    "    # payout = 8.00\n",
    "    \n",
    "    expected_revenue = payout*1.6+20\n",
    "    #last 60 days of data\n",
    "    last60days= pd.Timestamp(dt.date.today()-dt.timedelta(days=60)).strftime('%Y-%m-%d')\n",
    "    df = df[df['Date']>=last60days]\n",
    "    df_3d = df[(df['Date']>=pd.Timestamp(df['Date'].max()-timedelta(3))) & (df['Send Strategy']=='P')]\n",
    "    df['Hitpath Offer ID'] = df['Hitpath Offer ID'].astype(str)\n",
    "    df['Hitpath Offer ID'] = df['Hitpath Offer ID'].replace(r'\\.0$', '', regex=True)\n",
    "    df = df[df['Send Strategy'] != 'AR']\n",
    "    #Average delivered volume by shortcode_DP.SV\n",
    "    avg_3_day_delivered = df_3d.groupby(['Date','shortcode_DP.SV'])['Delivered'].sum().reset_index()\n",
    "    avg_3_day_delivered = avg_3_day_delivered.groupby('shortcode_DP.SV')['Delivered'].mean().reset_index()\n",
    "    #eCPM by shortcode_DP.SV\n",
    "    eCPM_df = df.groupby('shortcode_DP.SV').agg({'Revenue':'sum','Delivered':'sum'})\n",
    "    eCPM_df['eCPM'] = eCPM_df['Revenue'] * 1000 / eCPM_df['Delivered']\n",
    "    #merge eCPM and median deliverd\n",
    "    merged_segment_size = avg_3_day_delivered.merge(eCPM_df,how = 'right', on = 'shortcode_DP.SV')\n",
    "    merged_segment_size = merged_segment_size.rename(columns=\n",
    "                                                    {\"Delivered_x\": \"Average Delivered\", \n",
    "                                                    \"Delivered_y\": \"Total Delivered\"})\n",
    "    merged_segment_size['segment_size'] = expected_revenue * 1000 / merged_segment_size['eCPM']\n",
    "    merged_segment_size['segment_size'] -= merged_segment_size['segment_size'] % -100\n",
    "    merged_segment_size['% Testing Size'] = merged_segment_size['segment_size']/ merged_segment_size['Average Delivered']\n",
    "    merged_segment_size['% Testing Size'] = merged_segment_size['% Testing Size'].fillna(0)\n",
    "    merged_segment_size['Good for Testing'] = False\n",
    "    merged_segment_size.loc[(merged_segment_size['% Testing Size'] <= 0.5), 'Good for Testing'] = True\n",
    "    proper_segment = merged_segment_size.copy()\n",
    "    proper_segment.loc[proper_segment['Good for Testing'] == False,'segment_size'] = 1500\n",
    "    proper_segment['% Testing Size'] = proper_segment['segment_size']/ proper_segment['Average Delivered']\n",
    "    proper_segment.loc[(proper_segment['% Testing Size'] <= 0.6), 'Good for Testing'] = True\n",
    "    \n",
    "    proper_segment.loc[(proper_segment['Good for Testing'] == False) & (proper_segment['Average Delivered']>1000), 'segment_size'] = proper_segment['Average Delivered']/2\n",
    "    proper_segment.loc[(proper_segment['Good for Testing'] == False) & (proper_segment['Average Delivered']>1000), 'Good for Testing'] = True\n",
    "    proper_segment['segment_size'] = proper_segment['segment_size'].astype(int)\n",
    "    proper_segment = proper_segment.loc[proper_segment['Good for Testing'] == True ]\n",
    "    try:\n",
    "        limit = proper_segment.loc[(proper_segment['shortcode_DP.SV'] == account), 'segment_size'].values[0] \n",
    "    except:\n",
    "        raise Exception('Limit does not work')\n",
    "    if limit is None :\n",
    "        print(\"     This account is NOT eligible to JT this offer because of segment size.\")\n",
    "        print(\" \")\n",
    "        result = 0\n",
    "    else:\n",
    "        result = 1       \n",
    "    return limit, result \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ad0c8",
   "metadata": {},
   "source": [
    "## Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd198c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mamba are loaded.\n",
      "Starting process to create Jump Page testing schedule.\n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 13194\n",
      "------------------------------------------------------------------------\n",
      "13194 Loan\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for HZB_AL.PL\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-24 00:00:00\n",
      "** We have found 1 JTs ending search for 13194 **\n",
      " \n",
      " \n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 12089\n",
      "------------------------------------------------------------------------\n",
      "12089 Education\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for SVT_AL.PL\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-25 00:00:00\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for DSS_IM.SVY\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-26 00:00:00\n",
      "** We have found 2 JTs ending search for 12089 **\n",
      " \n",
      " \n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 12978\n",
      "------------------------------------------------------------------------\n",
      "12978 Loan\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for FLC_WWM.YFA.2\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON FLC_WWM.YFA.2 *\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for HZB_DOT.PL\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-25 00:00:00\n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 12088\n",
      "------------------------------------------------------------------------\n",
      "12088 Education\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for SVT_AL.PL.2\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-25 00:00:00\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for SVT_DOT.PL\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON SVT_DOT.PL *\n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 12088\n",
      "------------------------------------------------------------------------\n",
      "12088 Education\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for SVT_AL.PL.2\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-25 00:00:00\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for SVT_DOT.PL\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON SVT_DOT.PL *\n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 12342\n",
      "------------------------------------------------------------------------\n",
      "12342 Loan\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for DSS_TLG.PL\n",
      "     There is an existing P drop, will swap.\n",
      "     Swapping drop on 2024-06-29 00:00:00\n",
      "** We have found 1 JTs ending search for 12342 **\n",
      " \n",
      " \n",
      "------------------------------------------------------------------------\n",
      "Generating Schedule for CCIDs using Hitpath Offer ID: 12945\n",
      "------------------------------------------------------------------------\n",
      "12945 Resources\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for MBC_WWM.YFA.2\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON MBC_WWM.YFA.2 *\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for DSS_JET.ZTA\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON DSS_JET.ZTA *\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for FLC_WWM.YFA.2\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON FLC_WWM.YFA.2 *\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#\n",
      "Searching for available date for DSS_IM.SVY\n",
      "The day can't be added JT, there's test drop already\n",
      "list index out of range\n",
      "* FAILED ON DSS_IM.SVY *\n",
      "\u001b[1mJump Page Test SCHEDULE GENERATION IS DONE, PLEASE CHECK OUTPUT BEFORE RUNNING SCHEDULE CODE.\n"
     ]
    }
   ],
   "source": [
    "reading_cobra()\n",
    "cobra['Drop'] = cobra['Drop'].str.replace('Drop ', '').astype(int)\n",
    "Account_P_Max = get_max_P_drops(df = cobra)\n",
    "content_feedback_report = pd.read_csv('offer_performance_awaiting_test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#- Functions -#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
    "\n",
    "print(\"Starting process to create Jump Page testing schedule.\")\n",
    "\n",
    "# create empty df to store schedule\n",
    "\n",
    "columns = [\n",
    "    'Date',\n",
    "    'Affiliate ID_DP.DS',\n",
    "    'Drop Number',\n",
    "    'Time',\n",
    "    'Segment',\n",
    "    'Send Strategy',\n",
    "    'Offer',\n",
    "    'Limit',\n",
    "    'Offset',\n",
    "    'Creative',\n",
    "    'Job Name',\n",
    "    'Can it Test?'\n",
    "]\n",
    "\n",
    "# Create an empty DataFrame\n",
    "upcoming_CT_schedule = pd.DataFrame()\n",
    "content_feedback_report['Hitpath Offer ID'] = content_feedback_report['Hitpath Offer ID'].astype('str').str.split('.',expand = True)[0]\n",
    "content_feedback_report = content_feedback_report[content_feedback_report['Hitpath Offer ID']!='nan']\n",
    "for index, row in content_feedback_report.iterrows():\n",
    "#for hitpath_offer_ID in content_feedback_report['Hitpath Offer ID']:\n",
    "\n",
    "    # drop, CCID, hitpath info\n",
    "    hitpath_offer_ID = row['Hitpath Offer ID']\n",
    "    CCIDs_to_Test = row[\"Jump Page Offer\"]\n",
    "    test_count = row[\"Test count\"]\n",
    "    #days_restrictions = offer_wk[offer_wk['Hitpath Offer ID'] == hitpath_offer_ID]['Day Restrictions'].iloc[0]\n",
    "    \n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Generating Schedule for CCIDs using Hitpath Offer ID:\", hitpath_offer_ID)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    \n",
    "    #offer_vertical = offer_wk[offer_wk['Hitpath Offer ID'] == hitpath_offer_ID]['Vertical'].iloc[0]\n",
    "    \n",
    "    filtered_df = offer_wk[offer_wk['Hitpath Offer ID'] == hitpath_offer_ID]\n",
    "\n",
    "    # check if the filtered DataFrame is not empty\n",
    "    if not filtered_df.empty:\n",
    "        offer_vertical = filtered_df['Vertical'].iloc[0]\n",
    "    else:\n",
    "        offer_vertical = None\n",
    "    \n",
    "\n",
    "    offer_gaps_df = get_offer_vertical_gaps(df = lexi)\n",
    "    account_rankings_df = get_account_rankings(df = lexi, offer = hitpath_offer_ID,cobra = cobra)\n",
    "    DPPub_test = list(account_rankings_df['shortcode_DP.SV'])\n",
    "        \n",
    "        \n",
    "    success_counter = 0\n",
    "    for DPPub in DPPub_test:\n",
    "\n",
    "        try:\n",
    "            CT_eligibility_df = check_CT_eligiblity(\n",
    "                                                    default_max_drops = 3,\n",
    "                                                    lexi = lexi,\n",
    "                                                    cobra = cobra,\n",
    "                                                    offer = hitpath_offer_ID)\n",
    "            drop_date_info = get_drop_date(offer_gaps_df = offer_gaps_df,\n",
    "                                            CT_eligibility_df = CT_eligibility_df,\n",
    "                                                account = DPPub, \n",
    "                                            offer = hitpath_offer_ID, \n",
    "                                            cobra = cobra, \n",
    "                                            end_date = 14)\n",
    "            drop_date = drop_date_info[0]\n",
    "                \n",
    "                # drop info to put into auto scheduler\n",
    "            Date_output = drop_date\n",
    "            DPPub_output = DPPub\n",
    "                \n",
    "            Drop_Number_output = choose_drop_slot(cobra = cobra,\n",
    "                                                    account = DPPub,\n",
    "                                                    date = pd.Timestamp(Date_output),\n",
    "                                                    offer = hitpath_offer_ID,\n",
    "                                                    P_drop_dict = Account_P_Max,\n",
    "                                                    eligibility_df = CT_eligibility_df)\n",
    "            \n",
    "            if Drop_Number_output !=2:\n",
    "                cobra_existing_drop = swap_existing_slot(\n",
    "                                                    cobra = cobra,\n",
    "                                                    account = DPPub,\n",
    "                                                    date = pd.Timestamp(Date_output),\n",
    "                                                    offer = hitpath_offer_ID)\n",
    "                Time_output_existing = cobra_existing_drop[0]\n",
    "                Segment_existing = cobra_existing_drop[1]\n",
    "                Send_Strategy_output_existing = cobra_existing_drop[2]\n",
    "                Offer_output_existing = cobra_existing_drop[3]\n",
    "                Hitpath_OfferID_output_existing = Offer_output_existing.split()[0]\n",
    "                Limit_output_existing = cobra_existing_drop[4]\n",
    "                Offset_output_existing = cobra_existing_drop[5]\n",
    "                Creative_output_existing = cobra_existing_drop[6]\n",
    "                Job_Name_output_existing = cobra_existing_drop[7]\n",
    "                Eligibility_output_existing = 1 \n",
    "                new_cobra_slot_date = pd.to_datetime(cobra_existing_drop[8])\n",
    "                drop_row_existing = [[new_cobra_slot_date, DPPub_output, 2, Time_output_existing, Segment_existing, Send_Strategy_output_existing,\n",
    "                            Offer_output_existing, Limit_output_existing, Offset_output_existing, Creative_output_existing, Job_Name_output_existing, Eligibility_output_existing]]\n",
    "\n",
    "        \n",
    "\n",
    "            cobra_output = get_cobra_slot(cobra = cobra,\n",
    "                                        account = DPPub,\n",
    "                                        date = pd.Timestamp(Date_output),\n",
    "                                        offer = hitpath_offer_ID,\n",
    "                                        Drop_Number = Drop_Number_output,\n",
    "                                        CCIDs = CCIDs_to_Test)  \n",
    "\n",
    "            #Drop_Number_output = 1\n",
    "            Time_output = cobra_output[0]\n",
    "            Segment = cobra_output[1]\n",
    "            Send_Strategy_output = 'JT'\n",
    "            Hitpath_OfferID_output = hitpath_offer_ID\n",
    "            #Scheduling_Name_output = offer_wk[offer_wk['Hitpath Offer ID'] == hitpath_offer_ID]['Scheduling Name'].iloc[0] # NEED TO CHANGE TO SMS \n",
    "            Offer_output = cobra_output[2]\n",
    "            Limit_output = cobra_output[3]\n",
    "            Offset_output = cobra_output[4]\n",
    "            Creative_output = cobra_output[5]\n",
    "            Job_Name_output = cobra_output[6] \n",
    "            if cobra_output[7] == 0:\n",
    "                drop_date_info[1] = 0 \n",
    "            Eligibility_output = + drop_date_info[1]\n",
    "                \n",
    "            # existing row in Cobra \n",
    "            \n",
    "            # Update Cobra \n",
    "            ## so it does not repeat the same accounts if it's scheduling multiple batches of the same offer\n",
    "            cobra_row = pd.DataFrame({'Date':[Date_output],\n",
    "                                        'shortcode_DP.SV': [DPPub_output],\n",
    "                                        'Hitpath Offer ID': [hitpath_offer_ID],\n",
    "                                        'Campaign ID':[Offer_output],\n",
    "                                        'Send Strategy': [Send_Strategy_output],\n",
    "                                        'Drop': [Drop_Number_output]\n",
    "                                        })\n",
    "            \n",
    "                \n",
    "            cobra.loc[((cobra['shortcode_DP.SV']==DPPub_output) & (cobra['Date']==Date_output) & (cobra['Drop'] ==Drop_Number_output )), 'Hitpath Offer ID'] = hitpath_offer_ID\n",
    "            if Drop_Number_output !=2:\n",
    "                upcoming_CT_schedule = upcoming_CT_schedule._append(drop_row_existing, ignore_index=True)\n",
    "                Drop_Number_output = 2\n",
    "            drop_row = [[Date_output, DPPub_output, Drop_Number_output, Time_output, Segment, Send_Strategy_output,\n",
    "                            Offer_output, Limit_output, Offset_output, Creative_output, Job_Name_output, Eligibility_output]]\n",
    "            \n",
    "\n",
    "            upcoming_CT_schedule = upcoming_CT_schedule._append(drop_row, ignore_index=True)\n",
    "            # if delete the drop if date, Affiliate ID_DP.DS and Drop Number is the same, we don't want to add that drop  \n",
    "\n",
    "\n",
    "            \n",
    "            success_counter = success_counter + drop_date_info[1]\n",
    "            if success_counter == test_count:\n",
    "                print(\"** We have found\", success_counter, \"JTs\", \"ending search for\", hitpath_offer_ID, \"**\")\n",
    "                print(\" \")\n",
    "                print(\" \")\n",
    "                break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"* FAILED ON\", DPPub, \"*\")\n",
    "            \n",
    " \n",
    "    # Rename the columns\n",
    "    #upcoming_CT_schedule.columns = columns \n",
    "upcoming_CT_schedule = upcoming_CT_schedule.rename(columns=dict(zip(upcoming_CT_schedule.columns, columns)))\n",
    "upcoming_CT_schedule = upcoming_CT_schedule[upcoming_CT_schedule['Can it Test?'] == 1]      \n",
    "upcoming_CT_schedule = upcoming_CT_schedule.drop('Can it Test?', axis=1)\n",
    "upcoming_CT_schedule = upcoming_CT_schedule.drop_duplicates(subset=['Date','Affiliate ID_DP.DS','Drop Number'], keep='first')\n",
    "\n",
    "\n",
    "\n",
    "    #CT_pipeline_output = prep_for_CT_pipeline_smartsheet(df = upcoming_CT_schedule, offer_wk = offer_wk)\n",
    "upcoming_CT_schedule.to_csv('Jump Page Testing Schedule.csv', index=False)  \n",
    "    #CT_pipeline_output.to_csv('Content Testing Pipeline Output.csv', index=False)\n",
    "\n",
    "    # upload content testing schedule to Google Sheet\n",
    "\n",
    "\n",
    "print(bold + \"Jump Page Test SCHEDULE GENERATION IS DONE, PLEASE CHECK OUTPUT BEFORE RUNNING SCHEDULE CODE.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b067166a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Affiliate ID_DP.DS</th>\n",
       "      <th>Drop Number</th>\n",
       "      <th>Time</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Send Strategy</th>\n",
       "      <th>Offer</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Creative</th>\n",
       "      <th>Job Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>HZB_AL.PL</td>\n",
       "      <td>2</td>\n",
       "      <td>12:00 PM EST</td>\n",
       "      <td>HZB_AL.PL_30DC_VZN</td>\n",
       "      <td>JT</td>\n",
       "      <td>13194v1 -  HZB</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>13194.SC.HZB.453941</td>\n",
       "      <td>SS_HZB_AL-PL-30DC-VZN_13194_JT_24Jun24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>SVT_AL.PL</td>\n",
       "      <td>2</td>\n",
       "      <td>11:45 AM EST</td>\n",
       "      <td>SVT_AL.PL_30DC</td>\n",
       "      <td>JT</td>\n",
       "      <td>12089v2 -  SVT</td>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>12089.SC.SVT.453841</td>\n",
       "      <td>SS_SVT_AL-PL-30DC_12089_JT_25Jun24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>DSS_IM.SVY</td>\n",
       "      <td>2</td>\n",
       "      <td>10:00 AM PST</td>\n",
       "      <td>DSS_IM.SVY_30DC</td>\n",
       "      <td>JT</td>\n",
       "      <td>12089v2 -  DSS</td>\n",
       "      <td>5300</td>\n",
       "      <td>0</td>\n",
       "      <td>12089.SC.DSS.453521</td>\n",
       "      <td>SS_DSS_IM-SVY-30DC_12089_JT_26Jun24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>HZB_DOT.PL</td>\n",
       "      <td>2</td>\n",
       "      <td>10:00 AM PST</td>\n",
       "      <td>HZB_DOT.PL_30DC_VZN</td>\n",
       "      <td>JT</td>\n",
       "      <td>12978v1 -  HZB</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>12978.SC.HZB.453871\\n12978.SC.HZB.454601</td>\n",
       "      <td>SS_HZB_DOT-PL-30DC-VZN_12978_JT_25Jun24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>SVT_AL.PL.2</td>\n",
       "      <td>2</td>\n",
       "      <td>11:00 AM EST</td>\n",
       "      <td>SVT_AL.PL.2_15DC</td>\n",
       "      <td>CT</td>\n",
       "      <td>12978 - SVT</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>12978.SC.SVT.454601\\n12978.SC.SVT.454602</td>\n",
       "      <td>SS_SVT_AL-PL-2-15DC_12088_CT_25Jun24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>SVT_AL.PL.2</td>\n",
       "      <td>2</td>\n",
       "      <td>11:45 AM EST</td>\n",
       "      <td>SVT_AL.PL.2_15DC</td>\n",
       "      <td>JT</td>\n",
       "      <td>12088v1 -  SVT</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>OE.12088.SC.SVT.452111\\n12088.SC.SVT.454551</td>\n",
       "      <td>SS_SVT_AL-PL-2-15DC_12088_JT_25Jun24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-06-29</td>\n",
       "      <td>DSS_TLG.PL</td>\n",
       "      <td>2</td>\n",
       "      <td>12:00 PM PST</td>\n",
       "      <td>DSS_TLG.PL_15DC</td>\n",
       "      <td>JT</td>\n",
       "      <td>12342v1 - LG PAL DSS</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>PAL.12342.SC.DSS.451621</td>\n",
       "      <td>SS_DSS_TLG-PL-15DC_12342_JT_29Jun24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Affiliate ID_DP.DS  Drop Number          Time  \\\n",
       "0 2024-06-24          HZB_AL.PL            2  12:00 PM EST   \n",
       "1 2024-06-25          SVT_AL.PL            2  11:45 AM EST   \n",
       "2 2024-06-26         DSS_IM.SVY            2  10:00 AM PST   \n",
       "3 2024-06-25         HZB_DOT.PL            2  10:00 AM PST   \n",
       "4 2024-06-26        SVT_AL.PL.2            2  11:00 AM EST   \n",
       "5 2024-06-25        SVT_AL.PL.2            2  11:45 AM EST   \n",
       "8 2024-06-29         DSS_TLG.PL            2  12:00 PM PST   \n",
       "\n",
       "               Segment Send Strategy                 Offer  Limit  Offset  \\\n",
       "0   HZB_AL.PL_30DC_VZN            JT        13194v1 -  HZB   1000       0   \n",
       "1       SVT_AL.PL_30DC            JT        12089v2 -  SVT   4500       0   \n",
       "2      DSS_IM.SVY_30DC            JT        12089v2 -  DSS   5300       0   \n",
       "3  HZB_DOT.PL_30DC_VZN            JT        12978v1 -  HZB    659       0   \n",
       "4     SVT_AL.PL.2_15DC            CT           12978 - SVT   2200       0   \n",
       "5     SVT_AL.PL.2_15DC            JT        12088v1 -  SVT   1500       0   \n",
       "8      DSS_TLG.PL_15DC            JT  12342v1 - LG PAL DSS    712       0   \n",
       "\n",
       "                                      Creative  \\\n",
       "0                          13194.SC.HZB.453941   \n",
       "1                          12089.SC.SVT.453841   \n",
       "2                          12089.SC.DSS.453521   \n",
       "3     12978.SC.HZB.453871\\n12978.SC.HZB.454601   \n",
       "4     12978.SC.SVT.454601\\n12978.SC.SVT.454602   \n",
       "5  OE.12088.SC.SVT.452111\\n12088.SC.SVT.454551   \n",
       "8                      PAL.12342.SC.DSS.451621   \n",
       "\n",
       "                                  Job Name  \n",
       "0   SS_HZB_AL-PL-30DC-VZN_13194_JT_24Jun24  \n",
       "1       SS_SVT_AL-PL-30DC_12089_JT_25Jun24  \n",
       "2      SS_DSS_IM-SVY-30DC_12089_JT_26Jun24  \n",
       "3  SS_HZB_DOT-PL-30DC-VZN_12978_JT_25Jun24  \n",
       "4     SS_SVT_AL-PL-2-15DC_12088_CT_25Jun24  \n",
       "5     SS_SVT_AL-PL-2-15DC_12088_JT_25Jun24  \n",
       "8      SS_DSS_TLG-PL-15DC_12342_JT_29Jun24  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upcoming_CT_schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e373945d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfor index, row in content_feedback_report.iterrows():\\n\\n    # variables\\n    hitpath_offer_ID  = content_feedback_report[\\'HitPath Offer ID\\'].iloc[index]\\n    CCIDs  = content_feedback_report[\"Content ID\\'s\"].iloc[index]\\n    OfferType = content_feedback_report[\"Offer Type\"].iloc[index]\\n    Days_to_test = content_feedback_report[\"Days to Test\"].iloc[index]\\n\\n    print(\"------------------------------------------------------------------------\")\\n    print(\"Generating Schedule for CCIDs using Hitpath Offer ID:\", hitpath_offer_ID)\\n    print(\"------------------------------------------------------------------------\")\\n    \\n    offer_gaps_df = get_offer_vertical_gaps(df = lexi, EIMT = EIMT)\\n    account_rankings_df = get_account_rankings(df = lexi, offer = hitpath_offer_ID)\\n    DPPub_test = list(account_rankings_df[\\'DP&Pub\\'])\\n    \\n    success_counter = 0\\n    for DPPub in DPPub_test:\\n\\n        try:\\n            CT_eligibility_df = check_CT_eligiblity(CT_settings_url = \\'https://docs.google.com/spreadsheets/d/1TmWNe9MYmAB9s2MyH0UOOS1ZKdJKYl0AY6jgL6grHcc/edit#gid=1087982961\\',\\n                                                 default_max_drops = 3,\\n                                                 lexi = lexi,\\n                                                 cobra = cobra,\\n                                                 dataset_convertor = Dataset_to_DPPub,\\n                                                 offer = hitpath_offer_ID)\\n            \\n        except:\\n            print(\"* FAILED ON\", DPPub, \"*\")\\n            pass\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "for index, row in content_feedback_report.iterrows():\n",
    "\n",
    "    # variables\n",
    "    hitpath_offer_ID  = content_feedback_report['HitPath Offer ID'].iloc[index]\n",
    "    CCIDs  = content_feedback_report[\"Content ID's\"].iloc[index]\n",
    "    OfferType = content_feedback_report[\"Offer Type\"].iloc[index]\n",
    "    Days_to_test = content_feedback_report[\"Days to Test\"].iloc[index]\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Generating Schedule for CCIDs using Hitpath Offer ID:\", hitpath_offer_ID)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    \n",
    "    offer_gaps_df = get_offer_vertical_gaps(df = lexi, EIMT = EIMT)\n",
    "    account_rankings_df = get_account_rankings(df = lexi, offer = hitpath_offer_ID)\n",
    "    DPPub_test = list(account_rankings_df['DP&Pub'])\n",
    "    \n",
    "    success_counter = 0\n",
    "    for DPPub in DPPub_test:\n",
    "\n",
    "        try:\n",
    "            CT_eligibility_df = check_CT_eligiblity(CT_settings_url = 'https://docs.google.com/spreadsheets/d/1TmWNe9MYmAB9s2MyH0UOOS1ZKdJKYl0AY6jgL6grHcc/edit#gid=1087982961',\n",
    "                                                 default_max_drops = 3,\n",
    "                                                 lexi = lexi,\n",
    "                                                 cobra = cobra,\n",
    "                                                 dataset_convertor = Dataset_to_DPPub,\n",
    "                                                 offer = hitpath_offer_ID)\n",
    "            \n",
    "        except:\n",
    "            print(\"* FAILED ON\", DPPub, \"*\")\n",
    "            pass\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
